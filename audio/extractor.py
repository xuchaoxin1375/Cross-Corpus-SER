##

import os
import sys
from collections import defaultdict
from pathlib import Path

import ipdb
import numpy as np
import pandas as pd
import tqdm
from joblib import load

import config.MetaPath as mp
from audio.core import extract_feature_of_audio
from audio.create_meta import create_csv_by_metaname
from config.EF import (AHNPS, HNS, AHNPS_dict, HNS_dict, e_config_def,
                       f_config_def)
from config.MetaPath import (ava_dbs, ava_fts_params, create_tag_name, emodb,
                             features_dir, get_first_letters, meta_dir,
                             project_dir, train_emodb_csv, validate_partition)

# from pathlib import Path
Series = pd.Series
DataFrame = pd.DataFrame


class AudioExtractor:
    """A class that is used to featurize audio clips, and provide
    them to the machine learning algorithms for training and testing
    å’Œç‰¹å¾æå–ä¸åŒ,æœ¬æ¨¡å—è´Ÿè´£å¤„ç†ç‰¹å¾æå–ä¹‹åçš„æ•°æ®å¤„ç†,ç‰¹å¾æå–(å‚çœ‹utils.extract_featureæ–¹æ³•)
    æœ¬æ¨¡å—å°è¯•ä»æŒ‡å®šç›®å½•(é»˜è®¤ä»features)ç›®å½•å¯¼å…¥ç‰¹å¾æ–‡ä»¶(.npy)(ç”±numpyæä¾›çš„å¯¹è±¡å­˜å‚¨æ–¹æ¡ˆ)
    """

    def __init__(
        self,
        dbs=None,
        f_config=None,
        e_config=None,
        features_dir=features_dir,
        verbose=True,
        classification_task=True,
        balance=True,
        shuffle=True,
        feature_transforms_dict=None,
    ):
        """
        åˆå§‹åŒ–AEå¯¹è±¡,åœ¨initä¸­å¯¹æ„é€ å™¨ä¸­ä¼ å…¥Noneæˆ–è€…ä¸ä¼ å€¼å¾—å‚æ•°è®¾ç½®äº†é»˜è®¤å€¼,é»˜è®¤å‚æ•°ä¸ºNoneæ˜¯å‚è€ƒNumpyçš„é£æ ¼
        ç„¶è€Œé»˜è®¤å€¼è®¾ç½®åœ¨initä¹Ÿæœ‰ä¸å¥½çš„åœ°æ–¹,æ¯”å¦‚è¿™å®¹æ˜“å‡ºç°ä¸€äº›é»˜è®¤ä½†æ˜¯å‡ºä¹æ„æ–™çš„è¡Œä¸º;æ‰€ä»¥åº”è¯¥åœ¨æ³¨é‡Šéƒ¨åˆ†å°½å¯èƒ½åœ°è¯¦ç»†è¯´æ˜

        Params:
        -
        audio_config (dict):
            the dictionary that indicates what features to extract from the audio file,
            default is {'mfcc': True, 'chroma': True, 'mel': True, 'contrast': False, 'tonnetz': False}
            (i.e mfcc, chroma and mel)

        verbose (bool/int):
            verbosity level, False for silence, True for info, default is True

        features_folder_name (str):
            the folder to store output features extracted,
            default is "features".

        classification (bool):
            whether it is a classification or regression, default is True (i.e classification)

        emotions (list):
            list of emotions to be extracted, default is [ 'happy','neutral' ,'sad']

        balance (bool):
            whether to balance dataset (both training and testing), default is True
        """
        self.f_config = f_config if f_config else f_config_def
        self.e_config = e_config if e_config else e_config_def
        self.dbs = dbs
        self.verbose = verbose
        self.features_dir = features_dir  # é»˜è®¤ä¸ºfeaturesç›®å½•
        self.classification_task = classification_task
        self.feature_transforms = feature_transforms_dict
        
        self.balance = balance
        self.shuffle = shuffle
        # input dimension
        self.feature_dimension = None
        self.feature_dimension_pca = None
        # è®°å½•æœ€åä¸€æ¬¡æå–è¯­éŸ³æ–‡ä»¶ä¿¡æ¯
        self.audio_paths = []
        self.emotions = []

        # partition attributes
        self.train_audio_paths = []
        self.train_emotions = []
        self.train_features = []

        self.test_audio_paths = []
        self.test_emotions = []
        self.test_features = []
        # ä½¿ç”¨å­—å…¸æ‰“åŒ…
        self.pca = None
    def pathlike_to_list(self, meta_paths):
        if isinstance(meta_paths, str) or isinstance(meta_paths,Path):
            # print(f"cast the '{meta_paths}' to [str]")
            meta_paths = [meta_paths]
        return meta_paths

    def get_partition_features(self, partition) -> np.ndarray:
        """å°†åŒ…å«è‹¥å¹²ä¸ªäºŒç»´ndarrayçš„åˆ—è¡¨vstackæˆ1ä¸ªäºŒç»´ndarray
        self.featuresæ˜¯ä¸€ä¸ªåŒ…å«è‹¥å¹²ä¸ªåŒåˆ—æ•°çš„äºŒç»´æ•°ç»„çš„list,è¿™é‡Œå°†listä¸­çš„äºŒç»´æ•°ç»„åˆå¹¶ä¸º1ä¸ªäºŒç»´æ•°ç»„è¿”å›ä¹‹
        Parameters
        ----------
        partition : str
            "train"|"test"

        Returns
        -------
        np.ndarray
            åˆå¹¶å®Œæˆçš„äºŒç»´æ•°ç»„,è€Œä¸æ˜¯list

        Raises
        ------
        ValueError
            _description_
        """
        # print("len(self.train_features),len(self.test_features):")
        # print(len(self.train_features),len(self.test_features))
        # return
        partition = validate_partition(partition, Noneable=False)
        if partition == "test":
            res = np.vstack(self.test_features) if self.test_features else np.array([])
        else:
            res = (
                np.vstack(self.train_features) if self.train_features else np.array([])
            )

        return res

    def load_metadata(self, meta_files):
        """
        ä»ç»™å®šmeta_files(æ–‡ä»¶)è·¯å¾„ä¸­è¯»å–è¯­æ–™åº“å„æ¡è¯­éŸ³çš„ä¿¡æ¯;
        å¦‚æœéœ€è¦è¯»å–çš„meta_filesä¸å­˜åœ¨,é‚£ä¹ˆå°è¯•è§£æmeta_files(å¦‚æœmeta_fileså‚æ•°æ˜¯ä¸€ä¸ªç¬¦åˆå¯è§£æè§„èŒƒçš„å­—ç¬¦ä¸²)
        è¿™ç§æƒ…å†µä¸‹ä¼šè°ƒç”¨create_metaæ¨¡å—ä¸­çš„create_csv_by_metanameå‡½æ•°è¿›è¡Œmetaæ–‡ä»¶æ„é€ 

        Read metadata from a  file & Extract meta if according meta_files and loads features of audio files

        Parameters
        ----------
        meta_files : list[str]|str
            éœ€è¦è¯»å–çš„metaæ–‡ä»¶
        Return
        -
        ä»metaä¸­è¯»å–çš„ä¿¡æ¯:åŒ…æ‹¬å„è¯­éŸ³æ–‡ä»¶çš„è·¯å¾„å’Œæƒ…æ„Ÿæ ‡ç­¾

        """
        # empty dataframe
        df = pd.DataFrame({"path": [], "emotion": []})
        # åˆå¹¶æ‰€æœ‰éœ€è¦è¯»å…¥çš„æ–‡ä»¶
        # for meta_file in meta_files:
        #     # concat dataframes
        #     df = pd.concat((df, pd.read_csv(meta_file)), sort=False)
        if isinstance(meta_files, str):
            meta_files = [meta_files]
        if self.verbose:
            print("[I] Loading audio file paths and its corresponding labels...")
        # print("meta_files:", meta_files)

        # print("type(meta_files)", type(meta_files))

        meta_files = self.pathlike_to_list(meta_files)
        for meta_file in meta_files:
            if not os.path.exists(meta_file):
                # create_csv_by_meta_name
                print(f"{meta_file} does not exist,creating...ğŸ˜‚")

                create_csv_by_metaname(meta_file, shuffle=self.shuffle)
            else:
                print(f"meta_fileå­˜åœ¨{meta_file}æ–‡ä»¶!")
            df_meta = pd.read_csv(meta_file)
            df = pd.concat((df, df_meta), sort=False)
        # get columns
        # æŠ½å–éŸ³é¢‘æ–‡ä»¶è·¯å¾„ä¿¡æ¯å’Œå¯¹åº”çš„æƒ…æ„Ÿæ ‡ç­¾
        # audio_paths_:list
        # emotions_:list
        audio_paths, emotions = list(df["path"]), list(df["emotion"])
        return audio_paths, emotions

    def _class2rgr(self):
        # å¦‚æœæ‰§è¡Œå›å½’é¢„æµ‹,é‚£ä¹ˆæœ¬æ¨¡å—å°†å¢åŠ self.categories_rgrå°†æ ‡ç­¾æ•°å€¼åŒ–
        # é»˜è®¤æƒ…å†µä¸‹,ç³»ç»Ÿæ‰§è¡Œåˆ†ç±»é¢„æµ‹,æ ‡ç­¾æ˜¯æƒ…æ„Ÿåè¯å­—ç¬¦ä¸²
        # æ•°å€¼åŒ–ç±»åˆ«æ ‡ç­¾,ä¾¿äºä½¿ç”¨å›å½’ç®—æ³•é¢„æµ‹(è®¾ç½®3æƒ…æ„Ÿå’Œ5æƒ…æ„Ÿ2ç§æ¨¡å¼)
        # if not classification, convert emotions to numbers
        if not self.classification_task and self.e_config:
            if len(self.e_config) == 3:
                # HNSæƒ…æ„Ÿæ¨¡å¼(Happy,Neutral,Sad)
                self.categories_rgr = HNS_dict
            elif len(self.e_config) == 5:
                # AHNPSæƒ…æ„Ÿæ¨¡å¼:Angry,Happy,Neutral,PleasantSuprise,Sad
                self.categories_rgr = AHNPS_dict
            else:
                raise TypeError(f"Regression is only for either {HNS} or {AHNPS}")
            # TODO (improve)
            emotions = self.e_config  # å¯ä»¥å†ä¼˜åŒ–robustness
            emotions = [self.categories_rgr[e] for e in emotions]  # å­—ç¬¦ä¸²æ ‡ç­¾æ•°å­—åŒ–

    def _update_partition_attributes(
        self,
        partition,
        audio_paths=None,
        emotions=None,
        features=None,
    ):
        """
         ç”¨äºå®ç°å¢é‡æå–
         é™„åŠ å±æ€§é›†è®¾ç½®å’Œå¢é‡
         åˆæ¬¡è°ƒç”¨ä¼šè®¾ç½®æ–°å±æ€§

        ## Note1:
        è­¦æƒ•numpyçš„ndarrayæ•°ç»„åˆ¤æ–­boolå€¼æ—¶çš„é”™è¯¯åšæ³•:
        `ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`
        è¿™ä¸ªé”™è¯¯çš„æ˜¯ç”±äºndarrayå¯¹è±¡åœ¨boolä¸Šä¸‹æ–‡(æ¯”å¦‚if a)(aæ ‡è¯†ndarrayå¯¹è±¡)
        çš„è¯­å¥ä¸­,ç”±äºndarrayåŒ…å«çš„sizeä¸ªå…ƒç´ å„è‡ªæœ‰è‡ªå·±çš„`True`/`False`å€¼,éœ€è¦ç”¨any()æˆ–all()æ¥æ¶ˆé™¤æ­§ä¹‰
        ä¸è¿‡æœ‰æ—¶å€™æˆ‘ä»¬ä»…ä»…æƒ³çŸ¥é“è¢«åˆ¤æ–­çš„å¯¹è±¡æ˜¯å¦ä¸ºéç©ºæˆ–éNone,é‚£ä¹ˆå¯ä»¥ç”¨a.szieå±æ€§æ¥åˆ¤æ–­å…ƒç´ æ•°é‡,ç”¨`a is None`

        ## Note2:
        print(id(self.test_features), "@{Id@self.test_features}")
        print(id(features_attr), "@{Id@features_attr}")
        print(id(features),"@{Id@features}")


        Parameters
        ----------
        partition : str
            "train|test"
        audio_paths : list[str]
            train/test set file path
        emotions : list[str]
            tr/te set file path
        features : ndarray, optional
            ç”±ç‰¹å¾æå–ç¯èŠ‚è¿”å›çš„ç‰¹å¾æ•°ç»„, by default None

        """
        # if(audio_paths_ and emotions_):
        # audio_paths = self.audio_paths
        # emotions = self.e_config
        np.mean([12, 3])
        # è®¾ç½®è®­ç»ƒé›†å±æ€§
        partition = validate_partition(partition)
        verbose = self.verbose
        if verbose:
            print(f"[Info] Adding  {partition} samples")

        # partition_attribute_set
        audio_paths_attr, emotions_attr, features_attr = self.partition_attributes_set(
            partition
        )
        if audio_paths:
            audio_paths_attr += audio_paths
        if emotions:
            emotions_attr += emotions

        # è¿™é‡Œè¦åŒºåˆ«å¯¹å¾…features,åŸå› å‚è€ƒpythonçš„id()æ–¹æ³•
        if features is not None:
            features_attr += [features]  # å°†featuresæ‰“åŒ…ä¸ºåˆ—è¡¨åœ¨å¹¶å…¥
            # np.vstack(features)
        if verbose >= 2:
            # æ£€æŸ¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†å±æ€§æƒ…å†µ
            check_1 = self.partition_attributes_set(partition)
            for attr in check_1:
                nd_attr = np.array(attr, dtype=object)
                # print(nd_attr.shape, id(attr))

    def partition_attribute_update_handler(
        self, partition, features, audio_paths, emotions
    ):
        pass

    # @deprecate()
    def partition_attributes_set(self, partition="", verbose=1):
        """
        è¿”å›åˆå§‹å€¼ä¸ºç©ºåˆ—è¡¨çš„partitionå±æ€§
        - !è¦æ±‚è°ƒç”¨æœ¬æ–¹æ³•è¿”å›çš„å˜é‡å¿…é¡»ä½¿ç”¨+=çš„æ–¹æ³•ä¿®æ”¹,å¦åˆ™è¾¾ä¸åˆ°é¢„æœŸæ•ˆæœ
        - å¯¹äºfeatureså±æ€§,åœ¨è®¿é—®çš„æ—¶å€™å°†æ˜¯ä¸åŒçš„ç‰¹å¾çŸ©é˜µ
        - å…¶ä»–å†™æ³•
        if partition == "train":

            self.train_audio_paths+=value

        elif partition == "test":
            self.test_audio_paths+=value

        Parameters
        ----------
        partition : str
            _description_
        value : _type_
            _description_
        """
        partition = validate_partition(partition=partition)

        attributes = []
        if partition == "train":
            attributes = [
                self.train_audio_paths,
                self.train_emotions,
                self.train_features,
            ]
        elif partition == "test":
            attributes = [self.test_audio_paths, self.test_emotions, self.test_features]
        # print(attributes,"@{attributes}:",partition)
        if verbose >= 2:
            print("ids of attributes set:")
            print([id(attr) for attr in attributes])
        return attributes

    def _extract_feature_in_meta(self, partition="", meta_path="", verbose=1):
        """æ ¹æ®meta_filesæå–ç›¸åº”è¯­éŸ³æ–‡ä»¶çš„ç‰¹å¾
        è¿™é‡Œä»…å®Œæˆå•æ¬¡æå–

        çŸ©é˜µæ–‡ä»¶åä¸­çš„e_configå­—æ®µæš‚å®šä¸ºself.e_config
        å¦‚æœæ˜¯è¿™æ ·,å¯èƒ½ä¼šå’Œmeta_pathæ–‡ä»¶ä¸­çš„æƒ…æ„Ÿå­—æ®µå‡ºç°ä¸ä¸€è‡´çš„æƒ…å†µ.

        Parameters
        ----------
        meta_files : list[str]|str
            meta_files
        partition : str
            æ ‡è®°è¢«æå–æ–‡ä»¶æ˜¯æ¥è‡ªè®­ç»ƒé›†è¿˜æ˜¯æµ‹è¯•é›†(éªŒè¯é›†)
        """
        # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦æŒ‰ç…§é…ç½®çš„æƒ…æ„Ÿè¿›è¡Œç­›é€‰å’Œåˆ’åˆ†:

        audio_paths, emotions = self.load_metadata(meta_path)
        # å°†è®¡ç®—ç»“æœä¿å­˜ä¸ºå¯¹è±¡å±æ€§
        self.audio_paths = audio_paths
        self.emotions = emotions

        # å°è¯•è®¡ç®—è¯­æ–™åº“çš„åå­—å’Œæƒ…æ„Ÿé…ç½®åå­—
        db = self.fields_parse(meta_path)
        # ç‰¹å¾ä¿å­˜çš„ç›®å½•æ£€æŸ¥(ä¸å­˜åœ¨åˆ™åˆ›å»ºä¹‹)
        if not os.path.isdir(self.features_dir):
            os.mkdir(self.features_dir)

        n_samples = len(audio_paths)  # è®¡ç®—è¦å¤„ç†çš„éŸ³é¢‘æ–‡ä»¶æ•°

        features_file_path = self.get_features_file_path(partition, db, n_samples,ext="npy")
        fts_file_path=self.get_features_file_path(partition, db, n_samples,ext="fts")
        if verbose:
            print(f"æ£€æŸ¥ç‰¹å¾æ–‡ä»¶{features_file_path}æ˜¯å¦å­˜åœ¨...")
            print(f"{self.e_config=}")
            print(f"{self.f_config=}")

        ffp = os.path.isfile(features_file_path)
        # ftfp=os.path.isfile(fts_file_path)


        if ffp:
            # if file already exists, just load
            if self.verbose:
                print(f"ç‰¹å¾çŸ©é˜µæ–‡ä»¶(.npy)å·²ç»å­˜åœ¨,ç›´æ¥å¯¼å…¥:loading...")
            features = np.load(features_file_path)
            self.feature_dimension = features.shape[1]

        else:
            # file does not exist, extract those features and dump them into the file
            if self.verbose:
                print("npyæ–‡ä»¶ä¸å­˜åœ¨,å°è¯•åˆ›å»º...")
            # å¦‚æœå°šæœªæå–è¿‡ç‰¹å¾,åˆ™åœ¨æ­¤å¤„è¿›è¡Œæå–,åŒæ—¶ä¿å­˜æå–ç»“æœ,ä»¥ä¾¿ä¸‹æ¬¡ç›´æ¥ä½¿ç”¨
            # todo :ç›®å‰å¯¹äºç‰¹å¾æ ‡å‡†åŒ–std_scalerå’Œpcaé™ç»´ç­‰æ“ä½œ,åœ¨å°†éŸ³é¢‘æ–‡ä»¶æå–åˆå§‹ç‰¹å¾å¹¶æ‰§è¡Œtransformçš„æ—¶å€™ä¾èµ–äº
            # ä¹‹å‰æ‹Ÿåˆå·çš„transformer,å¦‚æœè¦ä¿ç•™è¿™ç±»å¤„ç†åçš„ç‰¹å¾,
            # ä¸ºäº†èƒ½å¤Ÿåœ¨å¯¼å…¥åèƒ½å¤Ÿæå–æ–°çš„éŸ³é¢‘åšåŒæ ·çš„é™ç»´æ“ä½œå°±éœ€è¦ä¹‹å‰çš„transformer
            # ç”±äºæ—¶é—´ä»“ä¿ƒ,æš‚æ—¶ä¸ä¿å­˜è¿™ç±»ç‰¹å¾,è€Œä»…ä¿å­˜(ç¼“å­˜)åˆå§‹ç‰¹å¾
            save_obj = not self.feature_transforms
            print(self.feature_transforms,"@{self.feature_transforms}ğŸˆ")
            print(save_obj,"@{save_obj}")
            features = self.features_extract_save(
                partition, audio_paths, features_file_path,save_obj
            )
        # if ftfp:
        #     if self.verbose:
        #         print("ftsæ–‡ä»¶(.fts)å­˜åœ¨,ç›´æ¥å¯¼å…¥...")
        #         # å¯¼å…¥åˆ°å¯¹è±¡å±æ€§
        #         self.fts=load(fts_file_path)
        # else:
        #     if self.verbose:
        #         print("ftsæ–‡ä»¶ä¸å­˜åœ¨,å°è¯•åˆ›å»º...")
        #     print(f"è¯·åˆ é™¤ç›¸å…³ç¼“å­˜æ–‡ä»¶{features_file_path}åé‡è¯•...")

        return features, audio_paths, emotions

    def get_features_file_path(self, partition, db, n_samples,ext=""):
        fts=self.feature_transforms

        if fts is None:
            self.feature_transforms = {}
        features_file_name = create_tag_name(
            db=db,
            partition=partition,  # å»ºè®®ä¿å­˜ç‰¹å¾æ–‡ä»¶æ—¶,è¿™ä¸ªå­—æ®µç½®ç©ºå³å¯
            e_config=self.e_config,
            f_config=self.f_config,
            n_samples=n_samples,
            ext=ext,
            **(self.feature_transforms),
        )

        # æ„é€ ä¿å­˜ç‰¹å¾çŸ©é˜µnpyæ–‡ä»¶çš„è·¯å¾„
        features_file_path = os.path.join(
            self.features_dir,
            features_file_name,
        )
        
        return features_file_path

    def fields_parse(self, meta_path):
        # è®¡ç®—è¯­æ–™åº“å­—æ®µå
        meta_fields, db = self.db_field_parse(meta_path)

        # è®¡ç®—æƒ…æ„Ÿå­—æ®µå¹¶æ£€æŸ¥
        self.validate_emotion_config_consistence(meta_fields)

        return db

    def db_field_parse(self, meta_path):
        meta_name = os.path.basename(meta_path)
        meta_name, ext = os.path.splitext(meta_name)
        meta_fields = meta_name.split("_")
        db = meta_fields[1]
        # print(f"{meta_path=}@")
        # print(f"{db=}@")

        db = db if db in ava_dbs else ""
        return meta_fields, db

    def validate_emotion_config_consistence(self, meta_fields):
        emotions_first_letters = meta_fields[-1]
        origin_efls = get_first_letters(self.e_config)
        # æ£€æŸ¥æƒ…æ„Ÿé…ç½®æ˜¯å¦å…·æœ‰ä¸€è‡´æ€§
        if emotions_first_letters != origin_efls:
            raise ValueError(
                f"{emotions_first_letters} is not inconsistant with {self.e_config}"
            )

    def features_extract_save(
        self, partition, audio_paths, features_file_path,save_obj=True
    ):
        """å°†æå–çš„ç‰¹å¾(ndarray)ä¿å­˜æŒä¹…åŒ–ä¿å­˜(ä¸ºnpyæ–‡ä»¶)
        åˆ©ç”¨qtmdæä¾›å¯è§†åŒ–ç‰¹å¾æŠ½å–è¿›åº¦

        Parameters
        ----------
        partition : str
            "test|train"
        audio_paths_ : str
            éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„
        features_file_path : str
            ä¿å­˜æ–‡ä»¶å(è·¯å¾„)

        Returns
        -------
        ndarray
            æå–çš„ç‰¹å¾æ•°ç»„
        """
        features = self.extract_features(partition, audio_paths)
        # ä¿å­˜æ•°æ®
        if save_obj:
            np.save(features_file_path, features)

        return features

    def extract_features(self, partition=None, audio_paths=None):
        """
        Extract features from audio_paths for a specific partition.

        å¤„ç†åŒ…æ‹¬æ ‡å‡†åŒ–æ”¾ç¼©
        pcaé™ç»´ç­‰ç‰¹å¾ä¼˜é€‰æ“ä½œ

        Args:
        -
        - partition: str, the partition to extract features for (train, val, test).
        - audio_paths: List[str], the list of audio file paths to extract features from.
        - verbose: bool, whether or not to print debugging info.

        Returns:
        - 
        - features: np.ndarray, the extracted features as a numpy array.
        """
        features = self.extract_raw_features(partition=partition, audio_paths=audio_paths)

        # è€ƒè™‘ç‰¹å¾é¢„å¤„ç†
        from sklearn.preprocessing import StandardScaler

        # Xä¸ºç‰¹å¾çŸ©é˜µ,yä¸ºæ ‡ç­¾

        fts = self.feature_transforms
        fts_keys=fts.keys()

        # if set(fts_keys) <= set(ava_fts_params):
        #     print("ftså‚æ•°keyåˆæ³•")
        # else:
        #     print("ftså‚æ•°ä¸åˆæ³•")
        for param in fts_keys:
            if param not in ava_fts_params:
                raise ValueError(f"ftså‚æ•°{param}ä¸åˆæ³•,è¯·å‚è€ƒå¯ç”¨çš„é…ç½®:{ava_fts_params}")
        print("ftså‚æ•°keyåˆæ³•")

        if fts.get("std_scaler"):
            print("use StandardScaler to transform features")
            std_scaler = StandardScaler()
            features = std_scaler.fit_transform(features)
        # å°å¿ƒå­—å…¸å…³é”®å­—åå­—pcaå’Œpca_params,å¦åˆ™åé¢ä»£ç æ— æ³•æ‰§è¡Œ!
        pca_params_dict = fts.get("pca_params")
        
        if not pca_params_dict:
            pass
            # print("the pca params may be invalid!")
        print("ğŸˆğŸˆğŸˆç‰¹å¾æå–")
        if pca_params_dict:
            from sklearn.decomposition import PCA

            print("use PCA to transform features")

            n_components = pca_params_dict.get("n_components")

      
            if n_components=='mle':
                pass
            elif isinstance(n_components, int):
                pass
            elif n_components and n_components.isdigit():
                # if n_components.isdigit():
                # int()å‡½æ•°è‡ªå¸¦ç±»å‹é”™è¯¯æ£€æµ‹,æœ‰éæ³•è¾“å…¥ä¼šè‡ªåŠ¨æŠ›å‡ºé”™è¯¯,æ‰€ä»¥è¿™é‡Œç›´æ¥ä½¿ç”¨,è€Œä¸å»æ‰‹åŠ¨æ£€æµ‹è¾“å…¥çš„åˆæ³•æ€§
                # pca_params_dict['n_components'] = int(n_components)
                n_components=int(n_components)
            # elif n_components == "None":
            else:
                # pca_params_dict["n_components"] = None
                n_components=None

            # å°†æ£€éªŒ&å¤„ç†åçš„n_componentså†™å…¥åˆ°pcaå­—å…¸ä¸­
            pca_params_dict['n_components']=n_components
            # æ ¹æ®å½“å‰aeå¯¹è±¡ä¸­çš„pcaå±æ€§ä»¥åŠå‚æ•°æƒ…å†µå†³å®šæ„é€ pcaå¯¹è±¡
            if self.pca is None:
                pca = self.pca = PCA(**pca_params_dict)
                pca.fit(features)

            else:
                pca = self.pca
            print(pca_params_dict, "@{pca_params_dict}ğŸ˜‚")
            print(pca.n_components_, "@{pca.n_components_}")
            features = pca.transform(features)
            print(features.shape, "{features.shape}ğŸ˜‚")
            # sys.exit()
            # è¿™éƒ¨åˆ†å¯ä»¥æŠ½å–ä¸ºå•ç‹¬çš„å‡½æ•°get_n_features_pcaæ›´åŠ çµæ´»
            # ä½¿ç”¨é¢å‘å¯¹è±¡çš„ç¼–ç¨‹æ–¹å¼æœ‰ç‚¹å°±æ˜¾ç¤ºå‡ºæ¥äº†,å¯ä»¥é€šè¿‡å¯¹è±¡å±æ€§æˆ–getæ–¹æ³•æ¥æé«˜è®¿é—®å¯¹è±¡æ•°æ®æˆ–å±æ€§,å®ç°çµæ´»é€šä¿¡,å‡å°‘å¯¹äºç‰¹å®šå‡½æ•°çš„ä¾èµ–
            self.feature_dimension_pca = pca.n_components
        return features

    def get_dimensions(self):
        return np.array(self.test_features).shape[1]

    def extract_raw_features(self, partition=None, audio_paths=None):
        features = []
        # print(audio_paths)
        # append = features.append

        # ç‰¹å¾æå–æ˜¯ä¸€ä¸ªæ¯”è¾ƒè€—æ—¶çš„è¿‡ç¨‹,ç‰¹å¾ç§ç±»è¶Šå¤šè¶Šè€—æ—¶,è¿™é‡Œé‡‡ç”¨tqdmæ˜¾ç¤ºç‰¹å¾æå–è¿›åº¦æ¡(å·²å¤„ç†æ–‡ä»¶/æ–‡ä»¶æ€»æ•°)
        cnt = 0
        # iter = tqdm.tqdm(
        #     audio_paths, f"Extracting features for partition:{partition}"
        # )
        iter= audio_paths
        for audio_file in iter:

            if self.verbose > 1:
                cnt += 1
                if cnt % 20 == 0:
                    print(f"æ­£åœ¨æŠ½å–ç¬¬{cnt}ä¸ªæ–‡ä»¶çš„ç‰¹å¾..")
            # è°ƒç”¨utilsæ¨¡å—ä¸­çš„extract_featrueè¿›è¡Œç‰¹å¾æå–
            f_config = self.f_config
            #! æŠ½å–ç‰¹å¾
            feature = extract_feature_of_audio(audio_file, f_config=f_config)
            if self.feature_dimension is None:
                # MCMç‰¹å¾ç»„åˆä¸‹(3ç‰¹å¾),æœ‰180ç»´çš„å•è½´æ•°ç»„,5ç‰¹å¾ä¸‹,æœ‰193ç»´
                self.feature_dimension = feature.shape[0]
            # æŠŠå½“å‰æ–‡ä»¶æå–å‡ºæ¥ç‰¹å¾æ·»åŠ åˆ°featuresæ•°ç»„ä¸­
            features.append(feature)

        # featuresæ˜¯ä¸€ä¸ªäºŒç»´æ•°ç»„(n_samples,feature_dimension),æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªç‰¹å¾
        # æ­¤æ—¶æ‰€æœ‰æ–‡ä»¶ç‰¹å¾æå–å®Œæ¯•,å°†å…¶ç”¨numpyä¿å­˜ä¸ºnpyæ–‡ä»¶
        # æ„æˆäºŒç»´æ•°ç»„
        features = np.array(features)
        return features

    def extract_update(self, partition="", meta_paths="", verbose=1):
        """
        æ ¹æ®meta_pathsè¿›è¡Œç‰¹å¾æå–ä»»åŠ¡
        æå–å®Œç‰¹å¾åå¯¹ç›¸å…³selfå±æ€§æ›´æ–°ç»´æŠ¤

        å¤šæ¬¡è°ƒç”¨å°†æ‰§è¡Œå¢é‡æå–,æ ¹æ®partitionçš„å–å€¼,å°†æ¯æ¬¡çš„æå–ç»“æœå¢é‡æ›´æ–°selfçš„ç›¸åº”å±æ€§é›†

        Parameters
        ----------
        partition : str
            "train"|"test"
        meta_paths : list[str]|str
            éœ€è¦æå–ç‰¹å¾çš„metaæ–‡ä»¶è·¯å¾„
        """
        if not meta_paths:
            raise ValueError("meta_files cannot be empty")
            # return meta_files
        meta_paths = self.pathlike_to_list(meta_paths)

        # æ‰§è¡Œç‰¹å¾æå–
        for meta_file in meta_paths:
            print(meta_file, "@ğŸˆ{meta_file}")
            # sys.exit()
            # æ ¹æ®metaæ–‡ä»¶è¿›è¡Œæ‰¹é‡åœ°ç‰¹å¾æå–
            features, audio_paths, emotions = self._extract_feature_in_meta(
                meta_path=meta_file, partition=""
            )
            # è¿™é‡Œå°†partitionè®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²,æ˜¯å› ä¸ºæ ‡è®°ç‰¹å¾æ˜¯ç”¨æ¥è®­ç»ƒè¿˜æ˜¯ç”¨æ¥æµ‹è¯•æ„ä¹‰ä¸å¤§
            # è€Œä¸”åœ¨è·¨åº“è¯•éªŒä¸­,æˆ‘ä»¬ä¼šè®©ä¸€ä¸ªtrain/test features äº¤æ¢èº«ä»½,
            # åªéœ€è¦çŸ¥é“è¿™ä¸ªç‰¹å¾æ–‡ä»¶åŒ…å«å“ªäº›æƒ…æ„Ÿç‰¹å¾,æ¥è‡ªå“ªä¸ªè¯­æ–™åº“,ä»¥åŠæœ‰å¤šå°‘ä¸ªæ–‡ä»¶å³å¯
            # å¦‚æœè¦æ›´ç»†è‡´ä¸€äº›,å¯ä»¥è€ƒè™‘åŠ å…¥balanceæˆ–shuffleä¿¡æ¯,ä½†è¿™ä¸æ˜¯å¿…é¡»çš„,è€Œä¸”ä¼šå¯¹è°ƒè¯•é€ æˆä¸å˜
            if verbose >= 1:
                print(features.shape, "@{feature.shape}")
            if verbose >= 2:
                print(features, "@{features}")

            # æ¯æ ¹æ®ä¸€ä¸ªmeta_fileæå–ä¸€æ‰¹ç‰¹å¾,å°±æ›´æ–°åˆ°selfçš„ç›¸å…³å±æ€§é›†ä¸­
            self._update_partition_attributes(
                partition=partition,
                audio_paths=audio_paths,
                emotions=emotions,
                features=features,
            )


    def load_data_preprocessing(self, meta_files=None, partition="", shuffle=False):
        """å°†ç‰¹å¾æå–å’Œå±æ€§è®¾ç½®ä»¥åŠæ‰“ä¹±å’Œå¹³è¡¡æ“ä½œæ‰“åŒ…å¤„ç†
        AEå¯¹è±¡åœ¨å¦‚æ•°æ®é›†åå¯é€‰çš„æ•°æ®å¤„ç†æ“ä½œ(balance&shuffle)

        Parameters
        ----------
        meta_files : list[str]|str
            éœ€è¦è½½å…¥æ•°æ®çš„metaä¿¡æ¯
        partition : str, optional
            "test|train", by default None
        shuffle : bool, optional
            æ˜¯å¦æ‰§è¡Œæ‰“ä¹±æ•°æ®é¡ºåºæ“ä½œ, by default False
        """
        print(f"{partition=}")
        # print(meta_files,"@{meta_files}in load_data_preprossing")
        if not meta_files:
            return
        self.extract_update(
            partition=partition,
            meta_paths=meta_files,
            # feature_transforms=self.feature_transforms,
        )

        # balancing the datasets ( both training or testing )
        if self.balance:
            self._balance_data(partition=partition)
        # shuffle
        if shuffle:
            self.shuffle_by_partition(partition)

    def shuffle_by_partition(self, partition):
        """æ‰“ä¹±æ•°æ®é¡ºåº

        Parameters
        ----------
        partition : str
            "train"|"test"

        Raises
        ------
        TypeError

        """
        if partition == "train":
            (
                self.train_audio_paths,
                self.train_emotions,
                self.train_features,
            ) = shuffle_data(
                self.train_audio_paths,
                self.train_emotions,
                # self.train_features
                self.get_partition_features("train"),
            )
        elif partition == "test":
            (
                self.test_audio_paths,
                self.test_emotions,
                self.test_features,
            ) = shuffle_data(
                self.test_audio_paths,
                self.test_emotions,
                #   self.test_features
                self.get_partition_features("test"),
            )
        else:
            raise TypeError("Invalid partition, must be either train/test")

    def _balance_data(self, partition=""):
        """
        å¯¹è®­ç»ƒé›†/æµ‹è¯•é›†çš„æ•°æ®åšå¹³è¡¡å¤„ç†

        """
        partition = validate_partition(partition=partition)

        audio_paths, counter, emotions_tags, features = self.emotions_counter(partition)

        # get the minimum data samples to balance to
        minimum = self.validate_balance_task(counter)
        if minimum == 0:
            return

        # æ„é€ å¹¶åˆå§‹åŒ–{æƒ…æ„Ÿ:æ•°é‡}å­—å…¸
        counter = self.count_dict()

        dd = self.balanced_dict(audio_paths, counter, emotions_tags, features, minimum)

        # å°†ç±»åˆ«å¹³è¡¡å¤„ç†å¥½çš„å…ƒç»„å½¢å¼é‡æ–°è§£æå›åŸºæœ¬pythonç±»å‹å¯¹è±¡
        audio_paths, emotions_tags, features = self.parse_balanced_data(dd)
        # å°†è§£æç»“æœæ›´æ–°å›selfå¯¹è±¡çš„ç›¸åº”å±æ€§ä¸Š
        self.update_balanced_attributes(partition, audio_paths, emotions_tags, features)

    def validate_balance_task(self, counter):
        minimum = min(counter)
        if self.verbose:
            print("[*] Balancing the dataset to the minimum value:", minimum)
        if minimum == 0:
            # won't balance, otherwise 0 samples will be loaded
            print("[!] One class has 0 samples, setting balance to False")
            self.balance = False
        return minimum

    def balanced_dict(self, audio_paths, counter, emotions_tags, features, minimum):
        """æ„é€ å¹³è¡¡å¤„ç†å¥½æ•°æ®é›†çš„å­—å…¸

        å®ç°è¯´æ˜:æœ¬æ–¹æ³•ä¸»è¦å€ŸåŠ©defaultdictå®ç°,ç®€ç§°dd
        å®ƒæ˜¯ Python ä¸­çš„ä¸€ä¸ªå­—å…¸å­ç±»ï¼Œå®ƒåœ¨å­—å…¸çš„åŸºç¡€ä¸Šæ·»åŠ äº†ä¸€ä¸ªé»˜è®¤å·¥å‚å‡½æ•°ï¼Œ
        ä½¿å¾—åœ¨è®¿é—®å­—å…¸ä¸­ä¸å­˜åœ¨çš„é”®æ—¶ï¼Œå¯ä»¥è¿”å›ä¸€ä¸ªé»˜è®¤å€¼è€Œä¸æ˜¯å¼•å‘ KeyError å¼‚å¸¸ã€‚
        defaultdict çš„æ„é€ å‡½æ•°éœ€è¦ä¸€ä¸ªå‚æ•°ï¼Œå³é»˜è®¤å·¥å‚å‡½æ•°ã€‚
        é»˜è®¤å·¥å‚å‡½æ•°å¯ä»¥æ˜¯ Python å†…ç½®ç±»å‹ï¼ˆå¦‚ intã€listã€set ç­‰ï¼‰ï¼Œä¹Ÿå¯ä»¥æ˜¯ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°ã€‚
        å½“è®¿é—®å­—å…¸ä¸­ä¸å­˜åœ¨çš„é”®æ—¶ï¼Œå¦‚æœä½¿ç”¨äº†é»˜è®¤å·¥å‚å‡½æ•°ï¼Œåˆ™ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªæ–°çš„é”®ï¼Œ
        å¹¶å°†å…¶å¯¹åº”çš„å€¼åˆå§‹åŒ–ä¸ºé»˜è®¤å€¼ï¼ˆç”±é»˜è®¤å·¥å‚å‡½æ•°è¿”å›ï¼‰ã€‚

        åœ¨ddçš„å¸®åŠ©ä¸‹,æˆ‘ä»¬å¯ä»¥è½»æ¾çš„ç»Ÿè®¡(æƒ…æ„Ÿ)ç±»åˆ«æ•°æœªçŸ¥çš„æƒ…å†µä¸‹,ç»Ÿè®¡å„ä¸ªæƒ…æ„Ÿçš„æ–‡ä»¶æ•°

        Parameters
        ----------
        audio_paths : list
            _description_
        counter :
            _description_
        emotions_tags : _type_
            _description_
        features : _type_
            _description_
        minimum : _type_
            _description_

        Returns
        -------
        _type_
            _description_
        """
        dd = defaultdict(list)  #
        for e, feature, audio_path in zip(emotions_tags, features, audio_paths):
            if counter[e] >= minimum:
                # minimum value exceeded
                continue
            counter[e] += 1
            dd[e].append((feature, audio_path))
        # data={}
        # ä¸´æ—¶å±æ€§ç”¨äºnotebookä¸­è°ƒè¯•
        self.dd_debug = dd
        # print(dd)
        return dd

    def count_dict(self, verbose=0):
        """æ„é€ å¹¶åˆå§‹åŒ–{æƒ…æ„Ÿ:æ•°é‡}å­—å…¸
        Returns
        -------
        dict
            ç”¨äºç»Ÿè®¡å¹³è¡¡æ•°æ®çš„å­—å…¸
        """
        if self.classification_task:
            res = {e: 0 for e in self.e_config}  # type:ignore
        else:
            res = {e: 0 for e in self.categories_rgr.values()}

        if verbose:
            print("{res}:")
            print(res)
        return res

    def parse_balanced_data(self, dd):
        emotions_tags, features, audio_paths = [[] for _ in range(3)]
        for emo, f_ap in dd.items():
            for feature, audio_path in f_ap:
                emotions_tags.append(emo)
                features.append(feature)
                audio_paths.append(audio_path)
        return audio_paths, emotions_tags, features

    def update_balanced_attributes(
        self, partition, audio_paths, emotions_tags, features
    ):
        """å°†è§£æç»“æœæ›´æ–°å›selfå¯¹è±¡çš„ç›¸åº”å±æ€§ä¸Š

        Parameters
        ----------
        partition : str
            "test|train"
        audio_paths : list
            è·¯å¾„
        emotions_tags : list
            æƒ…æ„Ÿæ ‡ç­¾
        features : list
            ç‰¹å¾

        Raises
        ------
        TypeError
            æ•°æ®é›†ç›®æ ‡åå­—åˆ’åˆ†éæ³•(test|train)
        """
        partition = validate_partition(partition=partition, Noneable=False)
        if partition == "train":
            self.train_emotions = emotions_tags
            self.train_features = features
            self.train_audio_paths = audio_paths
        elif partition == "test":
            self.test_emotions = emotions_tags
            self.test_features = features
            self.test_audio_paths = audio_paths

    def emotions_counter(self, partition):
        # ç»Ÿä¸€å˜é‡å
        data = [None] * 3
        if partition == "train":
            data = (self.train_emotions, self.train_features, self.train_audio_paths)
        elif partition == "test":
            data = (self.test_emotions, self.test_features, self.test_audio_paths)
        else:
            raise TypeError("Invalid partition, must be either train/test")
        emotions_tags, features, audio_paths = data
        # ä¸ºäº†ä½¿å„ä¸­æƒ…æ„Ÿçš„æ–‡ä»¶æ•°é‡ç›¸ç­‰,åˆ†åˆ«ç»Ÿè®¡ä¸åŒæƒ…æ„Ÿçš„æ–‡ä»¶æ•°
        counter = []  # countä¸­çš„å…ƒç´ ä¸ªæ•°ç­‰äºlen(self.emotions)
        # åˆ†ç±»é¢„æµ‹
        if self.classification_task:
            # éå†éœ€è¦æŠ½å–çš„æƒ…æ„Ÿæ ‡ç­¾
            e_config = self.e_config if self.e_config else e_config_def
            for emo in e_config:
                n_samples_of_emo = len([e for e in emotions_tags if e == emo])
                counter.append(n_samples_of_emo)
        # å›å½’é¢„æµ‹
        else:
            # regression, take actual numbers, not label emotion
            for emo in self.categories_rgr.values():
                counter.append(len([e for e in emotions_tags if e == emo]))
        return audio_paths, counter, emotions_tags, features
        # return counter


def shuffle_data(audio_paths, emotions, features):
    """Shuffle the data
        (called after making a complete pass through
        training or validation data during the training process)

    Params:
    -
        audio_paths (list): Paths to audio clips
        emotions (list): Emotions in each audio clip
        features (list): features audio clips
    """
    length = len(audio_paths)
    # print(length)
    # print([len(item) for item in (audio_paths,emotions,features)])
    if length:
        # å¯¹range(length)çš„ä¹±åºæ’åˆ—åˆ—è¡¨
        # æ ¹æ®ç»Ÿä¸€çš„ä¹±åºåºåˆ—,ä¾¿äºç»Ÿä¸€audio_paths,emotions,features
        # å› æ­¤è¿™é‡Œä¸å¯ç”¨ç›´æ¥åœ°å¯¹ä¸‰ä¸ªåˆ—è¡¨å„è‡ªåœ°è¿è¡Œshuffleæˆ–permutation,ä¼šå¯¼è‡´å¯¹åº”ä¸ä¸Š
        p = np.random.permutation(length)
        # æ‰‹åŠ¨åœ¨æ­¤å¤„æŠ›å‡ºè°ƒè¯•æ€§å¼‚å¸¸(æ­¤å¤„é‡‡ç”¨pdbæ¨¡å—æ¥è°ƒè¯•)
        # raise ValueError("short!")
        audio_paths = [audio_paths[i] for i in p]
        emotions = [emotions[i] for i in p]
        features = [features[i] for i in p]

    return audio_paths, emotions, features


def load_data_from_meta(
    train_meta_files=None,
    test_meta_files=None,
    f_config=None,
    e_config=None,
    classification_task=True,
    shuffle=True,
    balance=False,
    feature_transforms=None,
) -> dict:
    """
    æ ¹æ®metaæ–‡ä»¶,æå–/å¯¼å…¥è¯­éŸ³æ•°æ®(numpyç‰¹å¾),å¹¶è¿”å›numpyæ‰“åŒ…train/test datasetç›¸å…³å±æ€§çš„ndarrayç±»å‹
    å¦‚æœåªæƒ³æå–train/test datasetä¸­çš„ä¸€æ–¹,é‚£ä¹ˆå¦ä¸€æ–¹å°±ä¼ None(æˆ–è€…ä¸ä¼ å¯¹åº”å‚æ•°)å³,å‰ä¸¤ä¸ªå‚æ•°ä¸­å…è®¸å…¶ä¸­ä¸€ä¸ªä¸ºNone

    Parameters
    ----------
    train_desc_files : list
        éœ€è¦æå–ç‰¹å¾çš„è¯­éŸ³æ–‡ä»¶åˆ—è¡¨ä¿¡æ¯,ä½œä¸ºè®­ç»ƒé›†
    test_desc_files : list
        éœ€è¦æå–ç‰¹å¾çš„è¯­éŸ³æ–‡ä»¶åˆ—è¡¨ä¿¡æ¯,ä½œä¸ºæµ‹è¯•é›†
    f_config : list[str], optional
        éœ€è¦æå–çš„ç‰¹å¾ç»„åˆ, by default None
    e_config : list[str], optional
        éœ€è¦ä½¿ç”¨çš„æƒ…æ„Ÿç»„åˆ,ç±»åˆ«å­—ç¬¦ä¸²æ„æˆçš„åˆ—è¡¨, by default ['sad', 'neutral', 'happy']
    classification_task : bool, optional
        æ˜¯å¦é‡‡ç”¨åˆ†ç±»æ¨¡å‹(å¦åˆ™ä½¿ç”¨å›å½’æ¨¡å‹), by default True
    shuffle : bool, optional
        æ˜¯å¦æ‰“ä¹±é¡ºåº, by default True
    balance : bool, optional
        æ˜¯å¦è¿›è¡Œæ•°æ®å¹³è¡¡, by default True

    Returns
    -------
    dict
        è¿”å›è½½å…¥æƒ…æ„Ÿç‰¹å¾æ–‡ä»¶çš„çŸ©é˜µæ„æˆçš„å­—å…¸
    """
    # instantiate the class(å®ä¾‹åŒ–ä¸€ä¸ªAudioExtractorå®ä¾‹)
    ae = AudioExtractor(
        f_config=f_config,
        e_config=e_config,
        classification_task=classification_task,
        balance=balance,
        shuffle=shuffle,
        verbose=True,
        feature_transforms_dict=feature_transforms,
    )

    # print(test_meta_files, "@{test_meta_files} in load_data_from_meta")

    # Loads training data
    ae.load_data_preprocessing(
        meta_files=train_meta_files, partition="train", shuffle=shuffle
    )
    # Loads testing data
    ae.load_data_preprocessing(
        meta_files=test_meta_files, partition="test", shuffle=shuffle
    )

    # ä»¥trainé›†ä¸ºä¾‹æ£€æŸ¥selfå±æ€§
    # print("ae.train_audio_paths:\n", ae.train_audio_paths)
    # X_train, X_test, y_train, y_test

    return {
        # "X_train": np.array(ae.train_features),
        # "X_test": np.array(ae.test_features),
        "X_train": ae.get_partition_features("train"),
        "X_test": ae.get_partition_features("test"),
        "y_train": np.array(ae.train_emotions),
        "y_test": np.array(ae.test_emotions),
        "train_audio_paths": np.array(ae.train_audio_paths),
        "test_audio_paths": np.array(ae.test_audio_paths),
        "balance": ae.balance,  # åé¦ˆæ˜¯å¦é¡ºåˆ©æ‰§è¡Œäº†balance
        "ae": ae,
    }



def load_data_from_meta_demo():
    meta_dict=dict(
        train_meta_files=meta_dir/'train_emodb_HNS.csv',
        test_meta_files=meta_dir/'test_emodb_HNS.csv',
    )
    res=load_data_from_meta(**meta_dict,f_config=f_config_def)

    return res

if __name__ == "__main__":

    load_data_from_meta_demo()

    # ftd = dict(std_scaler=False, pca_params=dict(n_components=3))
    # ae = AudioExtractor(
    #     e_config=e_config_def,
    #     f_config=f_config_def, shuffle=True, feature_transforms_dict=ftd
    # )
    # print(ae)
    # ae._extract_feature_in_meta(meta_path=train_emodb_csv)
    # data = load_data_from_meta(
    #     # train_meta_files=train_emodb_csv,
    #     test_meta_files=test_emodb_csv,
    #     f_config=f_config_def,
    #     # balance=False,
    #     balance=True,
    # )
    
