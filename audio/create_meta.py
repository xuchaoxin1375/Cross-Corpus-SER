##
import os
import random
from glob import glob
from pathlib import Path

import pandas as pd
from pandas import DataFrame
from sklearn.model_selection import train_test_split as tts

from config.EF import categories_emodb, extend_emotion_names
from config.MetaPath import (
    emodb,
    emodb_files_glob,
    meta_paths_of_db,
    ravdess,
    ravdess_files_glob,
    savee,
    savee_files_glob,
)


def check_meta_names(e_config, train_name=None, test_name=None, db=""):
    if train_name is None or test_name is None:
        train_name, test_name = meta_paths_of_db(db, e_config=e_config)
    if db == "":
        raise ValueError("db must be specified non None")
    return train_name, test_name


##
"""
æœ¬æ¨¡å—è´Ÿè´£å°†ä¸åŒçš„è¯­æ–™åº“æ–‡ä»¶çš„å…ƒæ•°æ®(è·¯å¾„å’Œæƒ…æ„Ÿæ ‡ç­¾)ç»Ÿä¸€åŒ–,å¹¶ä¸”ä½œæŒä¹…åŒ–ä¿å­˜å¤„ç†(csvæ–‡ä»¶)
ä¸åŒçš„è¯­æ–™åº“ç”±äºæ–‡ä»¶åè§„èŒƒä¸åŒ,æ‰€ä»¥éœ€è¦åˆ†åˆ«ç¼–å†™å¤„ç†å‡½æ•°
!æ³¨æ„å°å¿ƒä½¿ç”¨os.chdir()æ”¹å˜å·¥ä½œç›®å½•,ç‰¹åˆ«éœ€è¦è®¿é—®ä¸åŒç›®å½•çš„æƒ…å†µ
"""


def create_emodb_csv(
    e_config=None,
    train_name=None,
    test_name=None,
    train_size=0.8,
    verbose=1,
    shuffle=False,
):
    """
    Reads speech emodb dataset from directory and write it to a metadata CSV file.

    params:
    -
        emotions (list):
            list of emotions to read from the folder, default is ['sad', 'neutral', 'happy']
        train_name (str):
            the output csv filename for training data, default is 'train_emo.csv'
        test_name (str):
            the output csv filename for testing data, default is 'test_emo.csv'
        train_size (float):
            the ratio of splitting training data, default is 0.8 (80% Training data and 20% testing data)

            - å¯ä»¥è€ƒè™‘ä½¿ç”¨sklearnçš„model_sectionæ¨¡å—æä¾›çš„apiæ¥å®Œæˆæ•°æ®åˆ’åˆ†æ“ä½œ,ä¾‹å¦‚train_test_split()æ–¹æ³•
        verbose (int/bool):
             verbositiy level, 0 for silence, 1 for info, default is 1
    """
    db = emodb

    train_name, test_name = check_meta_names(e_config, train_name, test_name, db)

    target = {"path": [], "emotion": []}
    categories = categories_emodb
    tp = target["path"]
    te = target["emotion"]
    # delete not specified emotions
    # é¢ å€’å­—å…¸ç§çš„é”®å€¼å¯¹ä¸º æƒ…æ„Ÿ:ç¼©å†™(emotion:code)
    # é¢ å€’ä¸æ˜¯å¿…é¡»çš„,è¿™é‡Œé¡ºä¾¿ä¸ºä¹‹,categories_reversedä½œä¸ºä¸´æ—¶çš„å­—å…¸è¾…åŠ©ç­›æ‰ä¸éœ€è¦çš„æƒ…æ„Ÿ
    categories_reversed = {emotion: code for code, emotion in categories.items()}
    if e_config is None:
        raise ValueError(f"e_config is None")
    for emotion, code in categories_reversed.items():
        if emotion not in e_config:
            del categories[code]
    # shuffleå¯ä»¥åœ¨è¿™ä¸ªç¯èŠ‚è¿›è¡Œ:
    files_iter = glob(emodb_files_glob)
    if shuffle:
        random.shuffle(files_iter)

    for file in files_iter:
        try:
            # emodbæ–‡ä»¶å½¢å¦‚`03a01Wa.wav`
            # - 03 è¡¨ç¤ºè¿™ä¸ªéŸ³é¢‘è®°å½•æ¥è‡ªç¬¬3ä½æ¼”å‘˜
            # - a01 è¡¨ç¤ºè¿™ä¸ªéŸ³é¢‘è®°å½•æ˜¯è¯¥æ¼”å‘˜è¡¨æ¼”çš„ç¬¬1ç§æƒ…æ„Ÿ
            # - W è¡¨ç¤ºè¿™ä¸ªæƒ…æ„Ÿæ˜¯â€œæ„¤æ€’â€ï¼ˆAngryï¼‰çš„ç¼©å†™
            # - a è¡¨ç¤ºè¿™ä¸ªæ˜¯è¯¥æƒ…æ„Ÿçš„ç¬¬1ä¸ªå‰¯æœ¬ï¼ˆç¬¬ä¸€ä¸ªè¡¨æ¼”ï¼‰
            # - .wav è¡¨ç¤ºè¿™ä¸ªæ–‡ä»¶çš„æ ¼å¼ä¸º.wavæ ¼å¼
            # æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯ç¬¬6ä¸ªå­—ç¬¦(ä¹Ÿå³æ˜¯[5])
            e = os.path.basename(file)[5]
            emotion: str = categories[e]
            # å¯ä»¥ä½¿ç”¨å­—å…¸çš„getæ–¹æ³•æ¥é¿å…KeyError,ä¸è¿‡è¿™é‡Œæˆ‘ä»¬è€ƒè™‘é€šè¿‡å¼‚å¸¸æŠ›å‡ºåšå‡ºåŠæ—¶çš„åé¦ˆ
        except KeyError:
            # print("key error")
            continue
        tp.append(file)
        te.append(emotion)
        # target['emotion'].append(emotion)
        # target['path'].append(file)
    n_samples = len(target["path"])

    if verbose:
        print("[EMO-DB] Total files to write:", n_samples)

    # dividing training/testing sets
    test_samples: int = int((1 - train_size) * n_samples)
    train_samples: int = int(train_size * n_samples)
    if verbose:
        print(
            f"[{db}_{e_config}] Training samples:",
            train_samples,
            "\nTesting samples:",
            test_samples,
        )

    X_train = target["path"][:train_samples]
    X_test = target["path"][train_samples:]
    y_train = target["emotion"][:train_samples]
    y_test = target["emotion"][train_samples:]
    print(e_config)

    # train_name=create_tag_name(emodb,partition="train")
    # test_name=create_tag_name(emodb,partition="test")
    # print(X_train,y_train)
    # print(train_name,test_name)
    pd.DataFrame({"path": X_train, "emotion": y_train}).to_csv(train_name)
    pd.DataFrame({"path": X_test, "emotion": y_test}).to_csv(test_name)


##
def create_savee_csv(
    e_config=None,
    train_name=None,
    test_name=None,
    train_size=0.8,
    verbose=1,
    subset_size=1,
    shuffle=False,
):
    db = savee
    train_name, test_name = check_meta_names(e_config, train_name, test_name, db)
    print(train_name, "@{train_name}")
    print(test_name, "@{test_name}")
    import re

    # æ•°æ®é‡ä¸èƒ½å¤ªå°,å¦åˆ™ttsåˆ†å‰²å¯èƒ½ä¼šå› ä¸ºtrain/test setä¸­çš„æŸä¸ªä¼šæ˜¯ç©ºçš„,å¯¼è‡´æŠ¥é”™
    audios = glob(savee_files_glob)
    total = len(audios)
    audios = audios[: int(total * subset_size)]

    from config.EF import categories_savee

    emos = []
    paths = []
    for audio in audios:
        audio_name = os.path.basename(audio)
        name, ext_ = os.path.splitext(audio_name)
        # å®šä¹‰ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºåŒ¹é…å¼€å¤´çš„å•è¯
        pattern = r"[a-zA-Z]+"

        # ä½¿ç”¨ re æ¨¡å—çš„ findall å‡½æ•°æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…é¡¹
        m = re.match(pattern, name)
        # print(audio_name,m)
        # æ‰“å°å‡ºæ‰€æœ‰åŒ¹é…é¡¹çš„å€¼
        emo_code = m.group()
        # print(emo_code)
        emo = categories_savee[emo_code]
        # print(audio,emo)
        paths.append(audio)
        emos.append(emo)

    df = DataFrame({"path": paths, "emotion": emos})
    # emo_bool_mask=df["emotion" ]
    emo_bool_mask = df["emotion"].isin(e_config)
    df = df[emo_bool_mask]
    print(f"{df.shape=}")

    n_samples = len(df)
    if verbose:
        print("[savee] Total files to write:", n_samples)
    # dividing training/testing sets
    test_samples: int = int((1 - train_size) * n_samples)
    train_samples: int = int(train_size * n_samples)
    if verbose:
        print(
            f"[{db}_{e_config}] Training samples:",
            train_samples,
            "\nTesting samples:",
            test_samples,
        )
    # paths=df["path"].tolist()
    # emos=df["emotion"].tolist()

    e_config_paths = df["path"]
    e_config_emos = df["emotion"]
    spl = tts(e_config_paths, e_config_emos, train_size=train_size, shuffle=shuffle)
    X_train, X_test, y_train, y_test = spl
    # df_e_config=

    print(train_name, "@{train_name}")
    print(test_name, "@{test_name}")
    DataFrame({"path": X_train, "emotion": y_train}).to_csv(train_name, index=False)
    DataFrame({"path": X_test, "emotion": y_test}).to_csv(test_name, index=False)
    print("æ–‡ä»¶åˆ›å»ºå®Œæ¯•!")
    return spl


# test
# res=create_savee_csv(e_config=e_config_def)


##


target_debug = []


def create_ravdess_csv(
    e_config=None, train_name=None, test_name=None, train_size=0.75, verbose=1
):
    """
    Reads speech training(RAVDESS) datasets from directory and write it to a metadata CSV file.
    params:
        emotions (list): list of emotions to read from the folder, default is e_config
        train_name (str): the output csv filename for training data, default is 'train_RAVDESS.csv'
        test_name (str): the output csv filename for testing data, default is 'test_RAVDESS.csv'
        verbose (int/bool): verbositiy level, 0 for silence, 1 for info, default is 1
    """
    db = ravdess
    target = {"path": [], "emotion": []}
    # å£°æ˜å¤–éƒ¨å˜é‡,ç”¨äºä¸´æ—¶è°ƒè¯•!
    global target_debug
    target_debug = target

    # è¿™ä¸ªæ•°æ®åº“æ–‡ä»¶æ¯”è¾ƒå¤š,ä¸ºäº†æ•æ·æ€§,æ§åˆ¶åªå¤„ç†ç‰¹å®šæƒ…æ„Ÿçš„æ–‡ä»¶è€Œä¸æ˜¯å…¨éƒ¨æƒ…æ„Ÿæ–‡ä»¶
    # æˆ‘ä»¬å°†TESS,RAVDESSè¯­æ–™åº“æ”¾åœ¨äº†è®­ç»ƒé›†ç›®å½•training
    print("[RAVDESS] files meta extacting...")
    if e_config is None:
        raise ValueError("[RAVDESS] e_config is None")
    for e in e_config:
        # for training speech directory
        ravdess_file_glob_emo = f"{ravdess_files_glob}/*_{e}.wav"
        total_files = glob(ravdess_file_glob_emo)
        for i, path in enumerate(total_files):
            target["path"].append(path)
            target["emotion"].append(e)
        # æç¤ºæ‰€æœ‰è®­ç»ƒé›†æ–‡ä»¶metaå¤„ç†å®Œæ¯•
        if verbose and total_files:
            print(f"There are {len(total_files)} training audio files for category:{e}")
    target = DataFrame(target)
    # print(target)
    # train_name,test_name =file_names(train_name,test_name)
    train_name, test_name = meta_paths_of_db(db, e_config=e_config)
    X_train, X_test = tts(target, test_size=1-train_size, random_state=0)
    print(X_train[:5], "@{X_train}")
    print(train_name, "@{train_name}")
    DataFrame(X_train).to_csv(train_name)
    DataFrame(X_test).to_csv(test_name)
    if verbose:
        print("ravdess db was splited to 2 csv files!")
        print(f"the train/test size rate is:{train_size}:{(1-train_size)}")


# ä¸å¯ä»¥æŒªåˆ°é¡¶éƒ¨,å› ä¸ºä¸‹é¢çš„selectorçš„å®šä¹‰éœ€è¦ç”¨åˆ°ä¸Šé¢å®šä¹‰çš„å‡½æ•°
selector = {
    emodb: create_emodb_csv,
    ravdess: create_ravdess_csv,
    savee: create_savee_csv,
}


def create_csv_by_metaname(meta_file):
    """æ ¹æ®ç»™å®šçš„ç¬¦åˆæœ¬é¡¹ç›®çš„æ–‡ä»¶åæ„é€ è§„èŒƒçš„æ–‡ä»¶å,ç”Ÿæˆå¯¹åº”çš„train/test dataset metadata files

    Parameters
    ----------
    meta_file : str
        æ–‡ä»¶å
    """
    print(meta_file, "@{meta_file}to be create...ğŸ˜‚")
    name = Path(meta_file).name
    # print(name,"@{name}")
    name, ext = os.path.splitext(name)  # æ–‡ä»¶åå»æ‰åç¼€ext
    # ç›´æ¥è§£ææˆä¸‰ä¸ªå­—ç¬¦ä¸²
    # print(name,"@{name}")
    _partitoin, db, emotion_first_letters = name.split("_")

    e_config = extend_emotion_names(emotion_first_letters)

    field_p2 = [db, emotion_first_letters]
    train_name = "_".join(["train"] + field_p2) + ".csv"
    test_name = "_".join(["test"] + field_p2) + ".csv"
    print(f"@create_csv..ğŸˆ{train_name}\n{test_name}")

    selector[db](
        e_config=e_config,
        #   train_name=train_name,
        #   test_name=test_name
    )


def create_meta_csv(
    train_meta_files,
    test_meta_files,
    dbs=None,
    e_config=None,
    verbose=1,
    override_csv=False,
):
    """
    @deprecated
    Write available CSV files in `self.train_desc_files` and `self.test_desc_files`
    determined by `self._set_metadata_filenames()` method.

    ## Note:
    ç¡¬ç¼–ç å®ç°:
    if emodb in train_csv_file:
            write_emodb_csv(
                self.e_config,
                train_name=train_csv_file,
                test_name=test_csv_file,
                verbose=self.verbose,
            )
            if self.verbose:
                print("[I] Generated EMO-DB  CSV meta File")
        elif ravdess in train_csv_file:
            write_ravdess_csv(
                self.e_config,
                train_name=train_csv_file,
                test_name=test_csv_file,
                verbose=self.verbose,
            )
            if self.verbose:
                print("[I] Generated RAVDESS CSV meta File")
    """
    meta_handler_dict = {emodb: create_emodb_csv, ravdess: create_ravdess_csv}
    for train_csv_file, test_csv_file in zip(train_meta_files, test_meta_files):
        # ä½¿ç”¨Pathå¯¹è±¡çš„`/`æ“ä½œç¬¦è¿æ¥è·¯å¾„
        # train_csv_file = (meta_dir / train_csv_file).name
        # test_csv_file = (meta_dir / test_csv_file).name
        # å…¼å®¹æ€§çš„å†™æ³•
        if os.path.isfile(train_csv_file) and os.path.isfile(test_csv_file):
            # file already exists, just skip writing csv files
            if not override_csv:
                continue
        if dbs:
            for db in dbs:
                if meta_handler_dict.get(db) is None:
                    raise ValueError(f"{db} not recognized")
                meta_handler_dict[db](
                    e_config,
                    train_name=train_csv_file,
                    test_name=test_csv_file,
                    verbose=verbose,
                )
                if verbose:
                    print(f"[I] Generated {db} CSV meta File")


##
if __name__ == "__main__":
    # write_emodb_csv(e_config=AHNPS)
    # write_ravdess_csv()
    name1 = "test_emodb_AS.csv"
    # create_csv_by_metaname(name1)
    name2 = "train_savee_AS.csv"
    create_csv_by_metaname(name2)

    ##
    # import numpy as np
    # from sklearn.model_selection import train_test_split

    # M=np.arange(100).reshape(10,10)
    # print(M,"@{M}")
    # X_train,X_test=train_test_split(M,train_size=0.7,shuffle=False)
    # print(X_train,"@{X_train}")
    # print(X_test,"@{X_test}")
