##
import os
import random
from glob import glob
from pathlib import Path

import pandas as pd
from pandas import DataFrame
from sklearn.model_selection import train_test_split as tts

from config.EF import categories_emodb, extend_emotion_names
from config.MetaPath import (
    emodb,
    emodb_files_glob,
    meta_paths_of_db,
    ravdess,
    ravdess_files_glob,
    savee,
    savee_files_glob,
)

emodb_files_glob, ravdess_files_glob, savee_files_glob = [
    str(p) for p in [emodb_files_glob, ravdess_files_glob, savee_files_glob]
]


def check_meta_names(e_config, train_name=None, test_name=None, db=""):
    if train_name is None or test_name is None:
        train_name, test_name = meta_paths_of_db(db, e_config=e_config)
    if db == "":
        raise ValueError("db must be specified non None")
    return train_name, test_name


##
"""
æœ¬æ¨¡å—è´Ÿè´£å°†ä¸åŒçš„è¯­æ–™åº“æ–‡ä»¶çš„å…ƒæ•°æ®(è·¯å¾„å’Œæƒ…æ„Ÿæ ‡ç­¾)ç»Ÿä¸€åŒ–,å¹¶ä¸”ä½œæŒä¹…åŒ–ä¿å­˜å¤„ç†(csvæ–‡ä»¶)
ä¸åŒçš„è¯­æ–™åº“ç”±äºæ–‡ä»¶åè§„èŒƒä¸åŒ,æ‰€ä»¥éœ€è¦åˆ†åˆ«ç¼–å†™å¤„ç†å‡½æ•°
!æ³¨æ„å°å¿ƒä½¿ç”¨os.chdir()æ”¹å˜å·¥ä½œç›®å½•,ç‰¹åˆ«éœ€è¦è®¿é—®ä¸åŒç›®å½•çš„æƒ…å†µ
"""


def create_emodb_meta(
    e_config=None,
    train_name=None,
    test_name=None,
    train_size=0.8,
    verbose=1,
    shuffle=True,
    balance=False,
    sort=True,
):
    """
    Reads speech emodb dataset from directory and write it to a metadata CSV file.

    params:
    -
        emotions (list):
            list of emotions to read from the folder, default is ['sad', 'neutral', 'happy']
        train_name (str):
            the output csv filename for training data, default is 'train_emo.csv'
        test_name (str):
            the output csv filename for testing data, default is 'test_emo.csv'
        train_size (float):
            the ratio of splitting training data, default is 0.8

            - å¯ä»¥è€ƒè™‘ä½¿ç”¨sklearnçš„model_sectionæ¨¡å—æä¾›çš„apiæ¥å®Œæˆæ•°æ®åˆ’åˆ†æ“ä½œ,ä¾‹å¦‚train_test_split()æ–¹æ³•
        verbose (int/bool):
             verbositiy level, 0 for silence, 1 for info, default is 1
    """
    db = emodb

    train_name, test_name = check_meta_names(e_config, train_name, test_name, db)

    target = {"path": [], "emotion": []}
    categories = categories_emodb
    tp = target["path"]
    te = target["emotion"]
    # delete not specified emotions
    # é¢ å€’å­—å…¸ç§çš„é”®å€¼å¯¹ä¸º æƒ…æ„Ÿ:ç¼©å†™(emotion:code)
    # é¢ å€’ä¸æ˜¯å¿…é¡»çš„,è¿™é‡Œé¡ºä¾¿ä¸ºä¹‹,categories_reversedä½œä¸ºä¸´æ—¶çš„å­—å…¸è¾…åŠ©ç­›æ‰ä¸éœ€è¦çš„æƒ…æ„Ÿ
    categories_reversed = {emotion: code for code, emotion in categories.items()}
    if e_config is None:
        raise ValueError(f"e_config is None")
    for emotion, code in categories_reversed.items():
        if emotion not in e_config:
            del categories[code]
    # shuffleå¯ä»¥åœ¨è¿™ä¸ªç¯èŠ‚è¿›è¡Œ:
    files_iter = glob(emodb_files_glob)
    if shuffle:
        random.shuffle(files_iter)

    for file in files_iter:
        try:
            # emodbæ–‡ä»¶å½¢å¦‚`03a01Wa.wav`
            # - 03 è¡¨ç¤ºè¿™ä¸ªéŸ³é¢‘è®°å½•æ¥è‡ªç¬¬3ä½æ¼”å‘˜
            # - a01 è¡¨ç¤ºè¿™ä¸ªéŸ³é¢‘è®°å½•æ˜¯è¯¥æ¼”å‘˜è¡¨æ¼”çš„ç¬¬1ç§æƒ…æ„Ÿ
            # - W è¡¨ç¤ºè¿™ä¸ªæƒ…æ„Ÿæ˜¯â€œæ„¤æ€’â€ï¼ˆAngryï¼‰çš„ç¼©å†™
            # - a è¡¨ç¤ºè¿™ä¸ªæ˜¯è¯¥æƒ…æ„Ÿçš„ç¬¬1ä¸ªå‰¯æœ¬ï¼ˆç¬¬ä¸€ä¸ªè¡¨æ¼”ï¼‰
            # - .wav è¡¨ç¤ºè¿™ä¸ªæ–‡ä»¶çš„æ ¼å¼ä¸º.wavæ ¼å¼
            # æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯ç¬¬6ä¸ªå­—ç¬¦(ä¹Ÿå³æ˜¯[5])
            e = os.path.basename(file)[5]
            emotion: str = categories[e]
            # å¯ä»¥ä½¿ç”¨å­—å…¸çš„getæ–¹æ³•æ¥é¿å…KeyError,ä¸è¿‡è¿™é‡Œæˆ‘ä»¬è€ƒè™‘é€šè¿‡å¼‚å¸¸æŠ›å‡ºåšå‡ºåŠæ—¶çš„åé¦ˆ
        except KeyError:
            # print("key error")
            continue
        tp.append(file)
        te.append(emotion)
        # target['emotion'].append(emotion)
        # target['path'].append(file)
    n_samples = len(target["path"])

    if verbose:
        print("[EMO-DB] Total files to write:", n_samples)

    # dividing training/testing sets
    test_samples: int = int((1 - train_size) * n_samples)
    train_samples: int = int(train_size * n_samples)
    if verbose:
        print(
            f"[{db}_{e_config}] Training samples:",
            train_samples,
            "\nTesting samples:",
            test_samples,
        )

    X_train = target["path"][:train_samples]
    X_test = target["path"][train_samples:]
    y_train = target["emotion"][:train_samples]
    y_test = target["emotion"][train_samples:]
    # print(e_config)

    # train_name=create_tag_name(emodb,partition="train")
    # test_name=create_tag_name(emodb,partition="test")
    # print(X_train,y_train)
    # print(train_name,test_name)
    write_to_csv(train_name, test_name, sort, X_train, X_test, y_train, y_test)


def write_to_csv(train_name, test_name, sort, X_train, X_test, y_train, y_test):
    df_train = DataFrame({"path": X_train, "emotion": y_train})
    df_test = DataFrame({"path": X_test, "emotion": y_test})
    if sort:
        df_train.sort_values(by="emotion").to_csv(train_name)
        df_test.sort_values(by="emotion").to_csv(test_name)


##
def create_savee_meta(
    e_config=None,
    train_name=None,
    test_name=None,
    train_size=0.8,
    verbose=1,
    subset_size=1,
    shuffle=True,
    balance=False,
    sort=True,
):
    db = savee
    train_name, test_name = check_meta_names(e_config, train_name, test_name, db)
    print(train_name, "@{train_name}")
    print(test_name, "@{test_name}")
    import re

    # æ•°æ®é‡ä¸èƒ½å¤ªå°,å¦åˆ™ttsåˆ†å‰²å¯èƒ½ä¼šå› ä¸ºtrain/test setä¸­çš„æŸä¸ªä¼šæ˜¯ç©ºçš„,å¯¼è‡´æŠ¥é”™
    audios = glob(savee_files_glob)
    total = len(audios)
    audios = audios[: int(total * subset_size)]

    from config.EF import categories_savee

    emos = []
    paths = []
    for audio in audios:
        audio_name = os.path.basename(audio)
        name, ext_ = os.path.splitext(audio_name)
        # å®šä¹‰ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºåŒ¹é…å¼€å¤´çš„å•è¯
        pattern = r"[a-zA-Z]+"

        # ä½¿ç”¨ re æ¨¡å—çš„ findall å‡½æ•°æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…é¡¹
        m = re.match(pattern, name)
        # print(audio_name,m)
        # æ‰“å°å‡ºæ‰€æœ‰åŒ¹é…é¡¹çš„å€¼
        emo_code = m.group()
        # print(emo_code)
        emo = categories_savee[emo_code]
        # print(audio,emo)
        paths.append(audio)
        emos.append(emo)

    p_e_df = DataFrame({"path": paths, "emotion": emos})
    # emo_bool_mask=df["emotion"]
    emo_bool_mask = p_e_df["emotion"].isin(e_config)
    p_e_df = p_e_df[emo_bool_mask]
    if verbose:
        print(f"{p_e_df.shape=}")
        n_samples = len(p_e_df)
        print("[savee] Total files to write:", n_samples)
        # dividing training/testing sets
        test_samples: int = int((1 - train_size) * n_samples)
        train_samples: int = int(train_size * n_samples)
        print(
            f"[{db}_{e_config}] Training samples:",
            train_samples,
            "\nTesting samples:",
            test_samples,
        )

    # paths = p_e_df["path"]
    # emotions = p_e_df["emotion"]
    # spl = tts(paths, emotions, train_size=train_size, shuffle=shuffle)
    # X_train, X_test, y_train, y_test = spl

    # DataFrame({"path": X_train, "emotion": y_train}).to_csv(train_name, index=False)
    # DataFrame({"path": X_test, "emotion": y_test}).to_csv(test_name, index=False)
    # write_to_csv(train_name, test_name, sort, X_train, X_test, y_train, y_test)

    spl = tts(p_e_df, train_size=train_size, shuffle=shuffle)
    Xy_train, Xy_test = spl
    from_df_write_to_csv(train_name=train_name, test_name=test_name, sort=sort, Xy_train=Xy_train, Xy_test=Xy_test)

    if verbose:
        print(train_name, "@{train_name}")
        print(test_name, "@{test_name}")
        print("æ–‡ä»¶åˆ›å»ºå®Œæ¯•!")
    return spl


##


def create_ravdess_meta(
    e_config=None,
    train_name=None,
    test_name=None,
    train_size=0.75,
    verbose=1,
    shuffle=True,
    balance=False,
    sort=True,
):
    """
    Reads speech training(RAVDESS) datasets from directory and write it to a metadata CSV file.
    params:
        emotions (list): list of emotions to read from the folder, default is e_config
        train_name (str): the output csv filename for training data,
        test_name (str): the output csv filename for testing data,
        verbose (int/bool): verbositiy level, 0 for silence, 1 for info, default is 1
    """
    db = ravdess
    meta_dict = {"path": [], "emotion": []}

    # è¿™ä¸ªæ•°æ®åº“æ–‡ä»¶æ¯”è¾ƒå¤š,ä¸ºäº†æ•æ·æ€§,æ§åˆ¶åªå¤„ç†ç‰¹å®šæƒ…æ„Ÿçš„æ–‡ä»¶è€Œä¸æ˜¯å…¨éƒ¨æƒ…æ„Ÿæ–‡ä»¶
    # æˆ‘ä»¬å°†TESS,RAVDESSè¯­æ–™åº“æ”¾åœ¨äº†è®­ç»ƒé›†ç›®å½•training
    print(f"{db} files meta extacting...")
    if e_config is None:
        raise ValueError(f"{db}e_config is None")
    for e in e_config:
        # for training speech directory
        ravdess_file_glob_emo = f"{ravdess_files_glob}/*_{e}.wav"
        total_files = glob(ravdess_file_glob_emo)
        for i, path in enumerate(total_files):
            meta_dict["path"].append(path)
            meta_dict["emotion"].append(e)
        # æç¤ºæ‰€æœ‰è®­ç»ƒé›†æ–‡ä»¶metaå¤„ç†å®Œæ¯•
        if verbose and total_files:
            print(f"There are {len(total_files)} training audio files for category:{e}")
    meta_df = DataFrame(meta_dict)
    # print(target)
    train_name, test_name = meta_paths_of_db(db, e_config=e_config)
    Xy_train, Xy_test = tts(
        meta_df, train_size=train_size, random_state=0, shuffle=shuffle
    )
    print(Xy_train[:5], "@{X_train}")
    print(train_name, "@{train_name}")
    from_df_write_to_csv(train_name=train_name, test_name=test_name, sort=sort, Xy_train=Xy_train, Xy_test=Xy_test)

    if verbose:
        print("ravdess db was splited to 2 csv files!")
        print(f"the train/test size rate is:{train_size}:{(1-train_size)}")


def from_df_write_to_csv(train_name="", test_name="", sort=True, Xy_train=None, Xy_test=None):
    train_df = DataFrame(Xy_train)
    test_df = DataFrame(Xy_test)
    if sort:
        sorted_train_df = train_df.sort_values(by="emotion")
        sorted_test_df = test_df.sort_values(by="emotion")
    sorted_train_df.to_csv(train_name)
    sorted_test_df.to_csv(test_name)


# ä¸å¯ä»¥æŒªåˆ°é¡¶éƒ¨,å› ä¸ºä¸‹é¢çš„selectorçš„å®šä¹‰éœ€è¦ç”¨åˆ°ä¸Šé¢å®šä¹‰çš„å‡½æ•°
selector = {
    emodb: create_emodb_meta,
    ravdess: create_ravdess_meta,
    savee: create_savee_meta,
}


def create_csv_by_metaname(meta_file, shuffle=True):
    """æ ¹æ®ç»™å®šçš„ç¬¦åˆæœ¬é¡¹ç›®çš„æ–‡ä»¶åæ„é€ è§„èŒƒçš„æ–‡ä»¶å,ç”Ÿæˆå¯¹åº”çš„train/test dataset metadata files

    Parameters
    ----------
    meta_file : str
        æ–‡ä»¶å
    """
    print(meta_file, "@{meta_file}to be create...ğŸ˜‚")
    name = Path(meta_file).name
    # print(name,"@{name}")
    name, ext = os.path.splitext(name)  # æ–‡ä»¶åå»æ‰åç¼€ext
    # ç›´æ¥è§£ææˆä¸‰ä¸ªå­—ç¬¦ä¸²
    # print(name,"@{name}")
    _partitoin, db, emotion_first_letters = name.split("_")

    e_config = extend_emotion_names(emotion_first_letters)

    field_p2 = [db, emotion_first_letters]
    train_name = "_".join(["train"] + field_p2) + ".csv"
    test_name = "_".join(["test"] + field_p2) + ".csv"
    print(f"@create_csv..ğŸˆ{train_name}\n{test_name}")

    selector[db](
        e_config=e_config,
        shuffle=shuffle,
        #   train_name=train_name,
        #   test_name=test_name
    )


##
if __name__ == "__main__":
    # write_emodb_csv(e_config=AHNPS)
    # write_ravdess_csv()
    name1 = "test_emodb_AS.csv"
    # create_csv_by_metaname(name1)
    name2 = "train_savee_AS.csv"
    name3 = "test_savee_HNS.csv"
    create_csv_by_metaname(name3, shuffle=True)

    ##
    # import numpy as np
    # from sklearn.model_selection import train_test_split

    # M=np.arange(100).reshape(10,10)
    # print(M,"@{M}")
    # X_train,X_test=train_test_split(M,train_size=0.7,shuffle=False)
    # print(X_train,"@{X_train}")
    # print(X_test,"@{X_test}")
