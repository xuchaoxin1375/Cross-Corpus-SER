{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导包@初始化环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utils as u\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    time.sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils 用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'd:\\\\repos\\\\CCSER\\\\emotion-recognition-using-speech\\\\testers\\\\..\\\\utils.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reload(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u.get_label({'mfcc': True, 'chroma': True, 'contrast': True, 'tonnetz': False, 'mel': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AEHS'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = [\"happy\", \"sad\", \"angry\", \"excited\"]\n",
    "u.get_first_letters(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='../data/emodb/wav/03a01Fa.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'd:\\\\repos\\\\CCSER\\\\emotion-recognition-using-speech\\\\testers\\\\..\\\\utils.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=16000\n",
      "mfcc=array([[-5.7949408e+02, -5.8237000e+02, -5.4231409e+02, ...,\n",
      "        -4.4443301e+02, -5.1189877e+02, -5.4893274e+02],\n",
      "       [ 4.2399986e+01,  4.3535309e+01,  4.6660248e+01, ...,\n",
      "         5.7969917e+01,  7.0551956e+01,  5.8467278e+01],\n",
      "       [ 2.6951712e+01,  3.6163773e+01,  2.3005287e+01, ...,\n",
      "        -2.2074558e+01,  2.2972417e+00,  2.3572979e+01],\n",
      "       ...,\n",
      "       [-1.1663159e+00, -3.3620620e-01, -1.5723083e+00, ...,\n",
      "         1.7019060e+00, -2.9701242e+00,  5.5493116e-02],\n",
      "       [-6.7166567e-02,  2.2954333e+00,  2.7009997e+00, ...,\n",
      "         8.9644995e+00,  5.4243727e+00, -1.1835574e+00],\n",
      "       [-1.9514959e+00, -3.3829910e-01, -3.6819839e-01, ...,\n",
      "         3.8285813e+00,  2.4170179e+00,  1.3678563e+00]], dtype=float32),mfcc.shape=(40, 60)\n",
      "mfccT=array([[-5.7949408e+02,  4.2399986e+01,  2.6951712e+01, ...,\n",
      "        -1.1663159e+00, -6.7166567e-02, -1.9514959e+00],\n",
      "       [-5.8237000e+02,  4.3535309e+01,  3.6163773e+01, ...,\n",
      "        -3.3620620e-01,  2.2954333e+00, -3.3829910e-01],\n",
      "       [-5.4231409e+02,  4.6660248e+01,  2.3005287e+01, ...,\n",
      "        -1.5723083e+00,  2.7009997e+00, -3.6819839e-01],\n",
      "       ...,\n",
      "       [-4.4443301e+02,  5.7969917e+01, -2.2074558e+01, ...,\n",
      "         1.7019060e+00,  8.9644995e+00,  3.8285813e+00],\n",
      "       [-5.1189877e+02,  7.0551956e+01,  2.2972417e+00, ...,\n",
      "        -2.9701242e+00,  5.4243727e+00,  2.4170179e+00],\n",
      "       [-5.4893274e+02,  5.8467278e+01,  2.3572979e+01, ...,\n",
      "         5.5493116e-02, -1.1835574e+00,  1.3678563e+00]], dtype=float32),mfccT.shape=(60, 40)\n",
      "mfccs=array([-2.3265572e+02,  7.8358467e+01, -5.6844797e+00,  2.3088652e+01,\n",
      "       -5.6207581e+00,  2.2314150e+00, -1.8465942e+01,  1.8867327e-01,\n",
      "       -8.6601543e+00,  5.2006965e+00, -8.8264589e+00,  1.2440554e+00,\n",
      "       -5.2814021e+00,  4.2053628e+00, -7.8796449e+00, -3.4433046e-01,\n",
      "       -2.1175959e+00, -2.6738899e+00, -3.7475629e+00,  3.4549470e+00,\n",
      "       -5.9737630e+00,  1.6132796e+00, -2.7754409e+00,  1.7341176e-01,\n",
      "       -5.1170844e-01,  1.5065254e+00,  1.7440118e+00,  2.7914314e+00,\n",
      "        3.6510980e+00,  8.7614536e-01,  1.2444402e+00,  2.3279290e+00,\n",
      "       -6.0442883e-01,  3.7340999e+00,  1.1456577e+00,  3.8093462e+00,\n",
      "        3.5860815e+00,  2.7987137e+00,  2.7823951e+00,  1.1447413e+00],\n",
      "      dtype=float32),mfccs.shape=(40,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.32655716e+02,  7.83584671e+01, -5.68447971e+00,  2.30886517e+01,\n",
       "       -5.62075806e+00,  2.23141503e+00, -1.84659424e+01,  1.88673273e-01,\n",
       "       -8.66015434e+00,  5.20069647e+00, -8.82645893e+00,  1.24405539e+00,\n",
       "       -5.28140211e+00,  4.20536280e+00, -7.87964487e+00, -3.44330460e-01,\n",
       "       -2.11759591e+00, -2.67388988e+00, -3.74756289e+00,  3.45494699e+00,\n",
       "       -5.97376299e+00,  1.61327958e+00, -2.77544093e+00,  1.73411757e-01,\n",
       "       -5.11708438e-01,  1.50652540e+00,  1.74401176e+00,  2.79143143e+00,\n",
       "        3.65109801e+00,  8.76145363e-01,  1.24444020e+00,  2.32792902e+00,\n",
       "       -6.04428828e-01,  3.73409986e+00,  1.14565766e+00,  3.80934620e+00,\n",
       "        3.58608150e+00,  2.79871368e+00,  2.78239512e+00,  1.14474130e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.extract_feature(file,mfcc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=16000\n",
      "stft_raw.shape=(1025, 60),stft.shape=(1025, 60)\n",
      "chroma_stft.shape=(12, 60),chroma_stftT.shape=(60, 12),chroma.shape=(12,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55151898, 0.49732938, 0.5180158 , 0.5756461 , 0.63191211,\n",
       "       0.68560082, 0.64491618, 0.63248903, 0.63560939, 0.67582351,\n",
       "       0.68403363, 0.6273756 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(u)\n",
    "u.extract_feature(file,chroma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=16000\n",
      "ms.shape=(128, 60),msT.shape=(60, 128),mel.shape=(128,)\n",
      "msT=array([[1.3702595e-02, 4.8334887e-03, 3.1367345e-03, ..., 4.0915941e-07,\n",
      "        3.0030935e-07, 3.9454810e-07],\n",
      "       [4.0931404e-02, 3.5017228e-03, 1.6344719e-03, ..., 9.6306212e-07,\n",
      "        5.2878028e-07, 2.7619788e-07],\n",
      "       [3.7430242e-02, 8.0639087e-03, 4.5845291e-04, ..., 1.1098733e-06,\n",
      "        5.5781237e-07, 2.3322487e-07],\n",
      "       ...,\n",
      "       [1.3696878e-01, 4.0431842e-03, 3.6065064e-03, ..., 1.4145832e-06,\n",
      "        5.9684714e-07, 2.6765488e-07],\n",
      "       [8.5475467e-02, 8.2362648e-03, 3.6103202e-03, ..., 5.6608536e-07,\n",
      "        3.4306808e-07, 2.3052857e-07],\n",
      "       [1.3893657e-02, 1.1152174e-02, 2.4494857e-03, ..., 1.1090027e-06,\n",
      "        6.6537564e-07, 4.3575008e-07]], dtype=float32),mel=array([2.02190965e-01, 9.42234695e-02, 8.35050568e-02, 1.15309954e+00,\n",
      "       2.08149219e+00, 5.87244225e+00, 1.08359509e+01, 9.20258045e+00,\n",
      "       7.70471621e+00, 9.27942181e+00, 5.89765501e+00, 2.63476801e+00,\n",
      "       3.21952724e+00, 5.13293982e+00, 6.69334698e+00, 5.50343657e+00,\n",
      "       2.16009498e+00, 1.80154860e+00, 2.07818818e+00, 4.68497610e+00,\n",
      "       8.75986862e+00, 8.55774212e+00, 4.34945250e+00, 3.00456738e+00,\n",
      "       5.22798681e+00, 8.79408360e+00, 7.66004276e+00, 6.60274553e+00,\n",
      "       6.97865105e+00, 4.60931730e+00, 3.16913772e+00, 3.07167315e+00,\n",
      "       2.44722605e+00, 1.99680769e+00, 1.56842840e+00, 1.99026978e+00,\n",
      "       3.17184114e+00, 3.22996736e+00, 2.49557900e+00, 3.31981635e+00,\n",
      "       2.23639345e+00, 2.29035211e+00, 1.15435743e+00, 7.28148103e-01,\n",
      "       5.21023452e-01, 5.74118972e-01, 4.87178773e-01, 8.90792429e-01,\n",
      "       5.42437553e-01, 8.40696394e-01, 6.77264452e-01, 8.89451265e-01,\n",
      "       1.08815217e+00, 1.01800644e+00, 1.30157614e+00, 7.36760914e-01,\n",
      "       1.45038104e+00, 1.24527657e+00, 1.69060338e+00, 9.90051568e-01,\n",
      "       1.16433096e+00, 8.83487880e-01, 7.34552443e-01, 5.92934847e-01,\n",
      "       2.92679906e-01, 3.39213729e-01, 4.23782736e-01, 3.75203580e-01,\n",
      "       3.01573128e-01, 2.60645241e-01, 3.13371181e-01, 1.01070903e-01,\n",
      "       8.63920227e-02, 9.34902653e-02, 7.40443096e-02, 5.62398955e-02,\n",
      "       7.99398199e-02, 6.24554642e-02, 5.17884269e-02, 8.25757682e-02,\n",
      "       8.95956755e-02, 1.19542092e-01, 1.28643781e-01, 1.45436049e-01,\n",
      "       1.47147730e-01, 8.67002755e-02, 6.66013509e-02, 5.77272326e-02,\n",
      "       1.31493703e-01, 9.59326476e-02, 7.38408640e-02, 5.45805059e-02,\n",
      "       9.99065414e-02, 1.15539104e-01, 9.31334496e-02, 7.61354938e-02,\n",
      "       1.19826548e-01, 9.77718979e-02, 4.24235649e-02, 6.45968020e-02,\n",
      "       3.46706286e-02, 3.67474779e-02, 6.01864532e-02, 4.96820211e-02,\n",
      "       4.93695885e-02, 3.79836448e-02, 4.89407107e-02, 3.39902900e-02,\n",
      "       4.01794948e-02, 2.75197625e-02, 2.43079048e-02, 2.27993056e-02,\n",
      "       2.25591920e-02, 2.19171364e-02, 2.41834521e-02, 1.80604793e-02,\n",
      "       1.87344532e-02, 1.81910153e-02, 1.83767658e-02, 1.55998552e-02,\n",
      "       1.46187739e-02, 1.45130688e-02, 6.94482913e-03, 6.01974968e-03,\n",
      "       5.09437360e-03, 2.35245144e-03, 7.04454258e-04, 3.61987011e-04],\n",
      "      dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.02190965e-01, 9.42234695e-02, 8.35050568e-02, 1.15309954e+00,\n",
       "       2.08149219e+00, 5.87244225e+00, 1.08359509e+01, 9.20258045e+00,\n",
       "       7.70471621e+00, 9.27942181e+00, 5.89765501e+00, 2.63476801e+00,\n",
       "       3.21952724e+00, 5.13293982e+00, 6.69334698e+00, 5.50343657e+00,\n",
       "       2.16009498e+00, 1.80154860e+00, 2.07818818e+00, 4.68497610e+00,\n",
       "       8.75986862e+00, 8.55774212e+00, 4.34945250e+00, 3.00456738e+00,\n",
       "       5.22798681e+00, 8.79408360e+00, 7.66004276e+00, 6.60274553e+00,\n",
       "       6.97865105e+00, 4.60931730e+00, 3.16913772e+00, 3.07167315e+00,\n",
       "       2.44722605e+00, 1.99680769e+00, 1.56842840e+00, 1.99026978e+00,\n",
       "       3.17184114e+00, 3.22996736e+00, 2.49557900e+00, 3.31981635e+00,\n",
       "       2.23639345e+00, 2.29035211e+00, 1.15435743e+00, 7.28148103e-01,\n",
       "       5.21023452e-01, 5.74118972e-01, 4.87178773e-01, 8.90792429e-01,\n",
       "       5.42437553e-01, 8.40696394e-01, 6.77264452e-01, 8.89451265e-01,\n",
       "       1.08815217e+00, 1.01800644e+00, 1.30157614e+00, 7.36760914e-01,\n",
       "       1.45038104e+00, 1.24527657e+00, 1.69060338e+00, 9.90051568e-01,\n",
       "       1.16433096e+00, 8.83487880e-01, 7.34552443e-01, 5.92934847e-01,\n",
       "       2.92679906e-01, 3.39213729e-01, 4.23782736e-01, 3.75203580e-01,\n",
       "       3.01573128e-01, 2.60645241e-01, 3.13371181e-01, 1.01070903e-01,\n",
       "       8.63920227e-02, 9.34902653e-02, 7.40443096e-02, 5.62398955e-02,\n",
       "       7.99398199e-02, 6.24554642e-02, 5.17884269e-02, 8.25757682e-02,\n",
       "       8.95956755e-02, 1.19542092e-01, 1.28643781e-01, 1.45436049e-01,\n",
       "       1.47147730e-01, 8.67002755e-02, 6.66013509e-02, 5.77272326e-02,\n",
       "       1.31493703e-01, 9.59326476e-02, 7.38408640e-02, 5.45805059e-02,\n",
       "       9.99065414e-02, 1.15539104e-01, 9.31334496e-02, 7.61354938e-02,\n",
       "       1.19826548e-01, 9.77718979e-02, 4.24235649e-02, 6.45968020e-02,\n",
       "       3.46706286e-02, 3.67474779e-02, 6.01864532e-02, 4.96820211e-02,\n",
       "       4.93695885e-02, 3.79836448e-02, 4.89407107e-02, 3.39902900e-02,\n",
       "       4.01794948e-02, 2.75197625e-02, 2.43079048e-02, 2.27993056e-02,\n",
       "       2.25591920e-02, 2.19171364e-02, 2.41834521e-02, 1.80604793e-02,\n",
       "       1.87344532e-02, 1.81910153e-02, 1.83767658e-02, 1.55998552e-02,\n",
       "       1.46187739e-02, 1.45130688e-02, 6.94482913e-03, 6.01974968e-03,\n",
       "       5.09437360e-03, 2.35245144e-03, 7.04454258e-04, 3.61987011e-04])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reload(u)\n",
    "u.extract_feature(file,mel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=16000\n",
      "stft_raw.shape=(1025, 60),stft.shape=(1025, 60)\n",
      "ctrT.shape=(60, 7),contrast.shape=(7,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([19.98351974, 15.98520726, 15.9027028 , 14.82882685, 17.76833269,\n",
       "       16.89691075, 18.98481095])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reload(u)\n",
    "u.extract_feature(file,contrast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=16000\n",
      "har.shape=(30372,),ttzT.shape=(60, 6),tonnetz.shape=(6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00380297,  0.01373861, -0.03871156,  0.00907444, -0.00254424,\n",
       "       -0.00471914])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reload(u)\n",
    "u.extract_feature(file,tonnetz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=16000\n",
      "res.shape=(174,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=512 is too small for input signal of length=475\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.32655716e+02,  7.83584671e+01, -5.68447971e+00,  2.30886517e+01,\n",
       "       -5.62075806e+00,  2.23141503e+00, -1.84659424e+01,  1.88673273e-01,\n",
       "       -8.66015434e+00,  5.20069647e+00, -8.82645893e+00,  1.24405539e+00,\n",
       "       -5.28140211e+00,  4.20536280e+00, -7.87964487e+00, -3.44330460e-01,\n",
       "       -2.11759591e+00, -2.67388988e+00, -3.74756289e+00,  3.45494699e+00,\n",
       "       -5.97376299e+00,  1.61327958e+00, -2.77544093e+00,  1.73411757e-01,\n",
       "       -5.11708438e-01,  1.50652540e+00,  1.74401176e+00,  2.79143143e+00,\n",
       "        3.65109801e+00,  8.76145363e-01,  1.24444020e+00,  2.32792902e+00,\n",
       "       -6.04428828e-01,  3.73409986e+00,  1.14565766e+00,  3.80934620e+00,\n",
       "        3.58608150e+00,  2.79871368e+00,  2.78239512e+00,  1.14474130e+00,\n",
       "        2.02190965e-01,  9.42234695e-02,  8.35050568e-02,  1.15309954e+00,\n",
       "        2.08149219e+00,  5.87244225e+00,  1.08359509e+01,  9.20258045e+00,\n",
       "        7.70471621e+00,  9.27942181e+00,  5.89765501e+00,  2.63476801e+00,\n",
       "        3.21952724e+00,  5.13293982e+00,  6.69334698e+00,  5.50343657e+00,\n",
       "        2.16009498e+00,  1.80154860e+00,  2.07818818e+00,  4.68497610e+00,\n",
       "        8.75986862e+00,  8.55774212e+00,  4.34945250e+00,  3.00456738e+00,\n",
       "        5.22798681e+00,  8.79408360e+00,  7.66004276e+00,  6.60274553e+00,\n",
       "        6.97865105e+00,  4.60931730e+00,  3.16913772e+00,  3.07167315e+00,\n",
       "        2.44722605e+00,  1.99680769e+00,  1.56842840e+00,  1.99026978e+00,\n",
       "        3.17184114e+00,  3.22996736e+00,  2.49557900e+00,  3.31981635e+00,\n",
       "        2.23639345e+00,  2.29035211e+00,  1.15435743e+00,  7.28148103e-01,\n",
       "        5.21023452e-01,  5.74118972e-01,  4.87178773e-01,  8.90792429e-01,\n",
       "        5.42437553e-01,  8.40696394e-01,  6.77264452e-01,  8.89451265e-01,\n",
       "        1.08815217e+00,  1.01800644e+00,  1.30157614e+00,  7.36760914e-01,\n",
       "        1.45038104e+00,  1.24527657e+00,  1.69060338e+00,  9.90051568e-01,\n",
       "        1.16433096e+00,  8.83487880e-01,  7.34552443e-01,  5.92934847e-01,\n",
       "        2.92679906e-01,  3.39213729e-01,  4.23782736e-01,  3.75203580e-01,\n",
       "        3.01573128e-01,  2.60645241e-01,  3.13371181e-01,  1.01070903e-01,\n",
       "        8.63920227e-02,  9.34902653e-02,  7.40443096e-02,  5.62398955e-02,\n",
       "        7.99398199e-02,  6.24554642e-02,  5.17884269e-02,  8.25757682e-02,\n",
       "        8.95956755e-02,  1.19542092e-01,  1.28643781e-01,  1.45436049e-01,\n",
       "        1.47147730e-01,  8.67002755e-02,  6.66013509e-02,  5.77272326e-02,\n",
       "        1.31493703e-01,  9.59326476e-02,  7.38408640e-02,  5.45805059e-02,\n",
       "        9.99065414e-02,  1.15539104e-01,  9.31334496e-02,  7.61354938e-02,\n",
       "        1.19826548e-01,  9.77718979e-02,  4.24235649e-02,  6.45968020e-02,\n",
       "        3.46706286e-02,  3.67474779e-02,  6.01864532e-02,  4.96820211e-02,\n",
       "        4.93695885e-02,  3.79836448e-02,  4.89407107e-02,  3.39902900e-02,\n",
       "        4.01794948e-02,  2.75197625e-02,  2.43079048e-02,  2.27993056e-02,\n",
       "        2.25591920e-02,  2.19171364e-02,  2.41834521e-02,  1.80604793e-02,\n",
       "        1.87344532e-02,  1.81910153e-02,  1.83767658e-02,  1.55998552e-02,\n",
       "        1.46187739e-02,  1.45130688e-02,  6.94482913e-03,  6.01974968e-03,\n",
       "        5.09437360e-03,  2.35245144e-03,  7.04454258e-04,  3.61987011e-04,\n",
       "        3.80297340e-03,  1.37386130e-02, -3.87115613e-02,  9.07443655e-03,\n",
       "       -2.54423918e-03, -4.71913670e-03])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(u)\n",
    "res=u.extract_feature(file,mfcc=True,mel=True,tonnetz=True)\n",
    "print(f'{res.shape=}')\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看最优超参数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf=\"../grid/best_classifiers.pickle\"\n",
    "best_rgr=\"../grid/best_regressors.pickle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DummyClassifier from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DummyRegressor from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator GradientBoostingRegressor from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator KNeighborsRegressor from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MLPRegressor from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "d:\\condaPythonEnvs\\sklearn0.24\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator BaggingRegressor from version 0.24.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle \n",
    "with open(best_clf,'rb') as f:\n",
    "    bclf=pickle.load(f)\n",
    "with open(best_rgr,'rb') as f:\n",
    "    brgr=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 6, list, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bclf),len(bclf),type(brgr),len(brgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(SVC(C=10, gamma=0.001),\n",
       "   {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "   0.9381835473133618),\n",
       "  (RandomForestClassifier(max_depth=7, max_features=0.5, n_estimators=40),\n",
       "   {'max_depth': 7,\n",
       "    'max_features': 0.5,\n",
       "    'min_samples_leaf': 1,\n",
       "    'min_samples_split': 2,\n",
       "    'n_estimators': 40},\n",
       "   0.8854018069424631),\n",
       "  (GradientBoostingClassifier(learning_rate=0.3, max_depth=7, subsample=0.7),\n",
       "   {'learning_rate': 0.3,\n",
       "    'max_depth': 7,\n",
       "    'max_features': None,\n",
       "    'min_samples_leaf': 1,\n",
       "    'min_samples_split': 2,\n",
       "    'n_estimators': 100,\n",
       "    'subsample': 0.7},\n",
       "   0.9476937708036139),\n",
       "  (KNeighborsClassifier(n_neighbors=3, p=1, weights='distance'),\n",
       "   {'n_neighbors': 3, 'p': 1, 'weights': 'distance'},\n",
       "   0.9320019020446981),\n",
       "  (MLPClassifier(alpha=0.01, batch_size=512, hidden_layer_sizes=(300,),\n",
       "                 learning_rate='adaptive', max_iter=400),\n",
       "   {'alpha': 0.01,\n",
       "    'batch_size': 512,\n",
       "    'hidden_layer_sizes': (300,),\n",
       "    'learning_rate': 'adaptive',\n",
       "    'max_iter': 400},\n",
       "   0.9358059914407989),\n",
       "  (BaggingClassifier(max_features=0.5, n_estimators=50),\n",
       "   {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 50},\n",
       "   0.9210651450309082)],\n",
       " [(RandomForestRegressor(max_depth=5, max_features=0.2, min_samples_leaf=2,\n",
       "                         min_samples_split=0.7, n_estimators=10),\n",
       "   {'max_depth': 5,\n",
       "    'max_features': 0.2,\n",
       "    'min_samples_leaf': 2,\n",
       "    'min_samples_split': 0.7,\n",
       "    'n_estimators': 10},\n",
       "   0.6738562803087499),\n",
       "  (GradientBoostingRegressor(learning_rate=0.3, max_depth=7, max_features=2,\n",
       "                             min_samples_leaf=0.5, min_samples_split=0.5,\n",
       "                             n_estimators=40, subsample=0.3),\n",
       "   {'learning_rate': 0.3,\n",
       "    'max_depth': 7,\n",
       "    'max_features': 2,\n",
       "    'min_samples_leaf': 0.5,\n",
       "    'min_samples_split': 0.5,\n",
       "    'n_estimators': 40,\n",
       "    'subsample': 0.3},\n",
       "   0.6747901250197804),\n",
       "  (KNeighborsRegressor(n_neighbors=3, p=5),\n",
       "   {'n_neighbors': 3, 'p': 5, 'weights': 'uniform'},\n",
       "   0.2780155333650341),\n",
       "  (MLPRegressor(alpha=0.005, batch_size=64, hidden_layer_sizes=(400,),\n",
       "                learning_rate='adaptive', max_iter=400),\n",
       "   {'alpha': 0.005,\n",
       "    'batch_size': 64,\n",
       "    'hidden_layer_sizes': (400,),\n",
       "    'learning_rate': 'adaptive',\n",
       "    'max_iter': 400},\n",
       "   0.9169556402367768),\n",
       "  (BaggingRegressor(max_features=1, max_samples=0.1),\n",
       "   {'max_features': 1, 'max_samples': 0.1, 'n_estimators': 10},\n",
       "   0.6521001743540973)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclf,brgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  joblib import load,dump\n",
    "\n",
    "bclf_job=dump(bclf,'../grid/best_clf.joblib')\n",
    "brgr_job=dump(brgr,'../grid/best_rgr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(SVC(C=10, gamma=0.001),\n",
       "   {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "   0.9381835473133618),\n",
       "  (RandomForestClassifier(max_depth=7, max_features=0.5, n_estimators=40),\n",
       "   {'max_depth': 7,\n",
       "    'max_features': 0.5,\n",
       "    'min_samples_leaf': 1,\n",
       "    'min_samples_split': 2,\n",
       "    'n_estimators': 40},\n",
       "   0.8854018069424631),\n",
       "  (GradientBoostingClassifier(learning_rate=0.3, max_depth=7, subsample=0.7),\n",
       "   {'learning_rate': 0.3,\n",
       "    'max_depth': 7,\n",
       "    'max_features': None,\n",
       "    'min_samples_leaf': 1,\n",
       "    'min_samples_split': 2,\n",
       "    'n_estimators': 100,\n",
       "    'subsample': 0.7},\n",
       "   0.9476937708036139),\n",
       "  (KNeighborsClassifier(n_neighbors=3, p=1, weights='distance'),\n",
       "   {'n_neighbors': 3, 'p': 1, 'weights': 'distance'},\n",
       "   0.9320019020446981),\n",
       "  (MLPClassifier(alpha=0.01, batch_size=512, hidden_layer_sizes=(300,),\n",
       "                 learning_rate='adaptive', max_iter=400),\n",
       "   {'alpha': 0.01,\n",
       "    'batch_size': 512,\n",
       "    'hidden_layer_sizes': (300,),\n",
       "    'learning_rate': 'adaptive',\n",
       "    'max_iter': 400},\n",
       "   0.9358059914407989),\n",
       "  (BaggingClassifier(max_features=0.5, n_estimators=50),\n",
       "   {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 50},\n",
       "   0.9210651450309082)],\n",
       " [(RandomForestRegressor(max_depth=5, max_features=0.2, min_samples_leaf=2,\n",
       "                         min_samples_split=0.7, n_estimators=10),\n",
       "   {'max_depth': 5,\n",
       "    'max_features': 0.2,\n",
       "    'min_samples_leaf': 2,\n",
       "    'min_samples_split': 0.7,\n",
       "    'n_estimators': 10},\n",
       "   0.6738562803087499),\n",
       "  (GradientBoostingRegressor(learning_rate=0.3, max_depth=7, max_features=2,\n",
       "                             min_samples_leaf=0.5, min_samples_split=0.5,\n",
       "                             n_estimators=40, subsample=0.3),\n",
       "   {'learning_rate': 0.3,\n",
       "    'max_depth': 7,\n",
       "    'max_features': 2,\n",
       "    'min_samples_leaf': 0.5,\n",
       "    'min_samples_split': 0.5,\n",
       "    'n_estimators': 40,\n",
       "    'subsample': 0.3},\n",
       "   0.6747901250197804),\n",
       "  (KNeighborsRegressor(n_neighbors=3, p=5),\n",
       "   {'n_neighbors': 3, 'p': 5, 'weights': 'uniform'},\n",
       "   0.2780155333650341),\n",
       "  (MLPRegressor(alpha=0.005, batch_size=64, hidden_layer_sizes=(400,),\n",
       "                learning_rate='adaptive', max_iter=400),\n",
       "   {'alpha': 0.005,\n",
       "    'batch_size': 64,\n",
       "    'hidden_layer_sizes': (400,),\n",
       "    'learning_rate': 'adaptive',\n",
       "    'max_iter': 400},\n",
       "   0.9169556402367768),\n",
       "  (BaggingRegressor(max_features=1, max_samples=0.1),\n",
       "   {'max_features': 1, 'max_samples': 0.1, 'n_estimators': 10},\n",
       "   0.6521001743540973)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load('../grid/best_clf.joblib'),load('../grid/best_rgr.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SVC(C=10, gamma=0.001), {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}, 0.9381835473133618)\n",
      "(RandomForestClassifier(max_depth=7, max_features=0.5, n_estimators=40), {'max_depth': 7, 'max_features': 0.5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 40}, 0.8854018069424631)\n",
      "(GradientBoostingClassifier(learning_rate=0.3, max_depth=7, subsample=0.7), {'learning_rate': 0.3, 'max_depth': 7, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.7}, 0.9476937708036139)\n",
      "(KNeighborsClassifier(n_neighbors=3, p=1, weights='distance'), {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}, 0.9320019020446981)\n",
      "(MLPClassifier(alpha=0.01, batch_size=512, hidden_layer_sizes=(300,),\n",
      "              learning_rate='adaptive', max_iter=400), {'alpha': 0.01, 'batch_size': 512, 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive', 'max_iter': 400}, 0.9358059914407989)\n",
      "(BaggingClassifier(max_features=0.5, n_estimators=50), {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 50}, 0.9210651450309082)\n"
     ]
    }
   ],
   "source": [
    "for item in bclf:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RandomForestRegressor(max_depth=5, max_features=0.2, min_samples_leaf=2,\n",
      "                      min_samples_split=0.7, n_estimators=10), {'max_depth': 5, 'max_features': 0.2, 'min_samples_leaf': 2, 'min_samples_split': 0.7, 'n_estimators': 10}, 0.6738562803087499)\n",
      "(GradientBoostingRegressor(learning_rate=0.3, max_depth=7, max_features=2,\n",
      "                          min_samples_leaf=0.5, min_samples_split=0.5,\n",
      "                          n_estimators=40, subsample=0.3), {'learning_rate': 0.3, 'max_depth': 7, 'max_features': 2, 'min_samples_leaf': 0.5, 'min_samples_split': 0.5, 'n_estimators': 40, 'subsample': 0.3}, 0.6747901250197804)\n",
      "(KNeighborsRegressor(n_neighbors=3, p=5), {'n_neighbors': 3, 'p': 5, 'weights': 'uniform'}, 0.2780155333650341)\n",
      "(MLPRegressor(alpha=0.005, batch_size=64, hidden_layer_sizes=(400,),\n",
      "             learning_rate='adaptive', max_iter=400), {'alpha': 0.005, 'batch_size': 64, 'hidden_layer_sizes': (400,), 'learning_rate': 'adaptive', 'max_iter': 400}, 0.9169556402367768)\n",
      "(BaggingRegressor(max_features=1, max_samples=0.1), {'max_features': 1, 'max_samples': 0.1, 'n_estimators': 10}, 0.6521001743540973)\n"
     ]
    }
   ],
   "source": [
    "for item in brgr:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BaggingRegressor(max_features=1, max_samples=0.1),\n",
       " {'max_features': 1, 'max_samples': 0.1, 'n_estimators': 10},\n",
       " 0.6521001743540973)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag=brgr[-1]\n",
    "bag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打印函数帮助文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function extract_feature in module utils:\n",
      "\n",
      "extract_feature(file_name, **kwargs)\n",
      "    Extract feature from audio file `file_name`\n",
      "        Features supported:\n",
      "            - MFCC (mfcc)\n",
      "            - Chroma (chroma)\n",
      "            - MEL Spectrogram Frequency (mel)\n",
      "            - Contrast (contrast)\n",
      "            - Tonnetz (tonnetz)\n",
      "        e.g:\n",
      "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# u.extract_feature.__doc__\n",
    "# help(u.extract_feature)\n",
    "u.extract_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('readme.md', '')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file='readme.md'\n",
    "file=''\n",
    "os.path.basename(file),os.path.dirname(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('D:/repos/CCSER/emotion-recognition-using-speech/testers'),\n",
       " WindowsPath('D:/repos/CCSER/emotion-recognition-using-speech/testers/utils'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "dir1=Path(\".\")\n",
    "dir2=Path('./results/../utils/')\n",
    "dir1.resolve(strict=True),dir2.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\repos\\CCSER\\emotion-recognition-using-speech\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\repos\\\\CCSER\\\\emotion-recognition-using-speech'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd D:\\repos\\CCSER\\emotion-recognition-using-speech\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text file contents'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Path('my_text_file')\n",
    "p.write_text('Text file contents')\n",
    "\n",
    "p.read_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Binary file contents'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Path('my_binary_file')\n",
    "p.write_bytes(b'Binary file contents')\n",
    "p.read_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data\\\\emodb\\\\wav', '03a01Fa.wav', '03a01Fa', '.wav')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name='utils.py'\n",
    "file_name=r'data\\emodb\\wav\\03a01Fa.wav'\n",
    "basename = os.path.basename(file_name)#name.ext\n",
    "dirname  = os.path.dirname(file_name)\n",
    "name, ext = os.path.splitext(basename)\n",
    "dirname,basename,name,ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03a01Fa_c.wav'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_basename = f\"{name}_c.wav\"\n",
    "new_basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\system32\\cmd.exe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cmd_path = os.environ['ComSpec']\n",
    "print(cmd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['ls', '-l'], stdout=subprocess.PIPE)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['ls', '-l'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/repos/CCSER/emotion-recognition-using-speech/testers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run([\"pwd\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(result.stdout.decode(\"utf-8\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argparse@python脚本命令行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这段代码放入文件中(比如文件prog1.py),然后用命令行中使用py prog1.py输入需要的参数体验\n",
    "import argparse\n",
    "\n",
    "# 创建一个ArgumentParser对象\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# 添加一个可选参数\n",
    "parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\", help=\"verbose mode\")\n",
    "\n",
    "# 解析命令行参数\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 打印可选参数的值\n",
    "if args.verbose:\n",
    "    print(\"Verbose mode is on\")\n",
    "else:\n",
    "    print(\"Verbose mode is off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: prog1.py [-h] [--verbose]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help     show this help message and exit\n",
      "  --verbose, -v  verbose mode\n"
     ]
    }
   ],
   "source": [
    "!python prog1.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose mode is off\n"
     ]
    }
   ],
   "source": [
    "!python prog1.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose mode is on\n"
     ]
    }
   ],
   "source": [
    "!python prog1.py -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
