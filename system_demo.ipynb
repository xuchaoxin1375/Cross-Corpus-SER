{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   0%|          | 1/2374 [00:00<04:02,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   0%|          | 5/2374 [00:00<03:22, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   0%|          | 7/2374 [00:00<03:15, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   0%|          | 9/2374 [00:00<03:44, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|          | 12/2374 [00:01<04:34,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|          | 15/2374 [00:01<04:16,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|          | 17/2374 [00:01<04:06,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|          | 18/2374 [00:01<04:17,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|          | 20/2374 [00:02<04:22,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|          | 24/2374 [00:02<04:02,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|          | 26/2374 [00:02<03:50, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|▏         | 30/2374 [00:03<03:32, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|▏         | 32/2374 [00:03<03:30, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   1%|▏         | 34/2374 [00:03<03:44, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 36/2374 [00:03<04:22,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 37/2374 [00:03<04:25,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 39/2374 [00:04<04:58,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 41/2374 [00:04<05:01,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 43/2374 [00:04<04:56,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 45/2374 [00:04<04:29,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 47/2374 [00:05<04:36,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 50/2374 [00:05<04:13,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 51/2374 [00:05<04:16,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 53/2374 [00:05<04:37,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   2%|▏         | 56/2374 [00:06<04:08,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   3%|▎         | 60/2374 [00:06<03:26, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   3%|▎         | 64/2374 [00:06<03:00, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   3%|▎         | 66/2374 [00:06<03:14, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   3%|▎         | 68/2374 [00:07<03:28, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   3%|▎         | 70/2374 [00:07<03:45, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   3%|▎         | 74/2374 [00:07<03:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   3%|▎         | 78/2374 [00:08<03:40, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   3%|▎         | 80/2374 [00:08<03:31, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▎         | 84/2374 [00:08<03:15, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▎         | 86/2374 [00:08<03:10, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▎         | 88/2374 [00:08<03:49,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▍         | 90/2374 [00:09<04:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▍         | 92/2374 [00:09<04:01,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▍         | 95/2374 [00:09<03:47, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▍         | 97/2374 [00:09<03:45, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▍         | 99/2374 [00:10<03:59,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▍         | 101/2374 [00:10<04:21,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▍         | 103/2374 [00:10<04:47,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   4%|▍         | 105/2374 [00:10<04:14,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▍         | 107/2374 [00:11<04:18,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▍         | 109/2374 [00:11<04:21,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▍         | 110/2374 [00:11<04:20,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▍         | 113/2374 [00:11<04:47,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▍         | 115/2374 [00:12<05:02,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▍         | 117/2374 [00:12<05:36,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▌         | 119/2374 [00:12<04:46,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▌         | 122/2374 [00:12<04:25,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▌         | 126/2374 [00:13<03:52,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   5%|▌         | 128/2374 [00:13<04:02,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▌         | 132/2374 [00:13<03:19, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▌         | 134/2374 [00:14<03:18, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▌         | 136/2374 [00:14<03:35, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▌         | 139/2374 [00:14<04:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▌         | 141/2374 [00:14<03:49,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▌         | 145/2374 [00:15<03:40, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▌         | 147/2374 [00:15<03:40, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▋         | 149/2374 [00:15<03:35, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▋         | 151/2374 [00:15<03:34, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   6%|▋         | 154/2374 [00:16<03:55,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 156/2374 [00:16<04:23,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 158/2374 [00:16<04:26,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 160/2374 [00:16<04:05,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 161/2374 [00:16<04:15,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 163/2374 [00:17<05:13,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 165/2374 [00:17<04:44,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 167/2374 [00:17<04:19,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 169/2374 [00:18<04:38,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 171/2374 [00:18<05:04,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 172/2374 [00:18<04:56,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 174/2374 [00:18<05:02,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 176/2374 [00:19<05:08,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   7%|▋         | 178/2374 [00:19<04:20,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 181/2374 [00:19<04:08,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 183/2374 [00:19<04:19,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 185/2374 [00:20<05:02,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 186/2374 [00:20<05:16,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 188/2374 [00:20<05:24,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 190/2374 [00:20<04:53,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 192/2374 [00:21<04:46,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 195/2374 [00:21<03:58,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 197/2374 [00:21<03:47,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 199/2374 [00:21<03:32, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   8%|▊         | 201/2374 [00:21<03:47,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▊         | 203/2374 [00:22<04:17,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▊         | 205/2374 [00:22<04:27,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▊         | 207/2374 [00:22<05:21,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▉         | 208/2374 [00:22<05:31,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▉         | 210/2374 [00:23<05:23,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▉         | 212/2374 [00:23<05:13,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▉         | 214/2374 [00:23<05:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▉         | 217/2374 [00:24<04:08,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▉         | 218/2374 [00:24<04:10,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▉         | 220/2374 [00:24<04:18,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:   9%|▉         | 223/2374 [00:24<03:44,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|▉         | 226/2374 [00:25<03:54,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|▉         | 228/2374 [00:25<04:09,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|▉         | 230/2374 [00:25<04:42,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|▉         | 232/2374 [00:25<04:52,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|▉         | 234/2374 [00:26<04:31,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|▉         | 236/2374 [00:26<04:23,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|█         | 238/2374 [00:26<04:02,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|█         | 240/2374 [00:26<04:05,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|█         | 242/2374 [00:26<03:44,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|█         | 245/2374 [00:27<03:45,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|█         | 247/2374 [00:27<04:03,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  10%|█         | 249/2374 [00:27<04:12,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 251/2374 [00:28<04:37,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 253/2374 [00:28<04:57,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 255/2374 [00:28<04:34,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 257/2374 [00:28<04:05,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 259/2374 [00:29<04:05,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 261/2374 [00:29<03:58,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 263/2374 [00:29<04:03,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 265/2374 [00:29<03:50,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█         | 267/2374 [00:29<03:40,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█▏        | 270/2374 [00:30<03:40,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  11%|█▏        | 272/2374 [00:30<03:23, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 275/2374 [00:30<03:38,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 277/2374 [00:30<04:10,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 280/2374 [00:31<03:53,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 281/2374 [00:31<03:54,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 283/2374 [00:31<04:17,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 285/2374 [00:31<04:10,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 287/2374 [00:32<03:51,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 289/2374 [00:32<03:51,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 292/2374 [00:32<04:11,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 294/2374 [00:33<04:49,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  12%|█▏        | 296/2374 [00:33<04:51,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 298/2374 [00:33<05:24,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 299/2374 [00:33<05:13,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 301/2374 [00:34<04:59,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 303/2374 [00:34<04:59,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 305/2374 [00:34<04:39,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 307/2374 [00:34<04:16,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 309/2374 [00:35<04:33,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 311/2374 [00:35<04:40,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 313/2374 [00:35<04:39,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 315/2374 [00:35<04:39,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n",
      "sample_rate=48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features for train:  13%|█▎        | 316/2374 [00:36<03:54,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate=48000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m rec \u001b[39m=\u001b[39m EmotionRecognizer(model\u001b[39m=\u001b[39mmy_model, emotions\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39msad\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhappy\u001b[39m\u001b[39m'\u001b[39m], balance\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m rec\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     10\u001b[0m \u001b[39m# check the test accuracy for that model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest score:\u001b[39m\u001b[39m\"\u001b[39m, rec\u001b[39m.\u001b[39mtest_score())\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\emotion_recognition.py:212\u001b[0m, in \u001b[0;36mEmotionRecognizer.train\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39mTrain the model, if data isn't loaded, it 'll be loaded automatically\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loaded:\n\u001b[0;32m    211\u001b[0m     \u001b[39m# if data isn't loaded yet, load it then\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_data()\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_trained:\n\u001b[0;32m    214\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train, y\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train)\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\emotion_recognition.py:192\u001b[0m, in \u001b[0;36mEmotionRecognizer.load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39m# 判断是否已经导入过数据.如果已经导入,则跳过,否则执行导入\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loaded:\n\u001b[0;32m    191\u001b[0m     \u001b[39m# 调用data_extractor中的数据导入函数\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m     result \u001b[39m=\u001b[39m load_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_desc_files, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_desc_files, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maudio_config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassification,\n\u001b[0;32m    193\u001b[0m                         emotions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memotions, balance\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbalance)\n\u001b[0;32m    194\u001b[0m     \u001b[39m# 设置实例的各个属性\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\data_extractor.py:304\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(train_desc_files, test_desc_files, audio_config, classification, shuffle, balance, emotions)\u001b[0m\n\u001b[0;32m    301\u001b[0m ae \u001b[39m=\u001b[39m AudioExtractor(audio_config\u001b[39m=\u001b[39maudio_config, classification\u001b[39m=\u001b[39mclassification,\n\u001b[0;32m    302\u001b[0m                            emotions\u001b[39m=\u001b[39memotions,balance\u001b[39m=\u001b[39mbalance, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    303\u001b[0m \u001b[39m# Loads training data\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m ae\u001b[39m.\u001b[39;49mload_train_data(train_desc_files, shuffle\u001b[39m=\u001b[39;49mshuffle)\n\u001b[0;32m    305\u001b[0m \u001b[39m# Loads testing data\u001b[39;00m\n\u001b[0;32m    306\u001b[0m ae\u001b[39m.\u001b[39mload_test_data(test_desc_files, shuffle\u001b[39m=\u001b[39mshuffle)\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\data_extractor.py:171\u001b[0m, in \u001b[0;36mAudioExtractor.load_train_data\u001b[1;34m(self, desc_files, shuffle)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_train_data\u001b[39m(\u001b[39mself\u001b[39m, desc_files:\u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtrain_speech.csv\u001b[39m\u001b[39m\"\u001b[39m], shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    168\u001b[0m     \u001b[39m\"\"\"Loads training data from the metadata files `desc_files`\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m    默认导入一个文件\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_data(desc_files, \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, shuffle)\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\data_extractor.py:154\u001b[0m, in \u001b[0;36mAudioExtractor._load_data\u001b[1;34m(self, desc_files, partition, shuffle)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_data\u001b[39m(\u001b[39mself\u001b[39m, desc_files, partition, shuffle):\n\u001b[0;32m    150\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39m    本函数通常不直接提供给外部调用(是一个私有方法)\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[39m    AE对象在如数据集后可选的数据处理操作(balance&shuffle)\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_metadata_from_desc_file(desc_files, partition)\n\u001b[0;32m    155\u001b[0m     \u001b[39m# balancing the datasets ( both training or testing )\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m partition \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbalance:\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\data_extractor.py:103\u001b[0m, in \u001b[0;36mAudioExtractor.load_metadata_from_desc_file\u001b[1;34m(self, desc_files, partition)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m# append = features.append\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m# 特征提取是一个比较耗时的过程,特征种类越多越耗时,这里采用tqdm显示特征提取进度条(已处理文件/文件总数)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m audio_file \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(audio_paths_csv, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting features for \u001b[39m\u001b[39m{\u001b[39;00mpartition\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    102\u001b[0m     \u001b[39m# 调用utils模块中的extract_featrue进行特征提取\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     feature \u001b[39m=\u001b[39m extract_feature(audio_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_config)\n\u001b[0;32m    104\u001b[0m     \u001b[39m# 默认设置input_dimension为feature.shape[0]\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dimension \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\utils_improving.py:136\u001b[0m, in \u001b[0;36mextract_feature\u001b[1;34m(file_name, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([])\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m mfcc:\n\u001b[1;32m--> 136\u001b[0m     mfcc\u001b[39m=\u001b[39mlibrosa\u001b[39m.\u001b[39;49mfeature\u001b[39m.\u001b[39;49mmfcc(y\u001b[39m=\u001b[39;49mX, sr\u001b[39m=\u001b[39;49msample_rate, n_mfcc\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m)\n\u001b[0;32m    137\u001b[0m     \u001b[39m#shape=(40,60)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[39m# 当调用librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)时，返回一个形状为(40, T)的二维数组，其中T表示输入音频信号的帧数。\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[39m# 每一列代表一个音频帧的40个MFCC系数(每一行表示一个音频文件的T个帧的第i个mfcc系数(i=1,2,..,40)，这些系数已经进行了离散余弦变换（DCT）以减少维度并增强特征。\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[39m# MFCC系数在音频信号处理中非常有用，因为它们能够捕捉音频信号的许多特征，例如说话人的身份、音调、声音的强度、语速等等。在语音识别中，MFCC系数通常被用来训练模型，以识别不同的语音单元（如音素）。\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     mfccT\u001b[39m=\u001b[39mmfcc\u001b[39m.\u001b[39mT\u001b[39m#shape=(60,40)\u001b[39;00m\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\librosa\\feature\\spectral.py:1903\u001b[0m, in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[0;32m   1784\u001b[0m \u001b[39m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m \n\u001b[0;32m   1786\u001b[0m \u001b[39m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1898\u001b[0m \u001b[39m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1901\u001b[0m \u001b[39mif\u001b[39;00m S \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1902\u001b[0m     \u001b[39m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[1;32m-> 1903\u001b[0m     S \u001b[39m=\u001b[39m power_to_db(melspectrogram(y\u001b[39m=\u001b[39my, sr\u001b[39m=\u001b[39msr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m   1905\u001b[0m M \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mfftpack\u001b[39m.\u001b[39mdct(S, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mdct_type, norm\u001b[39m=\u001b[39mnorm)[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :n_mfcc, :]\n\u001b[0;32m   1907\u001b[0m \u001b[39mif\u001b[39;00m lifter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1908\u001b[0m     \u001b[39m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\librosa\\feature\\spectral.py:2043\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   1922\u001b[0m \u001b[39m@deprecate_positional_args\u001b[39m\n\u001b[0;32m   1923\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmelspectrogram\u001b[39m(\n\u001b[0;32m   1924\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1935\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1936\u001b[0m ):\n\u001b[0;32m   1937\u001b[0m     \u001b[39m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \n\u001b[0;32m   1939\u001b[0m \u001b[39m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2040\u001b[0m \u001b[39m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[0;32m   2041\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2043\u001b[0m     S, n_fft \u001b[39m=\u001b[39m _spectrogram(\n\u001b[0;32m   2044\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   2045\u001b[0m         S\u001b[39m=\u001b[39;49mS,\n\u001b[0;32m   2046\u001b[0m         n_fft\u001b[39m=\u001b[39;49mn_fft,\n\u001b[0;32m   2047\u001b[0m         hop_length\u001b[39m=\u001b[39;49mhop_length,\n\u001b[0;32m   2048\u001b[0m         power\u001b[39m=\u001b[39;49mpower,\n\u001b[0;32m   2049\u001b[0m         win_length\u001b[39m=\u001b[39;49mwin_length,\n\u001b[0;32m   2050\u001b[0m         window\u001b[39m=\u001b[39;49mwindow,\n\u001b[0;32m   2051\u001b[0m         center\u001b[39m=\u001b[39;49mcenter,\n\u001b[0;32m   2052\u001b[0m         pad_mode\u001b[39m=\u001b[39;49mpad_mode,\n\u001b[0;32m   2053\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m     \u001b[39m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m   2056\u001b[0m     mel_basis \u001b[39m=\u001b[39m filters\u001b[39m.\u001b[39mmel(sr\u001b[39m=\u001b[39msr, n_fft\u001b[39m=\u001b[39mn_fft, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\librosa\\core\\spectrum.py:2564\u001b[0m, in \u001b[0;36m_spectrogram\u001b[1;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[0;32m   2559\u001b[0m         n_fft \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m (S\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m   2560\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2561\u001b[0m     \u001b[39m# Otherwise, compute a magnitude spectrogram from input\u001b[39;00m\n\u001b[0;32m   2562\u001b[0m     S \u001b[39m=\u001b[39m (\n\u001b[0;32m   2563\u001b[0m         np\u001b[39m.\u001b[39mabs(\n\u001b[1;32m-> 2564\u001b[0m             stft(\n\u001b[0;32m   2565\u001b[0m                 y,\n\u001b[0;32m   2566\u001b[0m                 n_fft\u001b[39m=\u001b[39;49mn_fft,\n\u001b[0;32m   2567\u001b[0m                 hop_length\u001b[39m=\u001b[39;49mhop_length,\n\u001b[0;32m   2568\u001b[0m                 win_length\u001b[39m=\u001b[39;49mwin_length,\n\u001b[0;32m   2569\u001b[0m                 center\u001b[39m=\u001b[39;49mcenter,\n\u001b[0;32m   2570\u001b[0m                 window\u001b[39m=\u001b[39;49mwindow,\n\u001b[0;32m   2571\u001b[0m                 pad_mode\u001b[39m=\u001b[39;49mpad_mode,\n\u001b[0;32m   2572\u001b[0m             )\n\u001b[0;32m   2573\u001b[0m         )\n\u001b[0;32m   2574\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m power\n\u001b[0;32m   2575\u001b[0m     )\n\u001b[0;32m   2577\u001b[0m \u001b[39mreturn\u001b[39;00m S, n_fft\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\librosa\\core\\spectrum.py:254\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mfor\u001b[39;00m bl_s \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, stft_matrix\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], n_columns):\n\u001b[0;32m    252\u001b[0m     bl_t \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(bl_s \u001b[39m+\u001b[39m n_columns, stft_matrix\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m--> 254\u001b[0m     stft_matrix[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, bl_s:bl_t] \u001b[39m=\u001b[39m fft\u001b[39m.\u001b[39mrfft(\n\u001b[0;32m    255\u001b[0m         fft_window \u001b[39m*\u001b[39m y_frames[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, bl_s:bl_t], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m stft_matrix\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from emotion_recognition import EmotionRecognizer\n",
    "from sklearn.svm import SVC\n",
    "# init a model, let's use SVC\n",
    "my_model = SVC()\n",
    "# pass my model to EmotionRecognizer instance\n",
    "# and balance the dataset\n",
    "rec = EmotionRecognizer(model=my_model, emotions=['sad', 'neutral', 'happy'], balance=True, verbose=0)\n",
    "# train the model\n",
    "rec.train()\n",
    "# check the test accuracy for that model\n",
    "print(\"Test score:\", rec.test_score())\n",
    "# check the train accuracy for that model\n",
    "print(\"Train score:\", rec.train_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'deep_emotion_recognition' from 'd:\\\\repos\\\\CCSER\\\\SER\\\\deep_emotion_recognition.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deep_emotion_recognition\n",
    "from deep_emotion_recognition import DeepEmotionRecognizer\n",
    "from importlib import reload\n",
    "reload(deep_emotion_recognition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAVDESS] There are 809 training audio files for category:angry\n",
      "[RAVDESS] There are 148 testing audio files for category:angry\n",
      "[RAVDESS] There are 813 training audio files for category:sad\n",
      "[RAVDESS] There are 147 testing audio files for category:sad\n",
      "[RAVDESS] There are 586 training audio files for category:neutral\n",
      "[RAVDESS] There are 94 testing audio files for category:neutral\n",
      "[RAVDESS] There are 514 training audio files for category:ps\n",
      "[RAVDESS] There are 78 testing audio files for category:ps\n",
      "[RAVDESS] There are 806 training audio files for category:happy\n",
      "[RAVDESS] There are 148 testing audio files for category:happy\n",
      "[+] Generated RAVDESS DB CSV File\n",
      "[EMO-DB] Total files to write: 339\n",
      "[EMO-DB] Training samples: 271\n",
      "[EMO-DB] Testing samples: 67\n",
      "[+] Generated EMO-DB CSV File\n",
      "[+] Data loaded\n",
      "[+] Model created\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6773 - accuracy: 0.2148\n",
      "Epoch 1: val_loss improved from inf to 1.63672, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1.6773 - accuracy: 0.2148 - val_loss: 1.6367 - val_accuracy: 0.2000\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6947 - accuracy: 0.2039\n",
      "Epoch 2: val_loss improved from 1.63672 to 1.61012, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 1.6947 - accuracy: 0.2039 - val_loss: 1.6101 - val_accuracy: 0.2667\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6464 - accuracy: 0.2121\n",
      "Epoch 3: val_loss improved from 1.61012 to 1.60011, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 1.6464 - accuracy: 0.2121 - val_loss: 1.6001 - val_accuracy: 0.2513\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6257 - accuracy: 0.2331\n",
      "Epoch 4: val_loss improved from 1.60011 to 1.59723, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6257 - accuracy: 0.2331 - val_loss: 1.5972 - val_accuracy: 0.2692\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6173 - accuracy: 0.2261\n",
      "Epoch 5: val_loss improved from 1.59723 to 1.59301, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 1.6173 - accuracy: 0.2261 - val_loss: 1.5930 - val_accuracy: 0.2692\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6083 - accuracy: 0.2339\n",
      "Epoch 6: val_loss improved from 1.59301 to 1.58504, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6083 - accuracy: 0.2339 - val_loss: 1.5850 - val_accuracy: 0.2667\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5930 - accuracy: 0.2572\n",
      "Epoch 7: val_loss improved from 1.58504 to 1.57396, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 1.5930 - accuracy: 0.2572 - val_loss: 1.5740 - val_accuracy: 0.2846\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5902 - accuracy: 0.2490\n",
      "Epoch 8: val_loss improved from 1.57396 to 1.56393, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 1.5902 - accuracy: 0.2490 - val_loss: 1.5639 - val_accuracy: 0.3385\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5706 - accuracy: 0.2735\n",
      "Epoch 9: val_loss improved from 1.56393 to 1.55596, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 1.5706 - accuracy: 0.2735 - val_loss: 1.5560 - val_accuracy: 0.4026\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5645 - accuracy: 0.2732\n",
      "Epoch 10: val_loss improved from 1.55596 to 1.54928, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 1.5645 - accuracy: 0.2732 - val_loss: 1.5493 - val_accuracy: 0.3692\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5525 - accuracy: 0.3023\n",
      "Epoch 11: val_loss improved from 1.54928 to 1.54248, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 1.5525 - accuracy: 0.3023 - val_loss: 1.5425 - val_accuracy: 0.3615\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5422 - accuracy: 0.3128\n",
      "Epoch 12: val_loss improved from 1.54248 to 1.53360, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 1.5422 - accuracy: 0.3128 - val_loss: 1.5336 - val_accuracy: 0.3718\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5222 - accuracy: 0.3428\n",
      "Epoch 13: val_loss improved from 1.53360 to 1.52108, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 1.5222 - accuracy: 0.3428 - val_loss: 1.5211 - val_accuracy: 0.3949\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5142 - accuracy: 0.3436\n",
      "Epoch 14: val_loss improved from 1.52108 to 1.50741, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 1.5142 - accuracy: 0.3436 - val_loss: 1.5074 - val_accuracy: 0.4282\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5006 - accuracy: 0.3459\n",
      "Epoch 15: val_loss improved from 1.50741 to 1.49366, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 1.5006 - accuracy: 0.3459 - val_loss: 1.4937 - val_accuracy: 0.4308\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4811 - accuracy: 0.3494\n",
      "Epoch 16: val_loss improved from 1.49366 to 1.48143, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 1.4811 - accuracy: 0.3494 - val_loss: 1.4814 - val_accuracy: 0.4077\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4681 - accuracy: 0.3642\n",
      "Epoch 17: val_loss improved from 1.48143 to 1.47268, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 1.4681 - accuracy: 0.3642 - val_loss: 1.4727 - val_accuracy: 0.3949\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4534 - accuracy: 0.3696\n",
      "Epoch 18: val_loss improved from 1.47268 to 1.46059, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 1.4534 - accuracy: 0.3696 - val_loss: 1.4606 - val_accuracy: 0.3923\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4380 - accuracy: 0.3767\n",
      "Epoch 19: val_loss improved from 1.46059 to 1.44189, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4380 - accuracy: 0.3767 - val_loss: 1.4419 - val_accuracy: 0.4103\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4173 - accuracy: 0.3992\n",
      "Epoch 20: val_loss improved from 1.44189 to 1.42462, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4173 - accuracy: 0.3992 - val_loss: 1.4246 - val_accuracy: 0.4154\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4162 - accuracy: 0.3883\n",
      "Epoch 21: val_loss improved from 1.42462 to 1.41191, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 1.4162 - accuracy: 0.3883 - val_loss: 1.4119 - val_accuracy: 0.4308\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3929 - accuracy: 0.4043\n",
      "Epoch 22: val_loss improved from 1.41191 to 1.39485, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3929 - accuracy: 0.4043 - val_loss: 1.3949 - val_accuracy: 0.4385\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3722 - accuracy: 0.4296\n",
      "Epoch 23: val_loss improved from 1.39485 to 1.37947, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 1.3722 - accuracy: 0.4296 - val_loss: 1.3795 - val_accuracy: 0.4436\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3554 - accuracy: 0.4389\n",
      "Epoch 24: val_loss improved from 1.37947 to 1.36783, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 1.3554 - accuracy: 0.4389 - val_loss: 1.3678 - val_accuracy: 0.4487\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3378 - accuracy: 0.4471\n",
      "Epoch 25: val_loss improved from 1.36783 to 1.35955, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 1.3378 - accuracy: 0.4471 - val_loss: 1.3596 - val_accuracy: 0.4590\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3140 - accuracy: 0.4549\n",
      "Epoch 26: val_loss improved from 1.35955 to 1.33918, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 1.3140 - accuracy: 0.4549 - val_loss: 1.3392 - val_accuracy: 0.4667\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2976 - accuracy: 0.4665\n",
      "Epoch 27: val_loss improved from 1.33918 to 1.31710, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 1.2976 - accuracy: 0.4665 - val_loss: 1.3171 - val_accuracy: 0.4590\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2832 - accuracy: 0.4661\n",
      "Epoch 28: val_loss improved from 1.31710 to 1.29770, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 1.2832 - accuracy: 0.4661 - val_loss: 1.2977 - val_accuracy: 0.4718\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2587 - accuracy: 0.4665\n",
      "Epoch 29: val_loss improved from 1.29770 to 1.27703, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 1.2587 - accuracy: 0.4665 - val_loss: 1.2770 - val_accuracy: 0.4718\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2428 - accuracy: 0.4743\n",
      "Epoch 30: val_loss improved from 1.27703 to 1.26220, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 1.2428 - accuracy: 0.4743 - val_loss: 1.2622 - val_accuracy: 0.4821\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2278 - accuracy: 0.4840\n",
      "Epoch 31: val_loss improved from 1.26220 to 1.25196, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 1.2278 - accuracy: 0.4840 - val_loss: 1.2520 - val_accuracy: 0.4949\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2072 - accuracy: 0.4965\n",
      "Epoch 32: val_loss improved from 1.25196 to 1.23691, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 1.2072 - accuracy: 0.4965 - val_loss: 1.2369 - val_accuracy: 0.4949\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1838 - accuracy: 0.4875\n",
      "Epoch 33: val_loss improved from 1.23691 to 1.21313, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 1.1838 - accuracy: 0.4875 - val_loss: 1.2131 - val_accuracy: 0.5026\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1787 - accuracy: 0.5051\n",
      "Epoch 34: val_loss improved from 1.21313 to 1.19751, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 1.1787 - accuracy: 0.5051 - val_loss: 1.1975 - val_accuracy: 0.4949\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1654 - accuracy: 0.4918\n",
      "Epoch 35: val_loss improved from 1.19751 to 1.18670, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 1.1654 - accuracy: 0.4918 - val_loss: 1.1867 - val_accuracy: 0.5051\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1367 - accuracy: 0.5222\n",
      "Epoch 36: val_loss improved from 1.18670 to 1.17945, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 1.1367 - accuracy: 0.5222 - val_loss: 1.1795 - val_accuracy: 0.5077\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1451 - accuracy: 0.5117\n",
      "Epoch 37: val_loss improved from 1.17945 to 1.17199, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 1.1451 - accuracy: 0.5117 - val_loss: 1.1720 - val_accuracy: 0.5077\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1321 - accuracy: 0.5230\n",
      "Epoch 38: val_loss improved from 1.17199 to 1.15911, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 1.1321 - accuracy: 0.5230 - val_loss: 1.1591 - val_accuracy: 0.5077\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1011 - accuracy: 0.5335\n",
      "Epoch 39: val_loss improved from 1.15911 to 1.14827, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 1.1011 - accuracy: 0.5335 - val_loss: 1.1483 - val_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1024 - accuracy: 0.5257\n",
      "Epoch 40: val_loss improved from 1.14827 to 1.13258, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 1.1024 - accuracy: 0.5257 - val_loss: 1.1326 - val_accuracy: 0.5333\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0794 - accuracy: 0.5420\n",
      "Epoch 41: val_loss improved from 1.13258 to 1.11986, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 1.0794 - accuracy: 0.5420 - val_loss: 1.1199 - val_accuracy: 0.5385\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0739 - accuracy: 0.5584\n",
      "Epoch 42: val_loss improved from 1.11986 to 1.10274, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 1.0739 - accuracy: 0.5584 - val_loss: 1.1027 - val_accuracy: 0.5333\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0585 - accuracy: 0.5467\n",
      "Epoch 43: val_loss improved from 1.10274 to 1.08839, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 1.0585 - accuracy: 0.5467 - val_loss: 1.0884 - val_accuracy: 0.5410\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0571 - accuracy: 0.5455\n",
      "Epoch 44: val_loss improved from 1.08839 to 1.07693, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 1.0571 - accuracy: 0.5455 - val_loss: 1.0769 - val_accuracy: 0.5410\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0486 - accuracy: 0.5475\n",
      "Epoch 45: val_loss improved from 1.07693 to 1.06887, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 1.0486 - accuracy: 0.5475 - val_loss: 1.0689 - val_accuracy: 0.5564\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0333 - accuracy: 0.5654\n",
      "Epoch 46: val_loss improved from 1.06887 to 1.06121, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 1.0333 - accuracy: 0.5654 - val_loss: 1.0612 - val_accuracy: 0.5513\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0110 - accuracy: 0.5743\n",
      "Epoch 47: val_loss improved from 1.06121 to 1.05135, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 1.0110 - accuracy: 0.5743 - val_loss: 1.0514 - val_accuracy: 0.5641\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9940 - accuracy: 0.5786\n",
      "Epoch 48: val_loss improved from 1.05135 to 1.04238, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.9940 - accuracy: 0.5786 - val_loss: 1.0424 - val_accuracy: 0.5641\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9934 - accuracy: 0.5786\n",
      "Epoch 49: val_loss improved from 1.04238 to 1.03271, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.9934 - accuracy: 0.5786 - val_loss: 1.0327 - val_accuracy: 0.5795\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9965 - accuracy: 0.5755\n",
      "Epoch 50: val_loss improved from 1.03271 to 1.02269, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.9965 - accuracy: 0.5755 - val_loss: 1.0227 - val_accuracy: 0.5846\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9919 - accuracy: 0.5833\n",
      "Epoch 51: val_loss improved from 1.02269 to 1.01177, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.9919 - accuracy: 0.5833 - val_loss: 1.0118 - val_accuracy: 0.5744\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9840 - accuracy: 0.5833\n",
      "Epoch 52: val_loss improved from 1.01177 to 1.00273, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.9840 - accuracy: 0.5833 - val_loss: 1.0027 - val_accuracy: 0.5795\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9574 - accuracy: 0.5872\n",
      "Epoch 53: val_loss improved from 1.00273 to 0.99450, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.9574 - accuracy: 0.5872 - val_loss: 0.9945 - val_accuracy: 0.5795\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9688 - accuracy: 0.5918\n",
      "Epoch 54: val_loss improved from 0.99450 to 0.98944, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.9688 - accuracy: 0.5918 - val_loss: 0.9894 - val_accuracy: 0.5821\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9565 - accuracy: 0.5895\n",
      "Epoch 55: val_loss improved from 0.98944 to 0.98723, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.9565 - accuracy: 0.5895 - val_loss: 0.9872 - val_accuracy: 0.5897\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9475 - accuracy: 0.5887\n",
      "Epoch 56: val_loss improved from 0.98723 to 0.98540, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.9475 - accuracy: 0.5887 - val_loss: 0.9854 - val_accuracy: 0.5821\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9488 - accuracy: 0.5981\n",
      "Epoch 57: val_loss improved from 0.98540 to 0.98009, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.9488 - accuracy: 0.5981 - val_loss: 0.9801 - val_accuracy: 0.5872\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9466 - accuracy: 0.6012\n",
      "Epoch 58: val_loss improved from 0.98009 to 0.97358, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.9466 - accuracy: 0.6012 - val_loss: 0.9736 - val_accuracy: 0.5872\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9282 - accuracy: 0.6167\n",
      "Epoch 59: val_loss improved from 0.97358 to 0.96499, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 754ms/step - loss: 0.9282 - accuracy: 0.6167 - val_loss: 0.9650 - val_accuracy: 0.6000\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9166 - accuracy: 0.6070\n",
      "Epoch 60: val_loss improved from 0.96499 to 0.95406, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.9166 - accuracy: 0.6070 - val_loss: 0.9541 - val_accuracy: 0.5949\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9255 - accuracy: 0.5965\n",
      "Epoch 61: val_loss improved from 0.95406 to 0.94692, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.9255 - accuracy: 0.5965 - val_loss: 0.9469 - val_accuracy: 0.5872\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9160 - accuracy: 0.6039\n",
      "Epoch 62: val_loss improved from 0.94692 to 0.94278, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.9160 - accuracy: 0.6039 - val_loss: 0.9428 - val_accuracy: 0.6000\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9161 - accuracy: 0.6078\n",
      "Epoch 63: val_loss improved from 0.94278 to 0.94094, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.9161 - accuracy: 0.6078 - val_loss: 0.9409 - val_accuracy: 0.6128\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.6140\n",
      "Epoch 64: val_loss improved from 0.94094 to 0.93788, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.9066 - accuracy: 0.6140 - val_loss: 0.9379 - val_accuracy: 0.6000\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9112 - accuracy: 0.6121\n",
      "Epoch 65: val_loss improved from 0.93788 to 0.93353, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.9112 - accuracy: 0.6121 - val_loss: 0.9335 - val_accuracy: 0.5949\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8833 - accuracy: 0.6237\n",
      "Epoch 66: val_loss improved from 0.93353 to 0.93014, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.8833 - accuracy: 0.6237 - val_loss: 0.9301 - val_accuracy: 0.6103\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9036 - accuracy: 0.6187\n",
      "Epoch 67: val_loss improved from 0.93014 to 0.92051, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.9036 - accuracy: 0.6187 - val_loss: 0.9205 - val_accuracy: 0.6026\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8916 - accuracy: 0.6253\n",
      "Epoch 68: val_loss improved from 0.92051 to 0.91316, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.8916 - accuracy: 0.6253 - val_loss: 0.9132 - val_accuracy: 0.6026\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8873 - accuracy: 0.6210\n",
      "Epoch 69: val_loss improved from 0.91316 to 0.90552, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.8873 - accuracy: 0.6210 - val_loss: 0.9055 - val_accuracy: 0.6026\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8893 - accuracy: 0.6230\n",
      "Epoch 70: val_loss improved from 0.90552 to 0.90114, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.8893 - accuracy: 0.6230 - val_loss: 0.9011 - val_accuracy: 0.6128\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8592 - accuracy: 0.6292\n",
      "Epoch 71: val_loss improved from 0.90114 to 0.89694, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.8592 - accuracy: 0.6292 - val_loss: 0.8969 - val_accuracy: 0.6051\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8651 - accuracy: 0.6374\n",
      "Epoch 72: val_loss did not improve from 0.89694\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.8651 - accuracy: 0.6374 - val_loss: 0.8970 - val_accuracy: 0.6000\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8671 - accuracy: 0.6276\n",
      "Epoch 73: val_loss improved from 0.89694 to 0.89638, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.8671 - accuracy: 0.6276 - val_loss: 0.8964 - val_accuracy: 0.6051\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8515 - accuracy: 0.6471\n",
      "Epoch 74: val_loss improved from 0.89638 to 0.89267, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.8515 - accuracy: 0.6471 - val_loss: 0.8927 - val_accuracy: 0.6128\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8662 - accuracy: 0.6405\n",
      "Epoch 75: val_loss improved from 0.89267 to 0.88981, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.8662 - accuracy: 0.6405 - val_loss: 0.8898 - val_accuracy: 0.6128\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8407 - accuracy: 0.6432\n",
      "Epoch 76: val_loss improved from 0.88981 to 0.88287, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.8407 - accuracy: 0.6432 - val_loss: 0.8829 - val_accuracy: 0.6154\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8392 - accuracy: 0.6412\n",
      "Epoch 77: val_loss improved from 0.88287 to 0.87920, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.8392 - accuracy: 0.6412 - val_loss: 0.8792 - val_accuracy: 0.6051\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8425 - accuracy: 0.6502\n",
      "Epoch 78: val_loss improved from 0.87920 to 0.87335, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 0.8425 - accuracy: 0.6502 - val_loss: 0.8734 - val_accuracy: 0.6077\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8342 - accuracy: 0.6591\n",
      "Epoch 79: val_loss improved from 0.87335 to 0.87242, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.8342 - accuracy: 0.6591 - val_loss: 0.8724 - val_accuracy: 0.6077\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8158 - accuracy: 0.6479\n",
      "Epoch 80: val_loss improved from 0.87242 to 0.86580, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.8158 - accuracy: 0.6479 - val_loss: 0.8658 - val_accuracy: 0.6179\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8265 - accuracy: 0.6467\n",
      "Epoch 81: val_loss improved from 0.86580 to 0.86513, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.8265 - accuracy: 0.6467 - val_loss: 0.8651 - val_accuracy: 0.6026\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8293 - accuracy: 0.6553\n",
      "Epoch 82: val_loss improved from 0.86513 to 0.86070, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.8293 - accuracy: 0.6553 - val_loss: 0.8607 - val_accuracy: 0.6103\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8314 - accuracy: 0.6537\n",
      "Epoch 83: val_loss did not improve from 0.86070\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.8314 - accuracy: 0.6537 - val_loss: 0.8651 - val_accuracy: 0.6231\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8127 - accuracy: 0.6638\n",
      "Epoch 84: val_loss improved from 0.86070 to 0.85867, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.8127 - accuracy: 0.6638 - val_loss: 0.8587 - val_accuracy: 0.6282\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8030 - accuracy: 0.6580\n",
      "Epoch 85: val_loss improved from 0.85867 to 0.85558, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.8030 - accuracy: 0.6580 - val_loss: 0.8556 - val_accuracy: 0.6103\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8113 - accuracy: 0.6685\n",
      "Epoch 86: val_loss improved from 0.85558 to 0.85339, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.8113 - accuracy: 0.6685 - val_loss: 0.8534 - val_accuracy: 0.6077\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7887 - accuracy: 0.6630\n",
      "Epoch 87: val_loss improved from 0.85339 to 0.84852, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.7887 - accuracy: 0.6630 - val_loss: 0.8485 - val_accuracy: 0.6282\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8011 - accuracy: 0.6603\n",
      "Epoch 88: val_loss improved from 0.84852 to 0.84805, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.8011 - accuracy: 0.6603 - val_loss: 0.8481 - val_accuracy: 0.6282\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7872 - accuracy: 0.6778\n",
      "Epoch 89: val_loss improved from 0.84805 to 0.84167, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.7872 - accuracy: 0.6778 - val_loss: 0.8417 - val_accuracy: 0.6333\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7717 - accuracy: 0.6751\n",
      "Epoch 90: val_loss improved from 0.84167 to 0.83466, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.7717 - accuracy: 0.6751 - val_loss: 0.8347 - val_accuracy: 0.6256\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7666 - accuracy: 0.6774\n",
      "Epoch 91: val_loss improved from 0.83466 to 0.82946, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.7666 - accuracy: 0.6774 - val_loss: 0.8295 - val_accuracy: 0.6410\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7808 - accuracy: 0.6739\n",
      "Epoch 92: val_loss improved from 0.82946 to 0.82482, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.7808 - accuracy: 0.6739 - val_loss: 0.8248 - val_accuracy: 0.6487\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7737 - accuracy: 0.6790\n",
      "Epoch 93: val_loss improved from 0.82482 to 0.82030, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.7737 - accuracy: 0.6790 - val_loss: 0.8203 - val_accuracy: 0.6487\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7894 - accuracy: 0.6704\n",
      "Epoch 94: val_loss improved from 0.82030 to 0.81303, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.7894 - accuracy: 0.6704 - val_loss: 0.8130 - val_accuracy: 0.6513\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7459 - accuracy: 0.6930\n",
      "Epoch 95: val_loss improved from 0.81303 to 0.80877, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.7459 - accuracy: 0.6930 - val_loss: 0.8088 - val_accuracy: 0.6538\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7399 - accuracy: 0.6879\n",
      "Epoch 96: val_loss improved from 0.80877 to 0.80584, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.7399 - accuracy: 0.6879 - val_loss: 0.8058 - val_accuracy: 0.6538\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7462 - accuracy: 0.6907\n",
      "Epoch 97: val_loss improved from 0.80584 to 0.80478, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.7462 - accuracy: 0.6907 - val_loss: 0.8048 - val_accuracy: 0.6564\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7390 - accuracy: 0.6984\n",
      "Epoch 98: val_loss improved from 0.80478 to 0.80250, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.7390 - accuracy: 0.6984 - val_loss: 0.8025 - val_accuracy: 0.6564\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7468 - accuracy: 0.6844\n",
      "Epoch 99: val_loss improved from 0.80250 to 0.79480, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.7468 - accuracy: 0.6844 - val_loss: 0.7948 - val_accuracy: 0.6641\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7336 - accuracy: 0.6899\n",
      "Epoch 100: val_loss improved from 0.79480 to 0.78601, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.7336 - accuracy: 0.6899 - val_loss: 0.7860 - val_accuracy: 0.6744\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7305 - accuracy: 0.6961\n",
      "Epoch 101: val_loss improved from 0.78601 to 0.78403, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.7305 - accuracy: 0.6961 - val_loss: 0.7840 - val_accuracy: 0.6641\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7210 - accuracy: 0.6981\n",
      "Epoch 102: val_loss improved from 0.78403 to 0.77956, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.7210 - accuracy: 0.6981 - val_loss: 0.7796 - val_accuracy: 0.6692\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.6996\n",
      "Epoch 103: val_loss improved from 0.77956 to 0.77797, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.7131 - accuracy: 0.6996 - val_loss: 0.7780 - val_accuracy: 0.6718\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.7093\n",
      "Epoch 104: val_loss improved from 0.77797 to 0.76746, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.7022 - accuracy: 0.7093 - val_loss: 0.7675 - val_accuracy: 0.6718\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.7136\n",
      "Epoch 105: val_loss improved from 0.76746 to 0.75970, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.7025 - accuracy: 0.7136 - val_loss: 0.7597 - val_accuracy: 0.6718\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.7109\n",
      "Epoch 106: val_loss improved from 0.75970 to 0.75749, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.7031 - accuracy: 0.7109 - val_loss: 0.7575 - val_accuracy: 0.6769\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6987 - accuracy: 0.7062\n",
      "Epoch 107: val_loss improved from 0.75749 to 0.75568, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.6987 - accuracy: 0.7062 - val_loss: 0.7557 - val_accuracy: 0.6744\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.7171\n",
      "Epoch 108: val_loss improved from 0.75568 to 0.74220, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.6874 - accuracy: 0.7171 - val_loss: 0.7422 - val_accuracy: 0.6897\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.7241\n",
      "Epoch 109: val_loss improved from 0.74220 to 0.73385, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.6763 - accuracy: 0.7241 - val_loss: 0.7339 - val_accuracy: 0.6872\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.7233\n",
      "Epoch 110: val_loss did not improve from 0.73385\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.6775 - accuracy: 0.7233 - val_loss: 0.7406 - val_accuracy: 0.6744\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6734 - accuracy: 0.7300\n",
      "Epoch 111: val_loss did not improve from 0.73385\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.6734 - accuracy: 0.7300 - val_loss: 0.7431 - val_accuracy: 0.6821\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.7280\n",
      "Epoch 112: val_loss did not improve from 0.73385\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.6633 - accuracy: 0.7280 - val_loss: 0.7349 - val_accuracy: 0.6846\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6714 - accuracy: 0.7296\n",
      "Epoch 113: val_loss improved from 0.73385 to 0.72787, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.6714 - accuracy: 0.7296 - val_loss: 0.7279 - val_accuracy: 0.6846\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.7323\n",
      "Epoch 114: val_loss improved from 0.72787 to 0.72536, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.6598 - accuracy: 0.7323 - val_loss: 0.7254 - val_accuracy: 0.6821\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.7335\n",
      "Epoch 115: val_loss improved from 0.72536 to 0.71860, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.6538 - accuracy: 0.7335 - val_loss: 0.7186 - val_accuracy: 0.6846\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6484 - accuracy: 0.7366\n",
      "Epoch 116: val_loss improved from 0.71860 to 0.71251, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.6484 - accuracy: 0.7366 - val_loss: 0.7125 - val_accuracy: 0.7026\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.7366\n",
      "Epoch 117: val_loss did not improve from 0.71251\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.6485 - accuracy: 0.7366 - val_loss: 0.7148 - val_accuracy: 0.7000\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.7366\n",
      "Epoch 118: val_loss did not improve from 0.71251\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 0.6456 - accuracy: 0.7366 - val_loss: 0.7233 - val_accuracy: 0.6846\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6267 - accuracy: 0.7545\n",
      "Epoch 119: val_loss did not improve from 0.71251\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.6267 - accuracy: 0.7545 - val_loss: 0.7191 - val_accuracy: 0.6872\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.7576\n",
      "Epoch 120: val_loss improved from 0.71251 to 0.70690, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.6238 - accuracy: 0.7576 - val_loss: 0.7069 - val_accuracy: 0.6974\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.7490\n",
      "Epoch 121: val_loss improved from 0.70690 to 0.70473, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.6330 - accuracy: 0.7490 - val_loss: 0.7047 - val_accuracy: 0.7077\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.7525\n",
      "Epoch 122: val_loss did not improve from 0.70473\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.6320 - accuracy: 0.7525 - val_loss: 0.7053 - val_accuracy: 0.6897\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.7681\n",
      "Epoch 123: val_loss improved from 0.70473 to 0.69565, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.6062 - accuracy: 0.7681 - val_loss: 0.6957 - val_accuracy: 0.7026\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.7556\n",
      "Epoch 124: val_loss did not improve from 0.69565\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.6022 - accuracy: 0.7556 - val_loss: 0.6972 - val_accuracy: 0.6949\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.7700\n",
      "Epoch 125: val_loss did not improve from 0.69565\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.5927 - accuracy: 0.7700 - val_loss: 0.7022 - val_accuracy: 0.6974\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.7700\n",
      "Epoch 126: val_loss improved from 0.69565 to 0.69195, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.5708 - accuracy: 0.7700 - val_loss: 0.6920 - val_accuracy: 0.7179\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5898 - accuracy: 0.7712\n",
      "Epoch 127: val_loss improved from 0.69195 to 0.68284, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.5898 - accuracy: 0.7712 - val_loss: 0.6828 - val_accuracy: 0.7231\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.7689\n",
      "Epoch 128: val_loss improved from 0.68284 to 0.68263, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.6075 - accuracy: 0.7689 - val_loss: 0.6826 - val_accuracy: 0.7205\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5911 - accuracy: 0.7689\n",
      "Epoch 129: val_loss did not improve from 0.68263\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5911 - accuracy: 0.7689 - val_loss: 0.6893 - val_accuracy: 0.7128\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.7603\n",
      "Epoch 130: val_loss did not improve from 0.68263\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5881 - accuracy: 0.7603 - val_loss: 0.6850 - val_accuracy: 0.7231\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.7642\n",
      "Epoch 131: val_loss did not improve from 0.68263\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.5745 - accuracy: 0.7642 - val_loss: 0.6840 - val_accuracy: 0.7205\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.7805\n",
      "Epoch 132: val_loss improved from 0.68263 to 0.67527, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.5769 - accuracy: 0.7805 - val_loss: 0.6753 - val_accuracy: 0.7128\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.7802\n",
      "Epoch 133: val_loss improved from 0.67527 to 0.67202, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.5866 - accuracy: 0.7802 - val_loss: 0.6720 - val_accuracy: 0.7154\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.7852\n",
      "Epoch 134: val_loss improved from 0.67202 to 0.66176, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.5514 - accuracy: 0.7852 - val_loss: 0.6618 - val_accuracy: 0.7308\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.7938\n",
      "Epoch 135: val_loss did not improve from 0.66176\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.5415 - accuracy: 0.7938 - val_loss: 0.6636 - val_accuracy: 0.7385\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.7798\n",
      "Epoch 136: val_loss did not improve from 0.66176\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.5525 - accuracy: 0.7798 - val_loss: 0.6734 - val_accuracy: 0.7308\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5526 - accuracy: 0.7852\n",
      "Epoch 137: val_loss did not improve from 0.66176\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.5526 - accuracy: 0.7852 - val_loss: 0.6802 - val_accuracy: 0.7077\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.7899\n",
      "Epoch 138: val_loss did not improve from 0.66176\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5419 - accuracy: 0.7899 - val_loss: 0.6736 - val_accuracy: 0.7154\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.7825\n",
      "Epoch 139: val_loss did not improve from 0.66176\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.5626 - accuracy: 0.7825 - val_loss: 0.6791 - val_accuracy: 0.7256\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.7899\n",
      "Epoch 140: val_loss did not improve from 0.66176\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5469 - accuracy: 0.7899 - val_loss: 0.6625 - val_accuracy: 0.7333\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.7907\n",
      "Epoch 141: val_loss improved from 0.66176 to 0.65629, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.5385 - accuracy: 0.7907 - val_loss: 0.6563 - val_accuracy: 0.7385\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.7984\n",
      "Epoch 142: val_loss improved from 0.65629 to 0.63979, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.5365 - accuracy: 0.7984 - val_loss: 0.6398 - val_accuracy: 0.7410\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.7965\n",
      "Epoch 143: val_loss improved from 0.63979 to 0.63554, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 0.5265 - accuracy: 0.7965 - val_loss: 0.6355 - val_accuracy: 0.7436\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.8070\n",
      "Epoch 144: val_loss did not improve from 0.63554\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 0.5146 - accuracy: 0.8070 - val_loss: 0.6423 - val_accuracy: 0.7308\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5318 - accuracy: 0.7914\n",
      "Epoch 145: val_loss did not improve from 0.63554\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.5318 - accuracy: 0.7914 - val_loss: 0.6503 - val_accuracy: 0.7256\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.7965\n",
      "Epoch 146: val_loss did not improve from 0.63554\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.5287 - accuracy: 0.7965 - val_loss: 0.6532 - val_accuracy: 0.7359\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.7914\n",
      "Epoch 147: val_loss did not improve from 0.63554\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.5240 - accuracy: 0.7914 - val_loss: 0.6467 - val_accuracy: 0.7282\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.7988\n",
      "Epoch 148: val_loss did not improve from 0.63554\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.5258 - accuracy: 0.7988 - val_loss: 0.6435 - val_accuracy: 0.7231\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.8035\n",
      "Epoch 149: val_loss improved from 0.63554 to 0.63463, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.5035 - accuracy: 0.8035 - val_loss: 0.6346 - val_accuracy: 0.7436\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5102 - accuracy: 0.8074\n",
      "Epoch 150: val_loss improved from 0.63463 to 0.63372, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.5102 - accuracy: 0.8074 - val_loss: 0.6337 - val_accuracy: 0.7385\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.8016\n",
      "Epoch 151: val_loss did not improve from 0.63372\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.4994 - accuracy: 0.8016 - val_loss: 0.6491 - val_accuracy: 0.7308\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.8012\n",
      "Epoch 152: val_loss did not improve from 0.63372\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.5246 - accuracy: 0.8012 - val_loss: 0.6478 - val_accuracy: 0.7359\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.7984\n",
      "Epoch 153: val_loss improved from 0.63372 to 0.62304, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.5005 - accuracy: 0.7984 - val_loss: 0.6230 - val_accuracy: 0.7462\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.8113\n",
      "Epoch 154: val_loss improved from 0.62304 to 0.61497, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.4953 - accuracy: 0.8113 - val_loss: 0.6150 - val_accuracy: 0.7487\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.8039\n",
      "Epoch 155: val_loss did not improve from 0.61497\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.5150 - accuracy: 0.8039 - val_loss: 0.6273 - val_accuracy: 0.7333\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4929 - accuracy: 0.8163\n",
      "Epoch 156: val_loss did not improve from 0.61497\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4929 - accuracy: 0.8163 - val_loss: 0.6357 - val_accuracy: 0.7282\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.8078\n",
      "Epoch 157: val_loss improved from 0.61497 to 0.61083, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5011 - accuracy: 0.8078 - val_loss: 0.6108 - val_accuracy: 0.7513\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4666 - accuracy: 0.8280\n",
      "Epoch 158: val_loss improved from 0.61083 to 0.60520, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4666 - accuracy: 0.8280 - val_loss: 0.6052 - val_accuracy: 0.7564\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.8179\n",
      "Epoch 159: val_loss did not improve from 0.60520\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4906 - accuracy: 0.8179 - val_loss: 0.6151 - val_accuracy: 0.7538\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4714 - accuracy: 0.8276\n",
      "Epoch 160: val_loss did not improve from 0.60520\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 0.4714 - accuracy: 0.8276 - val_loss: 0.6278 - val_accuracy: 0.7333\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.8109\n",
      "Epoch 161: val_loss did not improve from 0.60520\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4779 - accuracy: 0.8109 - val_loss: 0.6098 - val_accuracy: 0.7513\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.8144\n",
      "Epoch 162: val_loss did not improve from 0.60520\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 0.4641 - accuracy: 0.8144 - val_loss: 0.6167 - val_accuracy: 0.7436\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.8179\n",
      "Epoch 163: val_loss did not improve from 0.60520\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.4675 - accuracy: 0.8179 - val_loss: 0.6461 - val_accuracy: 0.7359\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.8097\n",
      "Epoch 164: val_loss did not improve from 0.60520\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.4802 - accuracy: 0.8097 - val_loss: 0.6465 - val_accuracy: 0.7333\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8148\n",
      "Epoch 165: val_loss improved from 0.60520 to 0.60257, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.4573 - accuracy: 0.8148 - val_loss: 0.6026 - val_accuracy: 0.7513\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.8175\n",
      "Epoch 166: val_loss improved from 0.60257 to 0.58110, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.4708 - accuracy: 0.8175 - val_loss: 0.5811 - val_accuracy: 0.7744\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4652 - accuracy: 0.8284\n",
      "Epoch 167: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 0.4652 - accuracy: 0.8284 - val_loss: 0.5879 - val_accuracy: 0.7667\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8307\n",
      "Epoch 168: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.4481 - accuracy: 0.8307 - val_loss: 0.6025 - val_accuracy: 0.7667\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8339\n",
      "Epoch 169: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.4415 - accuracy: 0.8339 - val_loss: 0.5997 - val_accuracy: 0.7538\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.8358\n",
      "Epoch 170: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.4476 - accuracy: 0.8358 - val_loss: 0.5972 - val_accuracy: 0.7538\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4592 - accuracy: 0.8265\n",
      "Epoch 171: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4592 - accuracy: 0.8265 - val_loss: 0.6071 - val_accuracy: 0.7538\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.8319\n",
      "Epoch 172: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.4496 - accuracy: 0.8319 - val_loss: 0.6142 - val_accuracy: 0.7513\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.8323\n",
      "Epoch 173: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.4333 - accuracy: 0.8323 - val_loss: 0.5949 - val_accuracy: 0.7615\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8401\n",
      "Epoch 174: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 0.4326 - accuracy: 0.8401 - val_loss: 0.5845 - val_accuracy: 0.7692\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8304\n",
      "Epoch 175: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.4492 - accuracy: 0.8304 - val_loss: 0.5825 - val_accuracy: 0.7615\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.8401\n",
      "Epoch 176: val_loss did not improve from 0.58110\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.4350 - accuracy: 0.8401 - val_loss: 0.5821 - val_accuracy: 0.7615\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8319\n",
      "Epoch 177: val_loss improved from 0.58110 to 0.57257, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.4416 - accuracy: 0.8319 - val_loss: 0.5726 - val_accuracy: 0.7795\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.8307\n",
      "Epoch 178: val_loss did not improve from 0.57257\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.4367 - accuracy: 0.8307 - val_loss: 0.5899 - val_accuracy: 0.7590\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.8409\n",
      "Epoch 179: val_loss did not improve from 0.57257\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.4162 - accuracy: 0.8409 - val_loss: 0.6004 - val_accuracy: 0.7692\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.8354\n",
      "Epoch 180: val_loss did not improve from 0.57257\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.4286 - accuracy: 0.8354 - val_loss: 0.5944 - val_accuracy: 0.7667\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.8412\n",
      "Epoch 181: val_loss did not improve from 0.57257\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.4109 - accuracy: 0.8412 - val_loss: 0.5793 - val_accuracy: 0.7846\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.8471\n",
      "Epoch 182: val_loss did not improve from 0.57257\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.4069 - accuracy: 0.8471 - val_loss: 0.5809 - val_accuracy: 0.7821\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4110 - accuracy: 0.8440\n",
      "Epoch 183: val_loss did not improve from 0.57257\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.4110 - accuracy: 0.8440 - val_loss: 0.5990 - val_accuracy: 0.7718\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8311\n",
      "Epoch 184: val_loss did not improve from 0.57257\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.4377 - accuracy: 0.8311 - val_loss: 0.6092 - val_accuracy: 0.7615\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4171 - accuracy: 0.8471\n",
      "Epoch 185: val_loss did not improve from 0.57257\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.4171 - accuracy: 0.8471 - val_loss: 0.5820 - val_accuracy: 0.7718\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8486\n",
      "Epoch 186: val_loss improved from 0.57257 to 0.57149, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.4102 - accuracy: 0.8486 - val_loss: 0.5715 - val_accuracy: 0.7744\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8467\n",
      "Epoch 187: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.4086 - accuracy: 0.8467 - val_loss: 0.5927 - val_accuracy: 0.7821\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4195 - accuracy: 0.8412\n",
      "Epoch 188: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.4195 - accuracy: 0.8412 - val_loss: 0.6164 - val_accuracy: 0.7667\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.8424\n",
      "Epoch 189: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.4007 - accuracy: 0.8424 - val_loss: 0.5994 - val_accuracy: 0.7744\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8389\n",
      "Epoch 190: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.4158 - accuracy: 0.8389 - val_loss: 0.5985 - val_accuracy: 0.7667\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.8381\n",
      "Epoch 191: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.4060 - accuracy: 0.8381 - val_loss: 0.6008 - val_accuracy: 0.7692\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.8416\n",
      "Epoch 192: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.4084 - accuracy: 0.8416 - val_loss: 0.6124 - val_accuracy: 0.7667\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.8436\n",
      "Epoch 193: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.4136 - accuracy: 0.8436 - val_loss: 0.5961 - val_accuracy: 0.7667\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8463\n",
      "Epoch 194: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3914 - accuracy: 0.8463 - val_loss: 0.5856 - val_accuracy: 0.7769\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8560\n",
      "Epoch 195: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3900 - accuracy: 0.8560 - val_loss: 0.5911 - val_accuracy: 0.7769\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8529\n",
      "Epoch 196: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3853 - accuracy: 0.8529 - val_loss: 0.5999 - val_accuracy: 0.7846\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.8556\n",
      "Epoch 197: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.3881 - accuracy: 0.8556 - val_loss: 0.5936 - val_accuracy: 0.7872\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8537\n",
      "Epoch 198: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3901 - accuracy: 0.8537 - val_loss: 0.5866 - val_accuracy: 0.7872\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8506\n",
      "Epoch 199: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.3914 - accuracy: 0.8506 - val_loss: 0.5827 - val_accuracy: 0.7846\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8599\n",
      "Epoch 200: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.3830 - accuracy: 0.8599 - val_loss: 0.5908 - val_accuracy: 0.7846\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8541\n",
      "Epoch 201: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.3864 - accuracy: 0.8541 - val_loss: 0.6016 - val_accuracy: 0.7718\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8486\n",
      "Epoch 202: val_loss did not improve from 0.57149\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.3900 - accuracy: 0.8486 - val_loss: 0.5823 - val_accuracy: 0.7769\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.8498\n",
      "Epoch 203: val_loss improved from 0.57149 to 0.56396, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.3943 - accuracy: 0.8498 - val_loss: 0.5640 - val_accuracy: 0.7923\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8576\n",
      "Epoch 204: val_loss did not improve from 0.56396\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3792 - accuracy: 0.8576 - val_loss: 0.5809 - val_accuracy: 0.7846\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8564\n",
      "Epoch 205: val_loss did not improve from 0.56396\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 0.3745 - accuracy: 0.8564 - val_loss: 0.6128 - val_accuracy: 0.7615\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8533\n",
      "Epoch 206: val_loss did not improve from 0.56396\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.3766 - accuracy: 0.8533 - val_loss: 0.5806 - val_accuracy: 0.7872\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8591\n",
      "Epoch 207: val_loss improved from 0.56396 to 0.55931, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3779 - accuracy: 0.8591 - val_loss: 0.5593 - val_accuracy: 0.7974\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.8623\n",
      "Epoch 208: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.3716 - accuracy: 0.8623 - val_loss: 0.5751 - val_accuracy: 0.7974\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3666 - accuracy: 0.8580\n",
      "Epoch 209: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3666 - accuracy: 0.8580 - val_loss: 0.6076 - val_accuracy: 0.7667\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8510\n",
      "Epoch 210: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.3852 - accuracy: 0.8510 - val_loss: 0.6047 - val_accuracy: 0.7718\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3711 - accuracy: 0.8545\n",
      "Epoch 211: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.3711 - accuracy: 0.8545 - val_loss: 0.5695 - val_accuracy: 0.7897\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.8638\n",
      "Epoch 212: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 0.3539 - accuracy: 0.8638 - val_loss: 0.5692 - val_accuracy: 0.7923\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8588\n",
      "Epoch 213: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3663 - accuracy: 0.8588 - val_loss: 0.5899 - val_accuracy: 0.7821\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8494\n",
      "Epoch 214: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3829 - accuracy: 0.8494 - val_loss: 0.5875 - val_accuracy: 0.7821\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.8630\n",
      "Epoch 215: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.3573 - accuracy: 0.8630 - val_loss: 0.5661 - val_accuracy: 0.7949\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8607\n",
      "Epoch 216: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3631 - accuracy: 0.8607 - val_loss: 0.5628 - val_accuracy: 0.7923\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8700\n",
      "Epoch 217: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.3485 - accuracy: 0.8700 - val_loss: 0.5791 - val_accuracy: 0.7795\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3483 - accuracy: 0.8728\n",
      "Epoch 218: val_loss did not improve from 0.55931\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.3483 - accuracy: 0.8728 - val_loss: 0.5597 - val_accuracy: 0.7846\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8747\n",
      "Epoch 219: val_loss improved from 0.55931 to 0.55423, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.3462 - accuracy: 0.8747 - val_loss: 0.5542 - val_accuracy: 0.7872\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.8763\n",
      "Epoch 220: val_loss did not improve from 0.55423\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.3500 - accuracy: 0.8763 - val_loss: 0.5709 - val_accuracy: 0.7897\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.8720\n",
      "Epoch 221: val_loss did not improve from 0.55423\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3486 - accuracy: 0.8720 - val_loss: 0.5597 - val_accuracy: 0.7949\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.8732\n",
      "Epoch 222: val_loss improved from 0.55423 to 0.55173, saving model to results\\AHNPS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3469 - accuracy: 0.8732 - val_loss: 0.5517 - val_accuracy: 0.8103\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.8677\n",
      "Epoch 223: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 0.3463 - accuracy: 0.8677 - val_loss: 0.5809 - val_accuracy: 0.7897\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8677\n",
      "Epoch 224: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.3446 - accuracy: 0.8677 - val_loss: 0.6010 - val_accuracy: 0.7769\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3457 - accuracy: 0.8576\n",
      "Epoch 225: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3457 - accuracy: 0.8576 - val_loss: 0.5903 - val_accuracy: 0.7872\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.8712\n",
      "Epoch 226: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3416 - accuracy: 0.8712 - val_loss: 0.5708 - val_accuracy: 0.7821\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.8728\n",
      "Epoch 227: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 0.3358 - accuracy: 0.8728 - val_loss: 0.5992 - val_accuracy: 0.7821\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8689\n",
      "Epoch 228: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.3389 - accuracy: 0.8689 - val_loss: 0.5922 - val_accuracy: 0.7872\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8782\n",
      "Epoch 229: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3232 - accuracy: 0.8782 - val_loss: 0.5792 - val_accuracy: 0.7718\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.8689\n",
      "Epoch 230: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3443 - accuracy: 0.8689 - val_loss: 0.6089 - val_accuracy: 0.7744\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.8747\n",
      "Epoch 231: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.3332 - accuracy: 0.8747 - val_loss: 0.5944 - val_accuracy: 0.7769\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8755\n",
      "Epoch 232: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.3333 - accuracy: 0.8755 - val_loss: 0.5888 - val_accuracy: 0.7872\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3354 - accuracy: 0.8716\n",
      "Epoch 233: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.3354 - accuracy: 0.8716 - val_loss: 0.5925 - val_accuracy: 0.7872\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.8805\n",
      "Epoch 234: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 0.3196 - accuracy: 0.8805 - val_loss: 0.6065 - val_accuracy: 0.7744\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8739\n",
      "Epoch 235: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.3415 - accuracy: 0.8739 - val_loss: 0.5960 - val_accuracy: 0.7667\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.8728\n",
      "Epoch 236: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3140 - accuracy: 0.8728 - val_loss: 0.6024 - val_accuracy: 0.7744\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.8732\n",
      "Epoch 237: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3219 - accuracy: 0.8732 - val_loss: 0.6043 - val_accuracy: 0.7846\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.8774\n",
      "Epoch 238: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3295 - accuracy: 0.8774 - val_loss: 0.5765 - val_accuracy: 0.8000\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3253 - accuracy: 0.8794\n",
      "Epoch 239: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.3253 - accuracy: 0.8794 - val_loss: 0.5968 - val_accuracy: 0.8026\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8716\n",
      "Epoch 240: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.3308 - accuracy: 0.8716 - val_loss: 0.6405 - val_accuracy: 0.7821\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.8782\n",
      "Epoch 241: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.3324 - accuracy: 0.8782 - val_loss: 0.6000 - val_accuracy: 0.7974\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.8887\n",
      "Epoch 242: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3105 - accuracy: 0.8887 - val_loss: 0.5691 - val_accuracy: 0.7974\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.8743\n",
      "Epoch 243: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.3183 - accuracy: 0.8743 - val_loss: 0.6220 - val_accuracy: 0.7821\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8887\n",
      "Epoch 244: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.3068 - accuracy: 0.8887 - val_loss: 0.6401 - val_accuracy: 0.7692\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.8840\n",
      "Epoch 245: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.3126 - accuracy: 0.8840 - val_loss: 0.5679 - val_accuracy: 0.7949\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8759\n",
      "Epoch 246: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.3189 - accuracy: 0.8759 - val_loss: 0.5521 - val_accuracy: 0.7949\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3171 - accuracy: 0.8739\n",
      "Epoch 247: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.3171 - accuracy: 0.8739 - val_loss: 0.5714 - val_accuracy: 0.7923\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.8778\n",
      "Epoch 248: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.3217 - accuracy: 0.8778 - val_loss: 0.5727 - val_accuracy: 0.8026\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.8864\n",
      "Epoch 249: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3012 - accuracy: 0.8864 - val_loss: 0.5630 - val_accuracy: 0.8051\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.8946\n",
      "Epoch 250: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.2948 - accuracy: 0.8946 - val_loss: 0.5546 - val_accuracy: 0.8103\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.8891\n",
      "Epoch 251: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.2902 - accuracy: 0.8891 - val_loss: 0.5707 - val_accuracy: 0.7923\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3075 - accuracy: 0.8790\n",
      "Epoch 252: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.3075 - accuracy: 0.8790 - val_loss: 0.5758 - val_accuracy: 0.7974\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3008 - accuracy: 0.8848\n",
      "Epoch 253: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.3008 - accuracy: 0.8848 - val_loss: 0.5859 - val_accuracy: 0.7897\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.8782\n",
      "Epoch 254: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.2985 - accuracy: 0.8782 - val_loss: 0.5999 - val_accuracy: 0.7949\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.8899\n",
      "Epoch 255: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2922 - accuracy: 0.8899 - val_loss: 0.5988 - val_accuracy: 0.7897\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.8875\n",
      "Epoch 256: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2966 - accuracy: 0.8875 - val_loss: 0.5932 - val_accuracy: 0.7872\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.8833\n",
      "Epoch 257: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.2987 - accuracy: 0.8833 - val_loss: 0.6219 - val_accuracy: 0.7795\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.8848\n",
      "Epoch 258: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.2902 - accuracy: 0.8848 - val_loss: 0.6134 - val_accuracy: 0.7846\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.8969\n",
      "Epoch 259: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.2806 - accuracy: 0.8969 - val_loss: 0.5917 - val_accuracy: 0.7923\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.8895\n",
      "Epoch 260: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.2891 - accuracy: 0.8895 - val_loss: 0.6170 - val_accuracy: 0.7872\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.8938\n",
      "Epoch 261: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2674 - accuracy: 0.8938 - val_loss: 0.5988 - val_accuracy: 0.7949\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.8934\n",
      "Epoch 262: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.2882 - accuracy: 0.8934 - val_loss: 0.5919 - val_accuracy: 0.8000\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.8922\n",
      "Epoch 263: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2782 - accuracy: 0.8922 - val_loss: 0.5967 - val_accuracy: 0.7949\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8875\n",
      "Epoch 264: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 0.3068 - accuracy: 0.8875 - val_loss: 0.6062 - val_accuracy: 0.7923\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.8895\n",
      "Epoch 265: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2899 - accuracy: 0.8895 - val_loss: 0.5873 - val_accuracy: 0.8000\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.8833\n",
      "Epoch 266: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.3018 - accuracy: 0.8833 - val_loss: 0.5843 - val_accuracy: 0.7949\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2937 - accuracy: 0.8848\n",
      "Epoch 267: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.2937 - accuracy: 0.8848 - val_loss: 0.6240 - val_accuracy: 0.7872\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.8977\n",
      "Epoch 268: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2711 - accuracy: 0.8977 - val_loss: 0.6133 - val_accuracy: 0.7872\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.8965\n",
      "Epoch 269: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.2733 - accuracy: 0.8965 - val_loss: 0.5784 - val_accuracy: 0.8051\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.8922\n",
      "Epoch 270: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2742 - accuracy: 0.8922 - val_loss: 0.5821 - val_accuracy: 0.7949\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.8887\n",
      "Epoch 271: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2949 - accuracy: 0.8887 - val_loss: 0.6314 - val_accuracy: 0.7923\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.9031\n",
      "Epoch 272: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2729 - accuracy: 0.9031 - val_loss: 0.6472 - val_accuracy: 0.7846\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.8926\n",
      "Epoch 273: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.2772 - accuracy: 0.8926 - val_loss: 0.5810 - val_accuracy: 0.8128\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.8988\n",
      "Epoch 274: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2654 - accuracy: 0.8988 - val_loss: 0.5829 - val_accuracy: 0.8000\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.8946\n",
      "Epoch 275: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2798 - accuracy: 0.8946 - val_loss: 0.6104 - val_accuracy: 0.7923\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.8957\n",
      "Epoch 276: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.2751 - accuracy: 0.8957 - val_loss: 0.6249 - val_accuracy: 0.7846\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2677 - accuracy: 0.8969\n",
      "Epoch 277: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2677 - accuracy: 0.8969 - val_loss: 0.5986 - val_accuracy: 0.7923\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.8938\n",
      "Epoch 278: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2813 - accuracy: 0.8938 - val_loss: 0.5873 - val_accuracy: 0.8000\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.8981\n",
      "Epoch 279: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.2721 - accuracy: 0.8981 - val_loss: 0.5972 - val_accuracy: 0.7949\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.8977\n",
      "Epoch 280: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.2684 - accuracy: 0.8977 - val_loss: 0.6165 - val_accuracy: 0.7744\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.8973\n",
      "Epoch 281: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2609 - accuracy: 0.8973 - val_loss: 0.6014 - val_accuracy: 0.7872\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.9062\n",
      "Epoch 282: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.2579 - accuracy: 0.9062 - val_loss: 0.5958 - val_accuracy: 0.8026\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.9047\n",
      "Epoch 283: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.2616 - accuracy: 0.9047 - val_loss: 0.6029 - val_accuracy: 0.8154\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.8953\n",
      "Epoch 284: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2838 - accuracy: 0.8953 - val_loss: 0.6401 - val_accuracy: 0.7872\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.9074\n",
      "Epoch 285: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.2453 - accuracy: 0.9074 - val_loss: 0.6470 - val_accuracy: 0.7872\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9074\n",
      "Epoch 286: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2406 - accuracy: 0.9074 - val_loss: 0.6109 - val_accuracy: 0.8000\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.9023\n",
      "Epoch 287: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2450 - accuracy: 0.9023 - val_loss: 0.6158 - val_accuracy: 0.8026\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.8922\n",
      "Epoch 288: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2813 - accuracy: 0.8922 - val_loss: 0.6546 - val_accuracy: 0.7949\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.8922\n",
      "Epoch 289: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.2653 - accuracy: 0.8922 - val_loss: 0.5877 - val_accuracy: 0.8051\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.9051\n",
      "Epoch 290: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.2502 - accuracy: 0.9051 - val_loss: 0.5718 - val_accuracy: 0.8026\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.9058\n",
      "Epoch 291: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 0.2464 - accuracy: 0.9058 - val_loss: 0.6206 - val_accuracy: 0.8051\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9039\n",
      "Epoch 292: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.2449 - accuracy: 0.9039 - val_loss: 0.6392 - val_accuracy: 0.8051\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9152\n",
      "Epoch 293: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.2371 - accuracy: 0.9152 - val_loss: 0.5892 - val_accuracy: 0.8077\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.9074\n",
      "Epoch 294: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.2458 - accuracy: 0.9074 - val_loss: 0.5734 - val_accuracy: 0.8000\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.9016\n",
      "Epoch 295: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.2575 - accuracy: 0.9016 - val_loss: 0.6158 - val_accuracy: 0.7897\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.9105\n",
      "Epoch 296: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2393 - accuracy: 0.9105 - val_loss: 0.6447 - val_accuracy: 0.7923\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.9113\n",
      "Epoch 297: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.2427 - accuracy: 0.9113 - val_loss: 0.5930 - val_accuracy: 0.8077\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.9113\n",
      "Epoch 298: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2356 - accuracy: 0.9113 - val_loss: 0.5723 - val_accuracy: 0.8051\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.9027\n",
      "Epoch 299: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.2457 - accuracy: 0.9027 - val_loss: 0.6256 - val_accuracy: 0.7872\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9019\n",
      "Epoch 300: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2449 - accuracy: 0.9019 - val_loss: 0.6391 - val_accuracy: 0.7949\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9121\n",
      "Epoch 301: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2296 - accuracy: 0.9121 - val_loss: 0.6337 - val_accuracy: 0.8103\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.9070\n",
      "Epoch 302: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2429 - accuracy: 0.9070 - val_loss: 0.6283 - val_accuracy: 0.8026\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9062\n",
      "Epoch 303: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2377 - accuracy: 0.9062 - val_loss: 0.6120 - val_accuracy: 0.8051\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9144\n",
      "Epoch 304: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.2409 - accuracy: 0.9144 - val_loss: 0.6266 - val_accuracy: 0.8051\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.9082\n",
      "Epoch 305: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2417 - accuracy: 0.9082 - val_loss: 0.6678 - val_accuracy: 0.7923\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.9031\n",
      "Epoch 306: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2543 - accuracy: 0.9031 - val_loss: 0.6675 - val_accuracy: 0.7949\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.9000\n",
      "Epoch 307: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.2471 - accuracy: 0.9000 - val_loss: 0.6062 - val_accuracy: 0.8051\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.9051\n",
      "Epoch 308: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.2497 - accuracy: 0.9051 - val_loss: 0.6368 - val_accuracy: 0.7923\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9218\n",
      "Epoch 309: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.2135 - accuracy: 0.9218 - val_loss: 0.6569 - val_accuracy: 0.8000\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9109\n",
      "Epoch 310: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.2331 - accuracy: 0.9109 - val_loss: 0.6435 - val_accuracy: 0.8051\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9191\n",
      "Epoch 311: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.2165 - accuracy: 0.9191 - val_loss: 0.6080 - val_accuracy: 0.8051\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9171\n",
      "Epoch 312: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.2268 - accuracy: 0.9171 - val_loss: 0.6523 - val_accuracy: 0.8026\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9109\n",
      "Epoch 313: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2260 - accuracy: 0.9109 - val_loss: 0.6880 - val_accuracy: 0.7923\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.9171\n",
      "Epoch 314: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.2202 - accuracy: 0.9171 - val_loss: 0.6519 - val_accuracy: 0.8103\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.9109\n",
      "Epoch 315: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2271 - accuracy: 0.9109 - val_loss: 0.6189 - val_accuracy: 0.7897\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.9058\n",
      "Epoch 316: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2381 - accuracy: 0.9058 - val_loss: 0.6572 - val_accuracy: 0.8026\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9148\n",
      "Epoch 317: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2261 - accuracy: 0.9148 - val_loss: 0.6710 - val_accuracy: 0.7974\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9132\n",
      "Epoch 318: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2199 - accuracy: 0.9132 - val_loss: 0.6728 - val_accuracy: 0.8026\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9237\n",
      "Epoch 319: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2264 - accuracy: 0.9237 - val_loss: 0.6541 - val_accuracy: 0.7974\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9082\n",
      "Epoch 320: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2310 - accuracy: 0.9082 - val_loss: 0.6410 - val_accuracy: 0.8000\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9105\n",
      "Epoch 321: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.2294 - accuracy: 0.9105 - val_loss: 0.7056 - val_accuracy: 0.7923\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9035\n",
      "Epoch 322: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2293 - accuracy: 0.9035 - val_loss: 0.6157 - val_accuracy: 0.8077\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9156\n",
      "Epoch 323: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2195 - accuracy: 0.9156 - val_loss: 0.6234 - val_accuracy: 0.8077\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.9206\n",
      "Epoch 324: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2099 - accuracy: 0.9206 - val_loss: 0.6974 - val_accuracy: 0.7923\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2466 - accuracy: 0.9043\n",
      "Epoch 325: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.2466 - accuracy: 0.9043 - val_loss: 0.6343 - val_accuracy: 0.8128\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9125\n",
      "Epoch 326: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2213 - accuracy: 0.9125 - val_loss: 0.6195 - val_accuracy: 0.8000\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.9148\n",
      "Epoch 327: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2101 - accuracy: 0.9148 - val_loss: 0.6400 - val_accuracy: 0.7949\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2223 - accuracy: 0.9171\n",
      "Epoch 328: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2223 - accuracy: 0.9171 - val_loss: 0.6660 - val_accuracy: 0.8000\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9268\n",
      "Epoch 329: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2070 - accuracy: 0.9268 - val_loss: 0.6652 - val_accuracy: 0.7974\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9202\n",
      "Epoch 330: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1932 - accuracy: 0.9202 - val_loss: 0.6727 - val_accuracy: 0.7949\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9101\n",
      "Epoch 331: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.2225 - accuracy: 0.9101 - val_loss: 0.6601 - val_accuracy: 0.8000\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9233\n",
      "Epoch 332: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1953 - accuracy: 0.9233 - val_loss: 0.6611 - val_accuracy: 0.8000\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.9187\n",
      "Epoch 333: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2069 - accuracy: 0.9187 - val_loss: 0.6700 - val_accuracy: 0.7949\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.9245\n",
      "Epoch 334: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2122 - accuracy: 0.9245 - val_loss: 0.6711 - val_accuracy: 0.8000\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.9171\n",
      "Epoch 335: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2054 - accuracy: 0.9171 - val_loss: 0.6757 - val_accuracy: 0.7974\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9206\n",
      "Epoch 336: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.2093 - accuracy: 0.9206 - val_loss: 0.6565 - val_accuracy: 0.8103\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9237\n",
      "Epoch 337: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1991 - accuracy: 0.9237 - val_loss: 0.6698 - val_accuracy: 0.8103\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9261\n",
      "Epoch 338: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.2048 - accuracy: 0.9261 - val_loss: 0.6751 - val_accuracy: 0.8026\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9198\n",
      "Epoch 339: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.2112 - accuracy: 0.9198 - val_loss: 0.7011 - val_accuracy: 0.7949\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 0.9257\n",
      "Epoch 340: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.2026 - accuracy: 0.9257 - val_loss: 0.6568 - val_accuracy: 0.8000\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1937 - accuracy: 0.9253\n",
      "Epoch 341: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.1937 - accuracy: 0.9253 - val_loss: 0.6526 - val_accuracy: 0.8026\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9307\n",
      "Epoch 342: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.1957 - accuracy: 0.9307 - val_loss: 0.6768 - val_accuracy: 0.7872\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9198\n",
      "Epoch 343: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2125 - accuracy: 0.9198 - val_loss: 0.6487 - val_accuracy: 0.8051\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9195\n",
      "Epoch 344: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2071 - accuracy: 0.9195 - val_loss: 0.6271 - val_accuracy: 0.8051\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9257\n",
      "Epoch 345: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1928 - accuracy: 0.9257 - val_loss: 0.6599 - val_accuracy: 0.7949\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9222\n",
      "Epoch 346: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2043 - accuracy: 0.9222 - val_loss: 0.7032 - val_accuracy: 0.7923\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.9230\n",
      "Epoch 347: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2120 - accuracy: 0.9230 - val_loss: 0.6432 - val_accuracy: 0.8026\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9272\n",
      "Epoch 348: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1942 - accuracy: 0.9272 - val_loss: 0.6163 - val_accuracy: 0.8154\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9210\n",
      "Epoch 349: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.2043 - accuracy: 0.9210 - val_loss: 0.6568 - val_accuracy: 0.8154\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.9268\n",
      "Epoch 350: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1988 - accuracy: 0.9268 - val_loss: 0.6995 - val_accuracy: 0.7949\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.9226\n",
      "Epoch 351: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2073 - accuracy: 0.9226 - val_loss: 0.6661 - val_accuracy: 0.8000\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.9241\n",
      "Epoch 352: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2089 - accuracy: 0.9241 - val_loss: 0.6364 - val_accuracy: 0.7974\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9230\n",
      "Epoch 353: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1935 - accuracy: 0.9230 - val_loss: 0.6662 - val_accuracy: 0.7897\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9237\n",
      "Epoch 354: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.2065 - accuracy: 0.9237 - val_loss: 0.6866 - val_accuracy: 0.8103\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9265\n",
      "Epoch 355: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.6645 - val_accuracy: 0.8103\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9233\n",
      "Epoch 356: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1983 - accuracy: 0.9233 - val_loss: 0.6411 - val_accuracy: 0.8051\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.9257\n",
      "Epoch 357: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1869 - accuracy: 0.9257 - val_loss: 0.6839 - val_accuracy: 0.7872\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9280\n",
      "Epoch 358: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.1778 - accuracy: 0.9280 - val_loss: 0.7157 - val_accuracy: 0.7872\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9315\n",
      "Epoch 359: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1874 - accuracy: 0.9315 - val_loss: 0.6344 - val_accuracy: 0.8103\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9335\n",
      "Epoch 360: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1802 - accuracy: 0.9335 - val_loss: 0.6464 - val_accuracy: 0.8128\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9233\n",
      "Epoch 361: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1930 - accuracy: 0.9233 - val_loss: 0.6852 - val_accuracy: 0.8103\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.9265\n",
      "Epoch 362: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.7116 - val_accuracy: 0.8154\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.9304\n",
      "Epoch 363: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1901 - accuracy: 0.9304 - val_loss: 0.6489 - val_accuracy: 0.8077\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9350\n",
      "Epoch 364: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1754 - accuracy: 0.9350 - val_loss: 0.6288 - val_accuracy: 0.8077\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9354\n",
      "Epoch 365: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.1821 - accuracy: 0.9354 - val_loss: 0.6705 - val_accuracy: 0.8154\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9374\n",
      "Epoch 366: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1607 - accuracy: 0.9374 - val_loss: 0.7017 - val_accuracy: 0.7949\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9362\n",
      "Epoch 367: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1732 - accuracy: 0.9362 - val_loss: 0.6916 - val_accuracy: 0.8026\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9311\n",
      "Epoch 368: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1833 - accuracy: 0.9311 - val_loss: 0.6754 - val_accuracy: 0.8051\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9315\n",
      "Epoch 369: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.1738 - accuracy: 0.9315 - val_loss: 0.6865 - val_accuracy: 0.7897\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.9292\n",
      "Epoch 370: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.1768 - accuracy: 0.9292 - val_loss: 0.7289 - val_accuracy: 0.8026\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.9280\n",
      "Epoch 371: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1894 - accuracy: 0.9280 - val_loss: 0.6955 - val_accuracy: 0.8026\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1838 - accuracy: 0.9315\n",
      "Epoch 372: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1838 - accuracy: 0.9315 - val_loss: 0.6939 - val_accuracy: 0.8000\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9358\n",
      "Epoch 373: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1823 - accuracy: 0.9358 - val_loss: 0.6900 - val_accuracy: 0.8026\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.9339\n",
      "Epoch 374: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1797 - accuracy: 0.9339 - val_loss: 0.6998 - val_accuracy: 0.7872\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9366\n",
      "Epoch 375: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.1634 - accuracy: 0.9366 - val_loss: 0.6883 - val_accuracy: 0.8026\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9304\n",
      "Epoch 376: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.1831 - accuracy: 0.9304 - val_loss: 0.6658 - val_accuracy: 0.7949\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9350\n",
      "Epoch 377: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.1710 - accuracy: 0.9350 - val_loss: 0.6786 - val_accuracy: 0.8051\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9307\n",
      "Epoch 378: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1693 - accuracy: 0.9307 - val_loss: 0.6999 - val_accuracy: 0.8077\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9393\n",
      "Epoch 379: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.1643 - accuracy: 0.9393 - val_loss: 0.6931 - val_accuracy: 0.8103\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9327\n",
      "Epoch 380: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.1748 - accuracy: 0.9327 - val_loss: 0.6865 - val_accuracy: 0.8051\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9377\n",
      "Epoch 381: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 0.1618 - accuracy: 0.9377 - val_loss: 0.7207 - val_accuracy: 0.8051\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9346\n",
      "Epoch 382: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.1704 - accuracy: 0.9346 - val_loss: 0.7368 - val_accuracy: 0.8026\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9339\n",
      "Epoch 383: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.1823 - accuracy: 0.9339 - val_loss: 0.7027 - val_accuracy: 0.8051\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9420\n",
      "Epoch 384: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.1588 - accuracy: 0.9420 - val_loss: 0.6749 - val_accuracy: 0.8051\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9436\n",
      "Epoch 385: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1526 - accuracy: 0.9436 - val_loss: 0.6860 - val_accuracy: 0.8103\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9424\n",
      "Epoch 386: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1598 - accuracy: 0.9424 - val_loss: 0.6920 - val_accuracy: 0.8026\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9377\n",
      "Epoch 387: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.1697 - accuracy: 0.9377 - val_loss: 0.6942 - val_accuracy: 0.8051\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 0.9451\n",
      "Epoch 388: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.1542 - accuracy: 0.9451 - val_loss: 0.7236 - val_accuracy: 0.8026\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.9401\n",
      "Epoch 389: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1666 - accuracy: 0.9401 - val_loss: 0.7403 - val_accuracy: 0.7974\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9412\n",
      "Epoch 390: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1680 - accuracy: 0.9412 - val_loss: 0.7274 - val_accuracy: 0.8026\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9370\n",
      "Epoch 391: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.1683 - accuracy: 0.9370 - val_loss: 0.7252 - val_accuracy: 0.8000\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9374\n",
      "Epoch 392: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.1535 - accuracy: 0.9374 - val_loss: 0.7328 - val_accuracy: 0.8103\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9339\n",
      "Epoch 393: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1739 - accuracy: 0.9339 - val_loss: 0.7569 - val_accuracy: 0.8000\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9385\n",
      "Epoch 394: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1685 - accuracy: 0.9385 - val_loss: 0.7131 - val_accuracy: 0.8103\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9432\n",
      "Epoch 395: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1517 - accuracy: 0.9432 - val_loss: 0.6830 - val_accuracy: 0.8154\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.9362\n",
      "Epoch 396: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1734 - accuracy: 0.9362 - val_loss: 0.7111 - val_accuracy: 0.8103\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9401\n",
      "Epoch 397: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.1593 - accuracy: 0.9401 - val_loss: 0.7631 - val_accuracy: 0.8026\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9420\n",
      "Epoch 398: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1545 - accuracy: 0.9420 - val_loss: 0.7223 - val_accuracy: 0.8128\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9475\n",
      "Epoch 399: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.1473 - accuracy: 0.9475 - val_loss: 0.6790 - val_accuracy: 0.8128\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9432\n",
      "Epoch 400: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.1541 - accuracy: 0.9432 - val_loss: 0.6717 - val_accuracy: 0.8000\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9475\n",
      "Epoch 401: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1440 - accuracy: 0.9475 - val_loss: 0.6989 - val_accuracy: 0.7974\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.9424\n",
      "Epoch 402: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.1507 - accuracy: 0.9424 - val_loss: 0.7201 - val_accuracy: 0.7949\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9412\n",
      "Epoch 403: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.1549 - accuracy: 0.9412 - val_loss: 0.7270 - val_accuracy: 0.7949\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9475\n",
      "Epoch 404: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.1412 - accuracy: 0.9475 - val_loss: 0.7104 - val_accuracy: 0.8077\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9514\n",
      "Epoch 405: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.1367 - accuracy: 0.9514 - val_loss: 0.6876 - val_accuracy: 0.8231\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9471\n",
      "Epoch 406: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.1506 - accuracy: 0.9471 - val_loss: 0.7181 - val_accuracy: 0.8128\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9447\n",
      "Epoch 407: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.1599 - accuracy: 0.9447 - val_loss: 0.7719 - val_accuracy: 0.8000\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.9432\n",
      "Epoch 408: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.1512 - accuracy: 0.9432 - val_loss: 0.7813 - val_accuracy: 0.7949\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9412\n",
      "Epoch 409: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.1472 - accuracy: 0.9412 - val_loss: 0.7185 - val_accuracy: 0.8000\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9424\n",
      "Epoch 410: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1527 - accuracy: 0.9424 - val_loss: 0.7057 - val_accuracy: 0.8051\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9510\n",
      "Epoch 411: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1388 - accuracy: 0.9510 - val_loss: 0.7845 - val_accuracy: 0.8051\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9366\n",
      "Epoch 412: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1664 - accuracy: 0.9366 - val_loss: 0.7751 - val_accuracy: 0.8103\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9397\n",
      "Epoch 413: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 0.1607 - accuracy: 0.9397 - val_loss: 0.7142 - val_accuracy: 0.8103\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9467\n",
      "Epoch 414: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1393 - accuracy: 0.9467 - val_loss: 0.6778 - val_accuracy: 0.8026\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.9339\n",
      "Epoch 415: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1695 - accuracy: 0.9339 - val_loss: 0.6913 - val_accuracy: 0.8128\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9490\n",
      "Epoch 416: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.1477 - accuracy: 0.9490 - val_loss: 0.7798 - val_accuracy: 0.8000\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9502\n",
      "Epoch 417: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.1400 - accuracy: 0.9502 - val_loss: 0.7766 - val_accuracy: 0.8077\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9533\n",
      "Epoch 418: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.1301 - accuracy: 0.9533 - val_loss: 0.7167 - val_accuracy: 0.8026\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9428\n",
      "Epoch 419: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.1400 - accuracy: 0.9428 - val_loss: 0.6912 - val_accuracy: 0.8077\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9510\n",
      "Epoch 420: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.1421 - accuracy: 0.9510 - val_loss: 0.7263 - val_accuracy: 0.8077\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9447\n",
      "Epoch 421: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.1391 - accuracy: 0.9447 - val_loss: 0.8073 - val_accuracy: 0.7949\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9401\n",
      "Epoch 422: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1659 - accuracy: 0.9401 - val_loss: 0.7938 - val_accuracy: 0.8000\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.9436\n",
      "Epoch 423: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 0.1453 - accuracy: 0.9436 - val_loss: 0.7504 - val_accuracy: 0.8000\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9486\n",
      "Epoch 424: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.1375 - accuracy: 0.9486 - val_loss: 0.6927 - val_accuracy: 0.8128\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9436\n",
      "Epoch 425: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 0.1582 - accuracy: 0.9436 - val_loss: 0.7096 - val_accuracy: 0.8154\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9498\n",
      "Epoch 426: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.1445 - accuracy: 0.9498 - val_loss: 0.7628 - val_accuracy: 0.8000\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9471\n",
      "Epoch 427: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.1434 - accuracy: 0.9471 - val_loss: 0.7761 - val_accuracy: 0.7974\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9494\n",
      "Epoch 428: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1278 - accuracy: 0.9494 - val_loss: 0.7502 - val_accuracy: 0.8000\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9412\n",
      "Epoch 429: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1445 - accuracy: 0.9412 - val_loss: 0.7030 - val_accuracy: 0.8077\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9463\n",
      "Epoch 430: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1535 - accuracy: 0.9463 - val_loss: 0.6879 - val_accuracy: 0.8026\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9471\n",
      "Epoch 431: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.1385 - accuracy: 0.9471 - val_loss: 0.7464 - val_accuracy: 0.8103\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9490\n",
      "Epoch 432: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1410 - accuracy: 0.9490 - val_loss: 0.7843 - val_accuracy: 0.7897\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9385\n",
      "Epoch 433: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1561 - accuracy: 0.9385 - val_loss: 0.7484 - val_accuracy: 0.8026\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9510\n",
      "Epoch 434: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 0.1418 - accuracy: 0.9510 - val_loss: 0.7304 - val_accuracy: 0.8000\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.9545\n",
      "Epoch 435: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.1285 - accuracy: 0.9545 - val_loss: 0.7292 - val_accuracy: 0.8051\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9475\n",
      "Epoch 436: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1383 - accuracy: 0.9475 - val_loss: 0.7212 - val_accuracy: 0.8179\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9498\n",
      "Epoch 437: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1326 - accuracy: 0.9498 - val_loss: 0.7237 - val_accuracy: 0.8103\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9537\n",
      "Epoch 438: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.1317 - accuracy: 0.9537 - val_loss: 0.7382 - val_accuracy: 0.8026\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.9444\n",
      "Epoch 439: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.1372 - accuracy: 0.9444 - val_loss: 0.7550 - val_accuracy: 0.8026\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9553\n",
      "Epoch 440: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.1228 - accuracy: 0.9553 - val_loss: 0.7863 - val_accuracy: 0.7974\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9580\n",
      "Epoch 441: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 0.1230 - accuracy: 0.9580 - val_loss: 0.7760 - val_accuracy: 0.8051\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9514\n",
      "Epoch 442: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.1311 - accuracy: 0.9514 - val_loss: 0.7475 - val_accuracy: 0.8051\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9553\n",
      "Epoch 443: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 0.1255 - accuracy: 0.9553 - val_loss: 0.7375 - val_accuracy: 0.8128\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9479\n",
      "Epoch 444: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1457 - accuracy: 0.9479 - val_loss: 0.7255 - val_accuracy: 0.8128\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9584\n",
      "Epoch 445: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1209 - accuracy: 0.9584 - val_loss: 0.7379 - val_accuracy: 0.7974\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9619\n",
      "Epoch 446: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.1081 - accuracy: 0.9619 - val_loss: 0.7539 - val_accuracy: 0.7974\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.9490\n",
      "Epoch 447: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1455 - accuracy: 0.9490 - val_loss: 0.7530 - val_accuracy: 0.8051\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9529\n",
      "Epoch 448: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - accuracy: 0.9529 - val_loss: 0.7207 - val_accuracy: 0.8179\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9533\n",
      "Epoch 449: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1248 - accuracy: 0.9533 - val_loss: 0.6949 - val_accuracy: 0.8179\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9568\n",
      "Epoch 450: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1051 - accuracy: 0.9568 - val_loss: 0.7256 - val_accuracy: 0.8077\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9510\n",
      "Epoch 451: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1396 - accuracy: 0.9510 - val_loss: 0.8067 - val_accuracy: 0.8000\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9521\n",
      "Epoch 452: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1310 - accuracy: 0.9521 - val_loss: 0.8200 - val_accuracy: 0.8000\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9529\n",
      "Epoch 453: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.1376 - accuracy: 0.9529 - val_loss: 0.7434 - val_accuracy: 0.8051\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9572\n",
      "Epoch 454: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.1189 - accuracy: 0.9572 - val_loss: 0.7059 - val_accuracy: 0.8154\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9521\n",
      "Epoch 455: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.1319 - accuracy: 0.9521 - val_loss: 0.7399 - val_accuracy: 0.8128\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9576\n",
      "Epoch 456: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 0.1157 - accuracy: 0.9576 - val_loss: 0.7840 - val_accuracy: 0.8026\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9521\n",
      "Epoch 457: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1294 - accuracy: 0.9521 - val_loss: 0.7770 - val_accuracy: 0.8000\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9549\n",
      "Epoch 458: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.1180 - accuracy: 0.9549 - val_loss: 0.7767 - val_accuracy: 0.7897\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9572\n",
      "Epoch 459: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1138 - accuracy: 0.9572 - val_loss: 0.7792 - val_accuracy: 0.7872\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9564\n",
      "Epoch 460: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1280 - accuracy: 0.9564 - val_loss: 0.7850 - val_accuracy: 0.7974\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9533\n",
      "Epoch 461: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 0.1258 - accuracy: 0.9533 - val_loss: 0.7833 - val_accuracy: 0.7974\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9584\n",
      "Epoch 462: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 773ms/step - loss: 0.1178 - accuracy: 0.9584 - val_loss: 0.7760 - val_accuracy: 0.8026\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9533\n",
      "Epoch 463: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.1191 - accuracy: 0.9533 - val_loss: 0.7768 - val_accuracy: 0.8077\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9580\n",
      "Epoch 464: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.1188 - accuracy: 0.9580 - val_loss: 0.7973 - val_accuracy: 0.8077\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9576\n",
      "Epoch 465: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.1109 - accuracy: 0.9576 - val_loss: 0.8070 - val_accuracy: 0.8103\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9560\n",
      "Epoch 466: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.1221 - accuracy: 0.9560 - val_loss: 0.7891 - val_accuracy: 0.8077\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9576\n",
      "Epoch 467: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.1192 - accuracy: 0.9576 - val_loss: 0.7666 - val_accuracy: 0.8026\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9560\n",
      "Epoch 468: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.1190 - accuracy: 0.9560 - val_loss: 0.7792 - val_accuracy: 0.7974\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9537\n",
      "Epoch 469: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.1204 - accuracy: 0.9537 - val_loss: 0.8207 - val_accuracy: 0.8000\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9486\n",
      "Epoch 470: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.1449 - accuracy: 0.9486 - val_loss: 0.8460 - val_accuracy: 0.7923\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9619\n",
      "Epoch 471: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.1060 - accuracy: 0.9619 - val_loss: 0.8166 - val_accuracy: 0.7949\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9502\n",
      "Epoch 472: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.1469 - accuracy: 0.9502 - val_loss: 0.7520 - val_accuracy: 0.7974\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9564\n",
      "Epoch 473: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.1276 - accuracy: 0.9564 - val_loss: 0.7242 - val_accuracy: 0.8026\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9572\n",
      "Epoch 474: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.1358 - accuracy: 0.9572 - val_loss: 0.7361 - val_accuracy: 0.8128\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9580\n",
      "Epoch 475: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.1149 - accuracy: 0.9580 - val_loss: 0.7966 - val_accuracy: 0.8026\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9576\n",
      "Epoch 476: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.1158 - accuracy: 0.9576 - val_loss: 0.8120 - val_accuracy: 0.7949\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9568\n",
      "Epoch 477: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.1132 - accuracy: 0.9568 - val_loss: 0.7678 - val_accuracy: 0.8103\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.9529\n",
      "Epoch 478: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.1201 - accuracy: 0.9529 - val_loss: 0.7119 - val_accuracy: 0.8154\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9580\n",
      "Epoch 479: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.1247 - accuracy: 0.9580 - val_loss: 0.7268 - val_accuracy: 0.8179\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.9498\n",
      "Epoch 480: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.1260 - accuracy: 0.9498 - val_loss: 0.7680 - val_accuracy: 0.8128\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9626\n",
      "Epoch 481: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 0.1162 - accuracy: 0.9626 - val_loss: 0.8516 - val_accuracy: 0.8000\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9595\n",
      "Epoch 482: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.1073 - accuracy: 0.9595 - val_loss: 0.8325 - val_accuracy: 0.8000\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9599\n",
      "Epoch 483: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.1068 - accuracy: 0.9599 - val_loss: 0.7560 - val_accuracy: 0.8103\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9599\n",
      "Epoch 484: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.1124 - accuracy: 0.9599 - val_loss: 0.7451 - val_accuracy: 0.8103\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9623\n",
      "Epoch 485: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.1038 - accuracy: 0.9623 - val_loss: 0.7785 - val_accuracy: 0.8051\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9619\n",
      "Epoch 486: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 0.1060 - accuracy: 0.9619 - val_loss: 0.7990 - val_accuracy: 0.8051\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9607\n",
      "Epoch 487: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 887ms/step - loss: 0.1069 - accuracy: 0.9607 - val_loss: 0.7694 - val_accuracy: 0.8179\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9580\n",
      "Epoch 488: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1200 - accuracy: 0.9580 - val_loss: 0.7675 - val_accuracy: 0.8128\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9541\n",
      "Epoch 489: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - accuracy: 0.9541 - val_loss: 0.7600 - val_accuracy: 0.8128\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9603\n",
      "Epoch 490: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1071 - accuracy: 0.9603 - val_loss: 0.7724 - val_accuracy: 0.8077\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9510\n",
      "Epoch 491: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1298 - accuracy: 0.9510 - val_loss: 0.7791 - val_accuracy: 0.8000\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9646\n",
      "Epoch 492: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.1080 - accuracy: 0.9646 - val_loss: 0.7627 - val_accuracy: 0.8103\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9642\n",
      "Epoch 493: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 0.1078 - accuracy: 0.9642 - val_loss: 0.7520 - val_accuracy: 0.8282\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.9576\n",
      "Epoch 494: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 0.1253 - accuracy: 0.9576 - val_loss: 0.7636 - val_accuracy: 0.8154\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9595\n",
      "Epoch 495: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.1169 - accuracy: 0.9595 - val_loss: 0.7504 - val_accuracy: 0.8179\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9650\n",
      "Epoch 496: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0996 - accuracy: 0.9650 - val_loss: 0.7624 - val_accuracy: 0.8103\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9553\n",
      "Epoch 497: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.1165 - accuracy: 0.9553 - val_loss: 0.7848 - val_accuracy: 0.8128\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9669\n",
      "Epoch 498: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.0978 - accuracy: 0.9669 - val_loss: 0.7830 - val_accuracy: 0.8179\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9689\n",
      "Epoch 499: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.0925 - accuracy: 0.9689 - val_loss: 0.8007 - val_accuracy: 0.8051\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.9584\n",
      "Epoch 500: val_loss did not improve from 0.55173\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 0.1141 - accuracy: 0.9584 - val_loss: 0.8283 - val_accuracy: 0.8051\n",
      "[+] Model trained\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EDCAA89160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "0.8051282051282052\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EDCAA89160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Prediction: angry\n"
     ]
    }
   ],
   "source": [
    "from deep_emotion_recognition import DeepEmotionRecognizer\n",
    "# initialize instance\n",
    "# inherited from emotion_recognition.EmotionRecognizer\n",
    "# default parameters (LSTM: 128x2, Dense:128x2)\n",
    "deeprec = DeepEmotionRecognizer(emotions=['angry', 'sad', 'neutral', 'ps', 'happy'], n_rnn_layers=2, n_dense_layers=2, rnn_units=128, dense_units=128)\n",
    "# train the model\n",
    "deeprec.train()\n",
    "# get the accuracy\n",
    "print(deeprec.test_score())\n",
    "# predict angry audio sample\n",
    "prediction = deeprec.predict('data/validation/Actor_10/03-02-05-02-02-02-10_angry.wav')\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAVDESS] There are 809 training audio files for category:angry\n",
      "[RAVDESS] There are 148 testing audio files for category:angry\n",
      "[RAVDESS] There are 813 training audio files for category:sad\n",
      "[RAVDESS] There are 147 testing audio files for category:sad\n",
      "[RAVDESS] There are 586 training audio files for category:neutral\n",
      "[RAVDESS] There are 94 testing audio files for category:neutral\n",
      "[RAVDESS] There are 514 training audio files for category:ps\n",
      "[RAVDESS] There are 78 testing audio files for category:ps\n",
      "[RAVDESS] There are 806 training audio files for category:happy\n",
      "[RAVDESS] There are 148 testing audio files for category:happy\n",
      "[I] Generated TESS & RAVDESS DB CSV File\n",
      "[EMO-DB] Total files to write: 339\n",
      "[EMO-DB] Training samples: 271\n",
      "[EMO-DB] Testing samples: 67\n",
      "[I] Generated EMO-DB CSV File\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_ravdess.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeep_emotion_recognition\u001b[39;00m \u001b[39mimport\u001b[39;00m DeepEmotionRecognizer\n\u001b[0;32m      2\u001b[0m \u001b[39m# initialize instance\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# inherited from emotion_recognition.EmotionRecognizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# default parameters (LSTM: 128x2, Dense:128x2)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m deeprec \u001b[39m=\u001b[39m DeepEmotionRecognizer(emotions\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mangry\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msad\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mneutral\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mps\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mhappy\u001b[39;49m\u001b[39m'\u001b[39;49m], n_rnn_layers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, n_dense_layers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, rnn_units\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, dense_units\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m deeprec\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\deep_emotion_recognition.py:108\u001b[0m, in \u001b[0;36mDeepEmotionRecognizer.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39m# compute the input length\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_input_length()\n\u001b[0;32m    110\u001b[0m \u001b[39m# boolean attributes\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_created \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\deep_emotion_recognition.py:143\u001b[0m, in \u001b[0;36mDeepEmotionRecognizer._compute_input_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[39mCalculates the input shape to be able to construct the model.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loaded:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_data()\n\u001b[0;32m    144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\deep_emotion_recognition.py:206\u001b[0m, in \u001b[0;36mDeepEmotionRecognizer.load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    202\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39m    Loads and extracts features from the audio files for the db's specified.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39m    And then reshapes the data.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mload_data()\n\u001b[0;32m    207\u001b[0m     \u001b[39m# reshape X's to 3 dims\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     X_train_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\emotion_recognition.py:197\u001b[0m, in \u001b[0;36mEmotionRecognizer.load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m# 判断是否已经导入过数据.如果已经导入,则跳过,否则执行导入\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loaded:\n\u001b[1;32m--> 197\u001b[0m     result \u001b[39m=\u001b[39m load_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_desc_files, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_desc_files, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maudio_config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassification,\n\u001b[0;32m    198\u001b[0m                         emotions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memotions, balance\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbalance)\n\u001b[0;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mX_test\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\data_extractor.py:302\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(train_desc_files, test_desc_files, audio_config, classification, shuffle, balance, emotions)\u001b[0m\n\u001b[0;32m    299\u001b[0m ae \u001b[39m=\u001b[39m AudioExtractor(audio_config\u001b[39m=\u001b[39maudio_config, classification\u001b[39m=\u001b[39mclassification,\n\u001b[0;32m    300\u001b[0m                            emotions\u001b[39m=\u001b[39memotions,balance\u001b[39m=\u001b[39mbalance, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    301\u001b[0m \u001b[39m# Loads training data\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m ae\u001b[39m.\u001b[39;49mload_train_data(train_desc_files, shuffle\u001b[39m=\u001b[39;49mshuffle)\n\u001b[0;32m    303\u001b[0m \u001b[39m# Loads testing data\u001b[39;00m\n\u001b[0;32m    304\u001b[0m ae\u001b[39m.\u001b[39mload_test_data(test_desc_files, shuffle\u001b[39m=\u001b[39mshuffle)\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\data_extractor.py:169\u001b[0m, in \u001b[0;36mAudioExtractor.load_train_data\u001b[1;34m(self, desc_files, shuffle)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_train_data\u001b[39m(\u001b[39mself\u001b[39m, desc_files\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtrain_speech.csv\u001b[39m\u001b[39m\"\u001b[39m], shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    168\u001b[0m     \u001b[39m\"\"\"Loads training data from the metadata files `desc_files`\"\"\"\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_data(desc_files, \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, shuffle)\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\data_extractor.py:154\u001b[0m, in \u001b[0;36mAudioExtractor._load_data\u001b[1;34m(self, desc_files, partition, shuffle)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_data\u001b[39m(\u001b[39mself\u001b[39m, desc_files, partition, shuffle):\n\u001b[0;32m    151\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[39m    AE对象在如数据集后可选的数据处理操作(balance&shuffle)\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_metadata_from_desc_file(desc_files, partition)\n\u001b[0;32m    155\u001b[0m     \u001b[39m# balancing the datasets ( both training or testing )\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m partition \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbalance:\n",
      "File \u001b[1;32md:\\repos\\CCSER\\SER\\data_extractor.py:57\u001b[0m, in \u001b[0;36mAudioExtractor.load_metadata_from_desc_file\u001b[1;34m(self, desc_files, partition)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# 合并所有需要读入的csv文件\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m desc_file \u001b[39min\u001b[39;00m desc_files:\n\u001b[0;32m     56\u001b[0m     \u001b[39m# concat dataframes\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat((df, pd\u001b[39m.\u001b[39;49mread_csv(desc_file)), sort\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[0;32m     59\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[Info] Loading audio file paths and its corresponding labels...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\condaPythonEnvs\\tf2.10\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_ravdess.csv'"
     ]
    }
   ],
   "source": [
    "from deep_emotion_recognition import DeepEmotionRecognizer\n",
    "# initialize instance\n",
    "# inherited from emotion_recognition.EmotionRecognizer\n",
    "# default parameters (LSTM: 128x2, Dense:128x2)\n",
    "deeprec = DeepEmotionRecognizer(emotions=['angry', 'sad', 'neutral', 'ps', 'happy'], n_rnn_layers=2, n_dense_layers=2, rnn_units=128, dense_units=128)\n",
    "# train the model\n",
    "deeprec.train()\n",
    "# get the accuracy\n",
    "print(deeprec.train_score(),\"@{deeprec.train_score}\")\n",
    "print(deeprec.test_score(),\"@{deeprec.test_score}\")\n",
    "# predict angry audio sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_emotion_recognition_improving import DeepEmotionRecognizer\n",
    "# initialize instance\n",
    "# inherited from emotion_recognition.EmotionRecognizer\n",
    "# default parameters (LSTM: 128x2, Dense:128x2)\n",
    "deeprec = DeepEmotionRecognizer(emotions=['angry', 'sad', 'neutral', 'ps', 'happy'], n_rnn_layers=2, n_dense_layers=2, rnn_units=128, dense_units=128)\n",
    "# train the model\n",
    "deeprec.train()\n",
    "# get the accuracy\n",
    "print(deeprec.test_score())\n",
    "# predict angry audio sample\n",
    "prediction = deeprec.predict('data/validation/Actor_10/03-02-05-02-02-02-10_angry.wav')\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
