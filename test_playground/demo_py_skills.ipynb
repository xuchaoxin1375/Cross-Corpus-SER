{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 1, 3, 8],\n",
       "       [5, 4, 6, 7],\n",
       "       [4, 1, 5, 5]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng=np.random.default_rng()\n",
    "a=rng.integers(1,10,size=(3,4))\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "def t(x=[]):\n",
    "    x.append(1)\n",
    "    print(x)\n",
    "t()\n",
    "t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"A\"= [1, 2, 3], \"B\"= [4, 5, 6], \"C\"= [7, 8, 9]}\n"
     ]
    }
   ],
   "source": [
    "d = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n",
    "import json\n",
    "\n",
    "def dict_to_filename(d):\n",
    "    # Convert dictionary to JSON string\n",
    "    json_str = json.dumps(d)\n",
    "\n",
    "    # Replace invalid characters with hyphen\n",
    "    invalid_chars = ':'\n",
    "    rep_dict={\n",
    "        \":\":\"=\",\n",
    "        '\"':'',\n",
    "        # \"'\":\"\"\n",
    "    }\n",
    "    for char in json_str:\n",
    "        if rep_dict.get(char):\n",
    "            json_str = json_str.replace(char, rep_dict[char])\n",
    "\n",
    "\n",
    "    # Truncate string if too long\n",
    "    # max_len = 260\n",
    "    # if len(json_str) > max_len:\n",
    "    #     json_str = json_str[:max_len]\n",
    "\n",
    "    return json_str\n",
    "res=dict_to_filename(d)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "1  2  5  8\n",
       "0  1  4  7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=tts(df)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成一个二分类数据集\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "\n",
    "# 将数据集分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred_prob = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 计算ROC曲线和AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=list(\"abc\")\n",
    "l2=list(range(3))\n",
    "d={\"c1\":l1,\"c2\":l2}\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(d)\n",
    "df\n",
    "# from pandas import p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=df[\"c1\"]\n",
    "s1,type(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=np.random.randint(10,size=(3,2))\n",
    "for x,y in M:\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "p=Path(\"./meta_files/\")\n",
    "p.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.isfile(p)\n",
    "demo=\"demo.ext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=(p/demo)\n",
    "p.name,p.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.write_text(\"test Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"W\": \"angry\",\n",
    "    \"L\": \"boredom\",\n",
    "    \"E\": \"disgust\",\n",
    "    \"A\": \"fear\",\n",
    "    \"F\": \"happy\",\n",
    "    \"T\": \"sad\",\n",
    "    \"N\": \"neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c=categories[\"abc\"]\n",
    "try:\n",
    "    d=categories[\"ab\"]\n",
    "except KeyError:\n",
    "    print(\"no key named ab\")\n",
    "else:\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "dd=defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[\"k1\"]+=list(\"asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'k1': ['a', 's', 'd', 'f'], 'k2': 'nekneknek'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[\"k2\"]+=\"nek\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dd['k3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "isinstance({\"a\":1},collections.abc.Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files_iter=glob.glob(\"data/emodb/wav/*.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "db=load_iris()\n",
    "X=db.data\n",
    "y=db.target\n",
    "# X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "# y = [0, 0, 1, 1, 2]\n",
    "svc=SVC(random_state=0)\n",
    "classif = OneVsRestClassifier(estimator=svc)\n",
    "y_pred=classif.fit(X, y).predict(X)\n",
    "# print(y_pred,\"@{y_pred}\")\n",
    "print(classification_report(y, y_pred, zero_division=1))\n",
    "print(accuracy_score(y, y_pred))\n",
    "\n",
    "\n",
    "# y_b = LabelBinarizer().fit_transform(y)\n",
    "lf=LabelBinarizer().fit(y)\n",
    "print(f'{lf.classes_=},{lf.y_type_}')\n",
    "y_b=lf.transform(y)\n",
    "#标签二进制化\n",
    "# print(y,\"@{y}\")\n",
    "# print(y_b,\"@{y_b}\")\n",
    "#基于二进制矩阵的标签进行拟合\n",
    "y_pred_b=classif.fit(X, y_b).predict(X)\n",
    "# print(y_pred_b, \"@{y_pred_b}\")\n",
    "print(classification_report(y_b,y_pred_b,zero_division=1))\n",
    "print(accuracy_score(y_b, y_pred_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris,load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "# db = load_iris()\n",
    "db=load_digits()\n",
    "X = db.data\n",
    "y = db.target\n",
    "# target_names = db.target_names\n",
    "\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# 训练SVC模型\n",
    "svc = SVC(kernel='linear', C=1, decision_function_shape='ovr')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = svc.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "# 计算准确率\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rep=classification_report(y_test,y_pred)\n",
    "print(rep,\"@{rep}\")\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "X = np.array([\n",
    "    [10, 10],\n",
    "    [8, 10],\n",
    "    [-5, 5.5],\n",
    "    [-5.4, 5.5],\n",
    "    [-20, -20],\n",
    "    [-15, -20]\n",
    "])\n",
    "y = np.array([0, 0, 1, 1, 2, 2])\n",
    "print(y,\"@{y}\")\n",
    "clf = OneVsRestClassifier(SVC()).fit(X, y)\n",
    "clf.predict([[-19, -20], [9, 9], [-5, 5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "y = [0, 0, 1, 1, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "classif.fit(X, y).predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "print(y,\"@{y}\")\n",
    "classif.fit(X, y).predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "# print(accuracy_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\n",
    "mlb = MultiLabelBinarizer()\n",
    "ymlb=mlb.fit_transform(y)\n",
    "# mlb.fit_transform属性只有在fit或fit_transform方法被成功调用后才被创建而存在\n",
    "print(mlb.classes_,\"@{mlb.classes_}\")\n",
    "print(ymlb,\"@{ymlb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f2_scorer=make_scorer(fbeta_score, beta=2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.datasets import load_iris,load_digits\n",
    "db=load_iris()\n",
    "db=load_digits()\n",
    "X,y=db.data,db.target#type:ignore\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "print(f'{f2_scorer=}')\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C': [1, 10]}\n",
    "grid = GridSearchCV(SVC(), \n",
    "                    param_grid=parameters,\n",
    "                    scoring=f2_scorer,\n",
    "                    verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_,\"@{grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    diff = np.abs(y_true - y_pred).max()\n",
    "    return np.log1p(diff)\n",
    "\n",
    "\n",
    "# score will negate the return value of my_custom_loss_func,\n",
    "# which will be np.log(2), 0.693, given the values for X\n",
    "# and y defined below.\n",
    "score = make_scorer(my_custom_loss_func, greater_is_better=False)\n",
    "X = [[1], [1]]\n",
    "y = [0, 1]\n",
    "clf = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "my_custom_loss_func(y, clf.predict(X))\n",
    "\n",
    "score(clf, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score (micro): 0.6666666666666666\n",
      "f1_score (macro): 0.7222222222222222\n",
      "f1_score (weighted): 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 假设模型的预测结果保存在y_pred变量中，真实标签保存在y_true变量中\n",
    "y_true = [[1, 0, 0],\n",
    "          [0, 1, 1],\n",
    "          [1, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "y_pred = [[1, 0, 1],\n",
    "          [1, 1, 0],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "# 计算不同加权方式下的f1_score\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"f1_score (micro):\", f1_micro)\n",
    "print(\"f1_score (macro):\", f1_macro)\n",
    "print(\"f1_score (weighted):\", f1_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [1. 1. 1. 1. 1.]\n",
      "recall: [1.   0.75 0.5  0.25 0.  ]\n",
      "thresholds: [0.6 0.7 0.8 0.9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 假设模型的预测概率保存在y_score变量中，真实标签保存在y_true变量中\n",
    "y_true = [0, 1, 1, 0, 1, 0, 0, 1]\n",
    "y_score = [0.2, 0.8, 0.6, 0.4, 0.9, 0.3, 0.1, 0.7]\n",
    "\n",
    "# 计算精度-召回率曲线\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "# 输出结果\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)\n",
    "print(\"thresholds:\", thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 0, 1, 2]), array([0, 2, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "nda=np.array\n",
    "y_true =nda( [0, 1, 2, 0, 1, 2])\n",
    "y_pred = nda([0, 2, 1, 0, 0, 1])\n",
    "# y_true,y_pred\n",
    "\n",
    "f1_score(y_true, y_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
