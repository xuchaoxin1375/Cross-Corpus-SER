import os
import sys
from collections import defaultdict
from email.mime import audio
from functools import partial

import numpy as np
import pandas as pd
import tqdm

import EF
from create_csv import create_csv_by_metaname
from EF import AHNPS, HNS, AHNPS_dict, HNS_dict, MCM_dict, e_config_def, f_config_def
from MetaPath import (
    create_tag_name,
    features_dir,
    get_features_tag,
    get_first_letters,
    test_emodb_csv,
    test_ravdess_csv,
    train_emodb_csv,
    train_ravdess_csv,
    validate_partition,
    ava_dbs,
)
from utils import extract_feature

# from pathlib import Path
Series = pd.Series
DataFrame = pd.DataFrame


class AudioExtractor:
    """A class that is used to featurize audio clips, and provide
    them to the machine learning algorithms for training and testing
    å’Œç‰¹å¾æå–ä¸åŒ,æœ¬æ¨¡å—è´Ÿè´£å¤„ç†ç‰¹å¾æå–ä¹‹åçš„æ•°æ®å¤„ç†,ç‰¹å¾æå–(å‚çœ‹utils.extract_featureæ–¹æ³•)
    æœ¬æ¨¡å—å°è¯•ä»æŒ‡å®šç›®å½•(é»˜è®¤ä»features)ç›®å½•å¯¼å…¥ç‰¹å¾æ–‡ä»¶(.npy)(ç”±numpyæä¾›çš„å¯¹è±¡å­˜å‚¨æ–¹æ¡ˆ)
    """

    def __init__(
        self,
        dbs=None,
        f_config=None,
        e_config=None,
        features_dir=features_dir,
        verbose=True,
        classification_task=True,
        balance=True,
    ):
        """
        åˆå§‹åŒ–AEå¯¹è±¡,åœ¨initä¸­å¯¹æ„é€ å™¨ä¸­ä¼ å…¥Noneæˆ–è€…ä¸ä¼ å€¼å¾—å‚æ•°è®¾ç½®äº†é»˜è®¤å€¼,é»˜è®¤å‚æ•°ä¸ºNoneæ˜¯å‚è€ƒNumpyçš„é£æ ¼
        ç„¶è€Œé»˜è®¤å€¼è®¾ç½®åœ¨initä¹Ÿæœ‰ä¸å¥½çš„åœ°æ–¹,æ¯”å¦‚è¿™å®¹æ˜“å‡ºç°ä¸€äº›é»˜è®¤ä½†æ˜¯å‡ºä¹æ„æ–™çš„è¡Œä¸º;æ‰€ä»¥åº”è¯¥åœ¨æ³¨é‡Šéƒ¨åˆ†å°½å¯èƒ½åœ°è¯¦ç»†è¯´æ˜

        Params:
        -
        audio_config (dict):
            the dictionary that indicates what features to extract from the audio file,
            default is {'mfcc': True, 'chroma': True, 'mel': True, 'contrast': False, 'tonnetz': False}
            (i.e mfcc, chroma and mel)

        verbose (bool/int):
            verbosity level, False for silence, True for info, default is True

        features_folder_name (str):
            the folder to store output features extracted,
            default is "features".

        classification (bool):
            whether it is a classification or regression, default is True (i.e classification)

        emotions (list):
            list of emotions to be extracted, default is [ 'happy','neutral' ,'sad']

        balance (bool):
            whether to balance dataset (both training and testing), default is True
        """
        self.f_config = f_config if f_config else f_config_def
        self.e_config = e_config if e_config else e_config_def
        self.dbs = dbs
        self.verbose = verbose
        self.features_dir = features_dir  # é»˜è®¤ä¸ºfeaturesç›®å½•
        self.classification_task = classification_task
        self.balance = balance
        # input dimension
        self.feature_dimension = None
        # è®°å½•æœ€åä¸€æ¬¡æå–è¯­éŸ³æ–‡ä»¶ä¿¡æ¯
        self.audio_paths = []
        self.emotions = []

        # partition attributes
        self.train_audio_paths = []
        self.train_emotions = []
        self.train_features = []

        self.test_audio_paths = []
        self.test_emotions = []
        self.test_features = []
        # ä½¿ç”¨å­—å…¸æ‰“åŒ…

    def get_partition_features(self, partition) -> np.ndarray:
        """å°†åŒ…å«è‹¥å¹²ä¸ªäºŒç»´ndarrayçš„åˆ—è¡¨vstackæˆ1ä¸ªäºŒç»´ndarray

        Parameters
        ----------
        partition : str
            "train"|"test"

        Returns
        -------
        np.ndarray
            åˆå¹¶å®Œæˆçš„çŸ©é˜µ

        Raises
        ------
        ValueError
            _description_
        """
        # print("len(self.train_features),len(self.test_features):")
        # print(len(self.train_features),len(self.test_features))
        # return
        partition = validate_partition(partition)
        if partition == "test":
            res = np.vstack(self.test_features) if self.test_features else np.array([])
        else:
            res = (
                np.vstack(self.train_features) if self.train_features else np.array([])
            )

        return res

    def load_metadata(self, meta_files):
        """
        ä»meta_files(æ–‡ä»¶)ä¸­è¯»å–è¯­æ–™åº“å„æ¡è¯­éŸ³çš„ä¿¡æ¯;

        Read metadata from a  file & Extract and loads features of audio files

        Parameters
        ----------
        meta_files : list[str]|str
            éœ€è¦è¯»å–çš„metaæ–‡ä»¶

        """
        # empty dataframe
        df = pd.DataFrame({"path": [], "emotion": []})
        # åˆå¹¶æ‰€æœ‰éœ€è¦è¯»å…¥çš„æ–‡ä»¶
        # for meta_file in meta_files:
        #     # concat dataframes
        #     df = pd.concat((df, pd.read_csv(meta_file)), sort=False)
        if isinstance(meta_files, str):
            meta_files = [meta_files]
        if self.verbose:
            print("[I] Loading audio file paths and its corresponding labels...")
        print("meta_files:", meta_files)
        # print("type(meta_files)", type(meta_files))
        if isinstance(meta_files, str):
            meta_files = [meta_files]
        for meta_file in meta_files:
            if not os.path.exists(meta_file):
                # create_csv_by_meta_name
                print(f"{meta_file} does not exist,creating...")
                create_csv_by_metaname(meta_file)
            else:
                print(f"å­˜åœ¨{meta_file}æ–‡ä»¶!")
            df_meta = pd.read_csv(meta_file)
            df = pd.concat((df, df_meta), sort=False)
        # get columns
        # æŠ½å–éŸ³é¢‘æ–‡ä»¶è·¯å¾„ä¿¡æ¯å’Œå¯¹åº”çš„æƒ…æ„Ÿæ ‡ç­¾
        # audio_paths_:list
        # emotions_:list
        audio_paths, emotions = list(df["path"]), list(df["emotion"])
        return audio_paths, emotions

    def _class2rgr(self):
        # å¦‚æœæ‰§è¡Œå›å½’é¢„æµ‹,é‚£ä¹ˆæœ¬æ¨¡å—å°†å¢åŠ self.categories_rgrå°†æ ‡ç­¾æ•°å€¼åŒ–
        # é»˜è®¤æƒ…å†µä¸‹,ç³»ç»Ÿæ‰§è¡Œåˆ†ç±»é¢„æµ‹,æ ‡ç­¾æ˜¯æƒ…æ„Ÿåè¯å­—ç¬¦ä¸²
        # æ•°å€¼åŒ–ç±»åˆ«æ ‡ç­¾,ä¾¿äºä½¿ç”¨å›å½’ç®—æ³•é¢„æµ‹(è®¾ç½®3æƒ…æ„Ÿå’Œ5æƒ…æ„Ÿ2ç§æ¨¡å¼)
        # if not classification, convert emotions to numbers
        if not self.classification_task and self.e_config:
            if len(self.e_config) == 3:
                # HNSæƒ…æ„Ÿæ¨¡å¼(Happy,Neutral,Sad)
                self.categories_rgr = HNS_dict
            elif len(self.e_config) == 5:
                # AHNPSæƒ…æ„Ÿæ¨¡å¼:Angry,Happy,Neutral,PleasantSuprise,Sad
                self.categories_rgr = AHNPS_dict
            else:
                raise TypeError(f"Regression is only for either {HNS} or {AHNPS}")
            # TODO (improve)
            emotions = self.e_config  # å¯ä»¥å†ä¼˜åŒ–robustness
            emotions = [self.categories_rgr[e] for e in emotions]  # å­—ç¬¦ä¸²æ ‡ç­¾æ•°å­—åŒ–

    def _update_partition_attributes(
        self,
        partition,
        audio_paths=None,
        emotions=None,
        features=None,
    ):
        """
         ç”¨äºå®ç°å¢é‡æå–
         é™„åŠ å±æ€§é›†è®¾ç½®å’Œå¢é‡
         åˆæ¬¡è°ƒç”¨ä¼šè®¾ç½®æ–°å±æ€§

        ## Note1:
        è­¦æƒ•numpyçš„ndarrayæ•°ç»„åˆ¤æ–­boolå€¼æ—¶çš„é”™è¯¯åšæ³•:
        `ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`
        è¿™ä¸ªé”™è¯¯çš„æ˜¯ç”±äºndarrayå¯¹è±¡åœ¨boolä¸Šä¸‹æ–‡(æ¯”å¦‚if a)(aæ ‡è¯†ndarrayå¯¹è±¡)
        çš„è¯­å¥ä¸­,ç”±äºndarrayåŒ…å«çš„sizeä¸ªå…ƒç´ å„è‡ªæœ‰è‡ªå·±çš„`True`/`False`å€¼,éœ€è¦ç”¨any()æˆ–all()æ¥æ¶ˆé™¤æ­§ä¹‰
        ä¸è¿‡æœ‰æ—¶å€™æˆ‘ä»¬ä»…ä»…æƒ³çŸ¥é“è¢«åˆ¤æ–­çš„å¯¹è±¡æ˜¯å¦ä¸ºéç©ºæˆ–éNone,é‚£ä¹ˆå¯ä»¥ç”¨a.szieå±æ€§æ¥åˆ¤æ–­å…ƒç´ æ•°é‡,ç”¨`a is None`

        ## Note2:
        print(id(self.test_features), "@{Id@self.test_features}")
        print(id(features_attr), "@{Id@features_attr}")
        print(id(features),"@{Id@features}")


        Parameters
        ----------
        partition : str
            "train|test"
        audio_paths : list[str]
            train/test set file path
        emotions : list[str]
            tr/te set file path
        features : ndarray, optional
            ç”±ç‰¹å¾æå–ç¯èŠ‚è¿”å›çš„ç‰¹å¾æ•°ç»„, by default None

        """
        # if(audio_paths_ and emotions_):
        # audio_paths = self.audio_paths
        # emotions = self.e_config
        np.mean([12, 3])
        # è®¾ç½®è®­ç»ƒé›†å±æ€§
        partition = validate_partition(partition)
        verbose = self.verbose
        if verbose:
            print(f"[Info] Adding  {partition} samples")

        # partition_attribute_set
        audio_paths_attr, emotions_attr, features_attr = self.partition_attributes_set(
            partition
        )
        if audio_paths:
            audio_paths_attr += audio_paths
        if emotions:
            emotions_attr += emotions

        # è¿™é‡Œè¦åŒºåˆ«å¯¹å¾…features,åŸå› å‚è€ƒpythonçš„id()æ–¹æ³•
        if features is not None:
            features_attr += [features]  # å°†featuresæ‰“åŒ…ä¸ºåˆ—è¡¨åœ¨å¹¶å…¥
            # np.vstack(features)
        if verbose >= 2:
            # æ£€æŸ¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†å±æ€§æƒ…å†µ
            check_1 = self.partition_attributes_set(partition)
            for attr in check_1:
                nd_attr = np.array(attr, dtype=object)
                # print(nd_attr.shape, id(attr))

    def partition_attribute_update_handler(
        self, partition, features, audio_paths, emotions
    ):
        pass

    # @deprecate()
    def partition_attributes_set(self, partition="", verbose=1):
        """
        è¿”å›åˆå§‹å€¼ä¸ºç©ºåˆ—è¡¨çš„partitionå±æ€§
        - !è¦æ±‚è°ƒç”¨æœ¬æ–¹æ³•è¿”å›çš„å˜é‡å¿…é¡»ä½¿ç”¨+=çš„æ–¹æ³•ä¿®æ”¹,å¦åˆ™è¾¾ä¸åˆ°é¢„æœŸæ•ˆæœ
        - å¯¹äºfeatureså±æ€§,åœ¨è®¿é—®çš„æ—¶å€™å°†æ˜¯ä¸åŒçš„ç‰¹å¾çŸ©é˜µ
        - å…¶ä»–å†™æ³•
        if partition == "train":

            self.train_audio_paths+=value

        elif partition == "test":
            self.test_audio_paths+=value

        Parameters
        ----------
        partition : str
            _description_
        value : _type_
            _description_
        """
        partition = validate_partition(partition=partition)

        attributes = []
        if partition == "train":
            attributes = [
                self.train_audio_paths,
                self.train_emotions,
                self.train_features,
            ]
        elif partition == "test":
            attributes = [self.test_audio_paths, self.test_emotions, self.test_features]
        # print(attributes,"@{attributes}:",partition)
        if verbose >= 2:
            print("ids of attributes set:")
            print([id(attr) for attr in attributes])
        return attributes

    def _extract_feature_in_meta(self, partition="", meta_path=""):
        """æ ¹æ®meta_filesæå–ç›¸åº”è¯­éŸ³æ–‡ä»¶çš„ç‰¹å¾
        è¿™é‡Œä»…å®Œæˆå•æ¬¡æå–

        çŸ©é˜µæ–‡ä»¶åä¸­çš„e_configå­—æ®µæš‚å®šä¸ºself.e_config,å¦‚æœæ˜¯è¿™æ ·,å¯èƒ½ä¼šå’Œmeta_pathæ–‡ä»¶ä¸­çš„æƒ…æ„Ÿå­—æ®µå‡ºç°ä¸ä¸€è‡´çš„æƒ…å†µ.

        Parameters
        ----------
        meta_files : list[str]|str
            meta_files
        partition : str
            æ ‡è®°è¢«æå–æ–‡ä»¶æ˜¯æ¥è‡ªè®­ç»ƒé›†è¿˜æ˜¯æµ‹è¯•é›†(éªŒè¯é›†)
        """
        # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦æŒ‰ç…§é…ç½®çš„æƒ…æ„Ÿè¿›è¡Œç­›é€‰å’Œåˆ’åˆ†:
        # if(not os.path.exists(meta_path)):
        #     create_csv_by_metaname(meta_file=meta_path)
        # self.load_metadata(meta_path)

        audio_paths, emotions = self.load_metadata(meta_path)
        # å°†è®¡ç®—ç»“æœä¿å­˜ä¸ºå¯¹è±¡å±æ€§

        self.audio_paths = audio_paths
        self.emotions = emotions
        # å°è¯•è®¡ç®—è¯­æ–™åº“çš„åå­—(å­—æ®µ)
        meta_name = os.path.basename(meta_path)
        meta_name,ext=os.path.splitext(meta_name)
        meta_fields = meta_name.split("_")
        db = meta_fields[1]
        print(f"{meta_path=}@")
        print(f"{db=}@")

        db = db if db in ava_dbs else ""
        #è®¡ç®—æƒ…æ„Ÿå­—æ®µ
        emotions_first_letters=meta_fields[-1]
        origin_efls = get_first_letters(self.e_config)
        if emotions_first_letters != origin_efls:
            raise ValueError(
                f"{emotions_first_letters} is not inconsistant with {self.e_config}"
            )
        if not os.path.isdir(self.features_dir):
            os.mkdir(self.features_dir)

        n_samples = len(audio_paths)  # è®¡ç®—è¦å¤„ç†çš„éŸ³é¢‘æ–‡ä»¶æ•°

        features_file_name = create_tag_name(
            db=db,
            partition=partition,  # å»ºè®®ä¿å­˜ç‰¹å¾æ–‡ä»¶æ—¶,è¿™ä¸ªå­—æ®µç½®ç©ºå³å¯
            e_config=self.e_config,
            f_config=self.f_config,
            n_samples=n_samples,
            ext="npy",
        )

        # æ„é€ ä¿å­˜ç‰¹å¾çŸ©é˜µnpyæ–‡ä»¶çš„è·¯å¾„
        features_file_path = os.path.join(
            self.features_dir,
            features_file_name,
        )

        print(f"æ£€æŸ¥ç‰¹å¾æ–‡ä»¶{features_file_path}æ˜¯å¦å­˜åœ¨...")
        print(f"{self.e_config=}")

        # if self.e_config == HNS:
        #     raise ValueError(f"{self.e_config=}")
        
        ffp = os.path.isfile(features_file_path)
        if ffp:
            # if file already exists, just load
            if self.verbose:
                print(f"ç‰¹å¾çŸ©é˜µæ–‡ä»¶(.npy)å·²ç»å­˜åœ¨,ç›´æ¥å¯¼å…¥:loading...")
            features = np.load(features_file_path)
        else:
            # file does not exist, extract those features and dump them into the file
            if self.verbose:
                print("npyæ–‡ä»¶ä¸å­˜åœ¨,å°è¯•åˆ›å»º...")
            # å¦‚æœå°šæœªæå–è¿‡ç‰¹å¾,åˆ™åœ¨æ­¤å¤„è¿›è¡Œæå–,åŒæ—¶ä¿å­˜æå–ç»“æœ,ä»¥ä¾¿ä¸‹æ¬¡ç›´æ¥ä½¿ç”¨
            features = self.features_save(partition, audio_paths, features_file_path)

        return features, audio_paths, emotions

    def features_save(self, partition, audio_paths, features_file_path):
        """å°†æå–çš„ç‰¹å¾(ndarray)ä¿å­˜æŒä¹…åŒ–ä¿å­˜(ä¸ºnpyæ–‡ä»¶)
        åˆ©ç”¨qtmdæä¾›å¯è§†åŒ–ç‰¹å¾æŠ½å–è¿›åº¦

        Parameters
        ----------
        partition : str
            "test|train"
        audio_paths_ : str
            éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„
        features_file_path : str
            ä¿å­˜æ–‡ä»¶å

        Returns
        -------
        ndarray
            æå–çš„ç‰¹å¾æ•°ç»„
        """
        features = []
        # print(audio_paths)
        # append = features.append

        # ç‰¹å¾æå–æ˜¯ä¸€ä¸ªæ¯”è¾ƒè€—æ—¶çš„è¿‡ç¨‹,ç‰¹å¾ç§ç±»è¶Šå¤šè¶Šè€—æ—¶,è¿™é‡Œé‡‡ç”¨tqdmæ˜¾ç¤ºç‰¹å¾æå–è¿›åº¦æ¡(å·²å¤„ç†æ–‡ä»¶/æ–‡ä»¶æ€»æ•°)
        cnt=0
        for audio_file in tqdm.tqdm(
            audio_paths, f"Extracting features for {partition}"
        ):
            cnt+=1
            if cnt%20 ==0:
                print(f"æ­£åœ¨æŠ½å–ç¬¬{cnt}ä¸ªæ–‡ä»¶çš„ç‰¹å¾..")
            # è°ƒç”¨utilsæ¨¡å—ä¸­çš„extract_featrueè¿›è¡Œç‰¹å¾æå–
            f_config = self.f_config
            feature = extract_feature(audio_file, f_config=f_config)
            if self.feature_dimension is None:
                # MCMç‰¹å¾ç»„åˆä¸‹(3ç‰¹å¾),æœ‰180ç»´çš„å•è½´æ•°ç»„,5ç‰¹å¾ä¸‹,æœ‰193ç»´
                self.feature_dimension = feature.shape[0]
            # æŠŠå½“å‰æ–‡ä»¶æå–å‡ºæ¥ç‰¹å¾æ·»åŠ åˆ°featuresæ•°ç»„ä¸­
            features.append(feature)
        # featuresæ˜¯ä¸€ä¸ªäºŒç»´æ•°ç»„(n_samples,feature_dimension),æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªç‰¹å¾
        # æ­¤æ—¶æ‰€æœ‰æ–‡ä»¶ç‰¹å¾æå–å®Œæ¯•,å°†å…¶ç”¨numpyä¿å­˜ä¸ºnpyæ–‡ä»¶
        features = np.array(features)  # æ„æˆäºŒç»´æ•°ç»„
        np.save(features_file_path, features)
        # print(features)
        # sys.exit(1)
        return features

    def extract_update(self, partition="", meta_paths="", verbose=1):
        """ç‰¹å¾æå–å’Œselfå±æ€§æ›´æ–°ç»´æŠ¤
        å¤šæ¬¡è°ƒç”¨å°†æ‰§è¡Œå¢é‡æå–,æ ¹æ®partitionçš„å–å€¼,å°†æ¯æ¬¡çš„æå–ç»“æœå¢é‡æ›´æ–°selfçš„ç›¸åº”å±æ€§é›†
        Parameters
        ----------
        partition : str
            "train"|"test"
        meta_files : list[str]|str
            _description_
        """
        if not meta_paths:
            raise ValueError("meta_files cannot be empty")
            # return meta_files
        if isinstance(meta_paths, str):
            print(f"cast the '{meta_paths}' to [str]")
            meta_paths = [meta_paths]
        # æ‰§è¡Œç‰¹å¾æå–
        for meta_file in meta_paths:
            print(meta_file, "@ğŸˆ{meta_file}")
            # sys.exit()
            features, audio_paths, emotions = self._extract_feature_in_meta(
                meta_path=meta_file, partition=""
            )
            # è¿™é‡Œå°†partitionè®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²,æ˜¯å› ä¸ºæ ‡è®°ç‰¹å¾æ˜¯ç”¨æ¥è®­ç»ƒè¿˜æ˜¯ç”¨æ¥æµ‹è¯•æ„ä¹‰ä¸å¤§,è€Œä¸”åœ¨è·¨åº“è¯•éªŒä¸­,æˆ‘ä»¬ä¼šè®©ä¸€ä¸ªtrain/test features å°ç¯èº«ä»½,åªéœ€è¦çŸ¥é“è¿™ä¸ªç‰¹å¾æ–‡ä»¶åŒ…å«å“ªäº›æƒ…æ„Ÿç‰¹å¾,æ¥è‡ªå“ªä¸ªè¯­æ–™åº“,ä»¥åŠæœ‰å¤šå°‘ä¸ªæ–‡ä»¶å³å¯
            # å¦‚æœè¦æ›´ç»†è‡´ä¸€äº›,å¯ä»¥è€ƒè™‘åŠ å…¥balanceæˆ–shuffleä¿¡æ¯,ä½†è¿™ä¸æ˜¯å¿…é¡»çš„,è€Œä¸”ä¼šå¯¹è°ƒè¯•é€ æˆä¸å˜
            if verbose >= 1:
                print(features.shape, "@{feature.shape}")
            if verbose >= 2:
                print(features, "@{features}")

            # æ¯æ ¹æ®ä¸€ä¸ªmeta_fileæå–ä¸€æ‰¹ç‰¹å¾,å°±æ›´æ–°åˆ°selfçš„ç›¸å…³å±æ€§é›†ä¸­
            self._update_partition_attributes(
                partition=partition,
                audio_paths=audio_paths,
                emotions=emotions,
                features=features,
            )

    def load_data_preprocessing(self, meta_files=None, partition="", shuffle=False):
        """å°†ç‰¹å¾æå–å’Œå±æ€§è®¾ç½®ä»¥åŠæ‰“ä¹±å’Œå¹³è¡¡æ“ä½œæ‰“åŒ…å¤„ç†
        AEå¯¹è±¡åœ¨å¦‚æ•°æ®é›†åå¯é€‰çš„æ•°æ®å¤„ç†æ“ä½œ(balance&shuffle)

        Parameters
        ----------
        meta_files : list[str]|str
            éœ€è¦è½½å…¥æ•°æ®çš„metaä¿¡æ¯
        partition : str, optional
            "test|train", by default None
        shuffle : bool, optional
            æ˜¯å¦æ‰§è¡Œæ‰“ä¹±æ•°æ®é¡ºåºæ“ä½œ, by default False
        """
        print(f"{partition=}")
        print(meta_files,"@{meta_files}in load_data_preprosscing")
        if not meta_files:
            return
        self.extract_update(partition=partition, meta_paths=meta_files)

        # balancing the datasets ( both training or testing )
        if self.balance:
            self._balance_data(partition=partition)
        # shuffle
        if shuffle:
            self.shuffle_data_by_partition(partition)

    def shuffle_data_by_partition(self, partition):
        """æ‰“ä¹±æ•°æ®é¡ºåº

        Parameters
        ----------
        partition : str
            "train"|"test"

        Raises
        ------
        TypeError

        """
        if partition == "train":
            (
                self.train_audio_paths,
                self.train_emotions,
                self.train_features,
            ) = shuffle_data(
                self.train_audio_paths, self.train_emotions, self.train_features
            )
        elif partition == "test":
            (
                self.test_audio_paths,
                self.test_emotions,
                self.test_features,
            ) = shuffle_data(
                self.test_audio_paths, self.test_emotions, self.test_features
            )
        else:
            raise TypeError("Invalid partition, must be either train/test")

    def _balance_data(self, partition=""):
        """
        å¯¹è®­ç»ƒé›†/æµ‹è¯•é›†çš„æ•°æ®åšå¹³è¡¡å¤„ç†

        """
        partition = validate_partition(partition=partition)

        audio_paths, counter, emotions_tags, features = self.emotions_counter(partition)

        # get the minimum data samples to balance to
        minimum = self.validate_balance_task(counter)
        if minimum == 0:
            return

        # æ„é€ å¹¶åˆå§‹åŒ–{æƒ…æ„Ÿ:æ•°é‡}å­—å…¸
        counter = self.count_dict()

        dd = self.balanced_dict(audio_paths, counter, emotions_tags, features, minimum)

        # å°†ç±»åˆ«å¹³è¡¡å¤„ç†å¥½çš„å…ƒç»„å½¢å¼é‡æ–°è§£æå›åŸºæœ¬pythonç±»å‹å¯¹è±¡
        audio_paths, emotions_tags, features = self.parse_balanced_data(dd)
        # å°†è§£æç»“æœæ›´æ–°å›selfå¯¹è±¡çš„ç›¸åº”å±æ€§ä¸Š
        self.update_balanced_attributes(partition, audio_paths, emotions_tags, features)

    def validate_balance_task(self, counter):
        minimum = min(counter)
        if self.verbose:
            print("[*] Balancing the dataset to the minimum value:", minimum)
        if minimum == 0:
            # won't balance, otherwise 0 samples will be loaded
            print("[!] One class has 0 samples, setting balance to False")
            self.balance = False
        return minimum

    def balanced_dict(self, audio_paths, counter, emotions_tags, features, minimum):
        """æ„é€ å¹³è¡¡å¤„ç†å¥½æ•°æ®é›†çš„å­—å…¸

        å®ç°è¯´æ˜:æœ¬æ–¹æ³•ä¸»è¦å€ŸåŠ©defaultdictå®ç°,ç®€ç§°dd
        å®ƒæ˜¯ Python ä¸­çš„ä¸€ä¸ªå­—å…¸å­ç±»ï¼Œå®ƒåœ¨å­—å…¸çš„åŸºç¡€ä¸Šæ·»åŠ äº†ä¸€ä¸ªé»˜è®¤å·¥å‚å‡½æ•°ï¼Œ
        ä½¿å¾—åœ¨è®¿é—®å­—å…¸ä¸­ä¸å­˜åœ¨çš„é”®æ—¶ï¼Œå¯ä»¥è¿”å›ä¸€ä¸ªé»˜è®¤å€¼è€Œä¸æ˜¯å¼•å‘ KeyError å¼‚å¸¸ã€‚
        defaultdict çš„æ„é€ å‡½æ•°éœ€è¦ä¸€ä¸ªå‚æ•°ï¼Œå³é»˜è®¤å·¥å‚å‡½æ•°ã€‚
        é»˜è®¤å·¥å‚å‡½æ•°å¯ä»¥æ˜¯ Python å†…ç½®ç±»å‹ï¼ˆå¦‚ intã€listã€set ç­‰ï¼‰ï¼Œä¹Ÿå¯ä»¥æ˜¯ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°ã€‚
        å½“è®¿é—®å­—å…¸ä¸­ä¸å­˜åœ¨çš„é”®æ—¶ï¼Œå¦‚æœä½¿ç”¨äº†é»˜è®¤å·¥å‚å‡½æ•°ï¼Œåˆ™ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªæ–°çš„é”®ï¼Œ
        å¹¶å°†å…¶å¯¹åº”çš„å€¼åˆå§‹åŒ–ä¸ºé»˜è®¤å€¼ï¼ˆç”±é»˜è®¤å·¥å‚å‡½æ•°è¿”å›ï¼‰ã€‚

        åœ¨ddçš„å¸®åŠ©ä¸‹,æˆ‘ä»¬å¯ä»¥è½»æ¾çš„ç»Ÿè®¡(æƒ…æ„Ÿ)ç±»åˆ«æ•°æœªçŸ¥çš„æƒ…å†µä¸‹,ç»Ÿè®¡å„ä¸ªæƒ…æ„Ÿçš„æ–‡ä»¶æ•°

        Parameters
        ----------
        audio_paths : list
            _description_
        counter :
            _description_
        emotions_tags : _type_
            _description_
        features : _type_
            _description_
        minimum : _type_
            _description_

        Returns
        -------
        _type_
            _description_
        """
        dd = defaultdict(list)  #
        for e, feature, audio_path in zip(emotions_tags, features, audio_paths):
            if counter[e] >= minimum:
                # minimum value exceeded
                continue
            counter[e] += 1
            dd[e].append((feature, audio_path))
        # data={}
        # ä¸´æ—¶å±æ€§ç”¨äºnotebookä¸­è°ƒè¯•
        self.dd_debug = dd
        # print(dd)
        return dd

    def count_dict(self, verbose=0):
        """æ„é€ å¹¶åˆå§‹åŒ–{æƒ…æ„Ÿ:æ•°é‡}å­—å…¸
        Returns
        -------
        dict
            ç”¨äºç»Ÿè®¡å¹³è¡¡æ•°æ®çš„å­—å…¸
        """
        if self.classification_task:
            res = {e: 0 for e in self.e_config}  # type:ignore
        else:
            res = {e: 0 for e in self.categories_rgr.values()}

        if verbose:
            print("{res}:")
            print(res)
        return res

    def parse_balanced_data(self, dd):
        emotions_tags, features, audio_paths = [[] for _ in range(3)]
        for emo, f_ap in dd.items():
            for feature, audio_path in f_ap:
                emotions_tags.append(emo)
                features.append(feature)
                audio_paths.append(audio_path)
        return audio_paths, emotions_tags, features

    def update_balanced_attributes(
        self, partition, audio_paths, emotions_tags, features
    ):
        """å°†è§£æç»“æœæ›´æ–°å›selfå¯¹è±¡çš„ç›¸åº”å±æ€§ä¸Š

        Parameters
        ----------
        partition : str
            "test|train"
        audio_paths : list
            è·¯å¾„
        emotions_tags : list
            æƒ…æ„Ÿæ ‡ç­¾
        features : list
            ç‰¹å¾

        Raises
        ------
        TypeError
            æ•°æ®é›†ç›®æ ‡åå­—åˆ’åˆ†éæ³•(test|train)
        """
        partition = validate_partition(partition=partition, Noneable=False)
        if partition == "train":
            self.train_emotions = emotions_tags
            self.train_features = features
            self.train_audio_paths = audio_paths
        elif partition == "test":
            self.test_emotions = emotions_tags
            self.test_features = features
            self.test_audio_paths = audio_paths

    def emotions_counter(self, partition):
        # ç»Ÿä¸€å˜é‡å
        data = [None] * 3
        if partition == "train":
            data = (self.train_emotions, self.train_features, self.train_audio_paths)
        elif partition == "test":
            data = (self.test_emotions, self.test_features, self.test_audio_paths)
        else:
            raise TypeError("Invalid partition, must be either train/test")
        emotions_tags, features, audio_paths = data
        # ä¸ºäº†ä½¿å„ä¸­æƒ…æ„Ÿçš„æ–‡ä»¶æ•°é‡ç›¸ç­‰,åˆ†åˆ«ç»Ÿè®¡ä¸åŒæƒ…æ„Ÿçš„æ–‡ä»¶æ•°
        counter = []  # countä¸­çš„å…ƒç´ ä¸ªæ•°ç­‰äºlen(self.emotions)
        # åˆ†ç±»é¢„æµ‹
        if self.classification_task:
            # éå†éœ€è¦æŠ½å–çš„æƒ…æ„Ÿæ ‡ç­¾
            e_config = self.e_config if self.e_config else e_config_def
            for emo in e_config:
                n_samples_of_emo = len([e for e in emotions_tags if e == emo])
                counter.append(n_samples_of_emo)
        # å›å½’é¢„æµ‹
        else:
            # regression, take actual numbers, not label emotion
            for emo in self.categories_rgr.values():
                counter.append(len([e for e in emotions_tags if e == emo]))
        return audio_paths, counter, emotions_tags, features
        # return counter


def shuffle_data(audio_paths, emotions, features):
    """Shuffle the data
        (called after making a complete pass through
        training or validation data during the training process)

    Params:
    -
        audio_paths (list): Paths to audio clips
        emotions (list): Emotions in each audio clip
        features (list): features audio clips
    """
    length = len(audio_paths)
    # print(length)
    # print([len(item) for item in (audio_paths,emotions,features)])
    if length:
        # å¯¹range(length)çš„ä¹±åºæ’åˆ—åˆ—è¡¨
        # æ ¹æ®ç»Ÿä¸€çš„ä¹±åºåºåˆ—,ä¾¿äºç»Ÿä¸€audio_paths,emotions,features
        # å› æ­¤è¿™é‡Œä¸å¯ç”¨ç›´æ¥åœ°å¯¹ä¸‰ä¸ªåˆ—è¡¨å„è‡ªåœ°è¿è¡Œshuffleæˆ–permutation,ä¼šå¯¼è‡´å¯¹åº”ä¸ä¸Š
        p = np.random.permutation(length)
        audio_paths = [audio_paths[i] for i in p]
        emotions = [emotions[i] for i in p]
        features = [features[i] for i in p]

    return audio_paths, emotions, features


def load_data_from_meta(
    train_meta_files=None,
    test_meta_files=None,
    f_config=None,
    e_config=None,
    classification_task=True,
    shuffle=False,
    balance=False,
) -> dict:
    """å¯¼å…¥è¯­éŸ³æ•°æ®,å¹¶è¿”å›numpyæ‰“åŒ…train/test datasetç›¸å…³å±æ€§çš„ndarrayç±»å‹
    å¦‚æœåªæƒ³æå–train/test datasetä¸­çš„ä¸€æ–¹,é‚£ä¹ˆå¦ä¸€æ–¹å°±ä¼ None(æˆ–è€…ä¸ä¼ å¯¹åº”å‚æ•°)

    Parameters
    ----------
    train_desc_files : list
        train_meta_files
    test_desc_files : list
        test_meta_files
    f_config : dict, optional
        éœ€è¦æå–çš„ç‰¹å¾, by default None
    e_config : list, optional
        éœ€è¦ä½¿ç”¨çš„æƒ…æ„Ÿç±»åˆ«å­—ç¬¦ä¸²æ„æˆçš„åˆ—è¡¨, by default ['sad', 'neutral', 'happy']
    classification_task : bool, optional
        æ˜¯å¦é‡‡ç”¨åˆ†ç±»å™¨(å¦åˆ™ä½¿ç”¨å›å½’æ¨¡å‹), by default True
    shuffle : bool, optional
        æ˜¯å¦æ‰“ä¹±é¡ºåº, by default True
    balance : bool, optional
        æ˜¯å¦è¿›è¡Œæ•°æ®å¹³è¡¡, by default True

    Returns
    -------
    dict
        è¿”å›è½½å…¥æƒ…æ„Ÿç‰¹å¾æ–‡ä»¶çš„çŸ©é˜µæ„æˆçš„å­—å…¸
    """
    # instantiate the class(å®ä¾‹åŒ–ä¸€ä¸ªAudioExtractorå®ä¾‹)
    ae = AudioExtractor(
        f_config=f_config,
        e_config=e_config,
        classification_task=classification_task,
        balance=balance,
        verbose=True,
    )

    print(test_meta_files, "@{test_meta_files} in load_data_from_meta")

    # Loads training data
    ae.load_data_preprocessing(
        meta_files=train_meta_files, partition="train", shuffle=shuffle
    )
    # Loads testing data
    ae.load_data_preprocessing(
        meta_files=test_meta_files, partition="test", shuffle=shuffle
    )

    # ä»¥trainé›†ä¸ºä¾‹æ£€æŸ¥selfå±æ€§
    # print("ae.train_audio_paths:\n", ae.train_audio_paths)
    # X_train, X_test, y_train, y_test

    return {
        # "X_train": np.array(ae.train_features),
        # "X_test": np.array(ae.test_features),
        "X_train": ae.get_partition_features("train"),
        "X_test": ae.get_partition_features("test"),
        "y_train": np.array(ae.train_emotions),
        "y_test": np.array(ae.test_emotions),
        "train_audio_paths": np.array(ae.train_audio_paths),
        "test_audio_paths": np.array(ae.test_audio_paths),
        "balance": ae.balance,
        "ae": ae,
    }


if __name__ == "__main__":
    ae = AudioExtractor(f_config=f_config_def)
    print(ae)
    ae._extract_feature_in_meta(meta_path=train_emodb_csv)

    # data = load_data_from_meta(
    #     # train_meta_files=train_emodb_csv,
    #     test_meta_files=test_emodb_csv,
    #     f_config=f_config_def,
    #     # balance=False,
    #     balance=True,
    # )
